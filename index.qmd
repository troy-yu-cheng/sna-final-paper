---
title: "Social Network Analysis"
subtitle: "Final Paper"
author: 
  - name: "Troy (Yu) Cheng"
    email: yc1317@georgetown.edu
    affiliation: Georgetown University
    corresponding: true
df-print: kable
title-block-banner: "#0a0e1a"
title-block-banner-color: "#4DB8FF"
execute:
  warning: false
date: 2025-04-28
date-modified: last-modified
format:
  html:
    embed-resources: true
    toc: true                 
    toc-title: "Contents"     
    toc-location: right       
    number-sections: true
    number-depth: 3       
    smooth-scroll: true       
    css: trycstyle.css 
    code-overflow: wrap
include-in-header:
  text: |
    <link rel="shortcut icon" href="assets/gu.ico" type="image/x-icon">           
highlight-style: nord       
engine: knitr
---
# Abstract

This study investigates the dissemination patterns of the misinformation narrative that COVID-19 was deliberately created/manufactured by China or the Wuhan laboratory. Drawing on Diffusion of Innovations Theory and Echo Chamber Theory, the study explores how early misinformation claims shaped subsequent retweeter networks and whether homophily emerged over time. The dataset is drawn from the MuMiN project, focusing on six prominent misinformation claims identified between March 2020 and August 2021. Retweeters are treated as nodes, and their relationships are defined by co-retweet, co-quote, co-reply, and follow ties.

The hypothesis posits that retweeters engaged with earlier misinformation claims are more central in the network and sustain higher connectivity over time. Social Network Analysis (SNA) is employed to construct adjacency matrices, visualize network structures, and calculate centrality and modularity measures. Temporal Exponential Random Graph Models (tERGM) are further applied to examine how historical ties and thematic claim categories influence network evolution.

This research contributes to understanding how misinformation diffusion evolves and how early spreaders maintain structural advantages, reinforcing the persistence of misinformation narratives in online social networks.

我现在对covid病毒是在中国/wuhan爆发这条谣言在推特用户间的传播规律（随时间）很感兴趣
一个misinformation的源头很难确定是具体哪个user/tweet 直接研究这种传播的过程会好一点
我们以retweeter作为节点，retweeter相互之间的co-retweet，co-reply，co-quote和follow作为边

# Literature Review


# Dataset

Raw dataset download link: <https://data.bristol.ac.uk/data/en_GB/dataset/23yv276we2mll25fjakkfim2ml/resource/e63a98c4-b4d6-4a89-9be9-06875b83ce33?inner_span=True>

## Set up

```{r}
#| label: set up packages
library(tidyverse)
library(readr)
library(statnet)
library(intergraph)
library(reshape2)
```


```{r}
# Load data
tweets <- read_csv("data/mumin_csv/tweet.csv")
claims <- read_csv("data/mumin_csv/claim.csv")
tweet_claim <- read_csv("data/mumin_csv/tweet_discusses_claim.csv")
user_retweet <- read_csv("data/mumin_csv/user_retweeted_tweet.csv")

# Join tweet & claim via tweet_claim
tweet_claim_joined <- tweet_claim |> 
  rename(tweet_id = src, claim_id = tgt) |> 
  inner_join(claims, by = c("claim_id" = "id"))

# Join retweeters within users & claim via retweeted tweet
user_claim <- user_retweet |> 
  rename(retweeter_id = src, tweet_id = tgt) |> 
  inner_join(tweet_claim_joined, by = "tweet_id")

retweet_map <- user_claim |> 
  select(retweeter_id, tweet_id) |> 
  distinct() 

table(user_claim$label)
table(user_claim$cluster_keywords)
```

初步整合数据之后，我们进一步筛选我们要研究的特定的misinformation话题

```{r}
user_claim_filtered <- user_claim |> 
  filter(str_detect(keywords, "china|wuhan")) 

unique(user_claim_filtered$keywords)


```

After checking the keywords, 我手动选择了所有跟covid19是中国/Wuhan蓄意制造和散播的misinformation。并把这些内容限制在了英文帖子。

```{r}
covid_wuhan_misinfo <- user_claim_filtered |>
  filter(keywords %in% c(
    "coronavirus comes biological laboratory wuhan",
    "including corona virus manufactured wuhan",
    "china created spread coronavirus",
    "announced coronavirus artificially created china",
    "china created coronavirus",
    "coronavirus created laboratory china",
    "honjo said china manufactured coronavirus",
    "said new coronavirus manufactured wuhan",
    "coronavirus tested biological weapon china",
    "china testing coronavirus biological weapon",
    "covid 19 lab china",
    "coronavirus natural worked wuhan laboratory",
    "coronavirus manufactured laboratory wuhan specifically",
    "doctor claimed coronavirus china create",
    "corona virus manufactured china",
    "says current coronavirus manufactured wuhan",
    "wuhan coronavirus created patented",
    "covid 19 disease manufactured china",
    "pandemic caused artificial virus china",
    "collaborator assures coronavirus manufactured wuhan",
    "concluded covid leaked wuhan lab",
    "coronavirus created united states china",
    "air comes china import coronavirus",
    "coronavirus released china"
  )) |>
  filter(language == "en") |>
  filter(label == "misinformation")

table(covid_wuhan_misinfo$keywords)
table(covid_wuhan_misinfo$cluster_keywords)

```

## Create SNA data

This network reflects the co-dissemination behavior of misinformation retweeters and their mutual social connections. While the true transmission paths are unknown, this co-spreader network allows us to model the structural properties and potential information diffusion routes among these users.

边类型	网络层	分析目标
co-retweet	Layer 1	传播链路，信息扩散路径
co-reply	Layer 2	互动讨论，情感交流
co-quote	Layer 3	引用传播，立场表达

### Co-retweet

The `co-retweet` network captures the relationship between users who have both retweeted the same misinformation tweet. In this network, a tie is created between two users if they co-retweeted the same piece of misinformation tweet. The edge weight indicates how many misinformation tweets the two users co-retweeted together. This structure reflects patterns of coordinated or shared interest in misinformation content, and is often used to analyze the spread dynamics and clustering behavior of misinformation propagation.

```{r}
# 获取 misinformation tweet ID
misinfo_tweet_id <- unique(covid_wuhan_misinfo$tweet_id)

# 保留转发这些 tweet 的所有 retweeter-pair（共传播者）
co_retweet_edges <- user_retweet |> 
  filter(tgt %in% misinfo_tweet_id) |> 
  rename(tweet_id = tgt, retweeter_id = src) |> 
  group_by(tweet_id) |> 
  summarise(
    pairs = list(as.data.frame(t(combn(retweeter_id, 2)))), 
    .groups = "drop"
  ) |> 
  unnest(pairs) |> 
  mutate(
    user_1 = pmin(V1, V2),  # 保持小的 ID 在前
    user_2 = pmax(V1, V2)   # 大的 ID 在后
  ) |> 
  select(user_1, user_2) |> 
  group_by(user_1, user_2) |> 
  summarise(weight = n(), .groups = "drop") |> 
  mutate(type = "co-retweet") |>
  filter(user_1 != user_2) |>
  mutate(
    user_1 = as.character(user_1),
    user_2 = as.character(user_2)
  )


# Step 1: Create initial matrix
adj_matrix_co_retweet <- acast(
  co_retweet_edges, 
  user_1 ~ user_2, 
  value.var = "weight", 
  fill = 0
)

# Step 2: Get full user list
all_users <- sort(unique(c(co_retweet_edges$user_1, co_retweet_edges$user_2)))

# Step 3: Add missing rows and columns with zeros
missing_rows <- setdiff(all_users, rownames(adj_matrix_co_retweet))
missing_cols <- setdiff(all_users, colnames(adj_matrix_co_retweet))

if (length(missing_rows) > 0) {
  adj_matrix_co_retweet <- rbind(
    adj_matrix_co_retweet, 
    matrix(0, nrow = length(missing_rows), ncol = ncol(adj_matrix_co_retweet), 
           dimnames = list(missing_rows, colnames(adj_matrix_co_retweet)))
  )
}

if (length(missing_cols) > 0) {
  adj_matrix_co_retweet <- cbind(
    adj_matrix_co_retweet, 
    matrix(0, nrow = nrow(adj_matrix_co_retweet), ncol = length(missing_cols), 
           dimnames = list(rownames(adj_matrix_co_retweet), missing_cols))
  )
}

# Step 4: Reorder to ensure rows and columns match
adj_matrix_co_retweet <- adj_matrix_co_retweet[all_users, all_users]

write.csv(adj_matrix_co_retweet, "data/adj_matrix_co_retweet.csv", row.names = TRUE)

ncol(adj_matrix_co_retweet)
nrow(adj_matrix_co_retweet)
```
### Co-quote

The `Co-quote` adjacency matrix captures the relationship between users who co-engaged with misinformation through the quoting function on Twitter. Specifically, two users are connected if one quoted a misinformation-related tweet and the other either quoted the same tweet or was the author of that quoted tweet. This interaction reflects a more deliberate and explicit form of engagement with misinformation content, often involving commentary or amplification.

The matrix is weighted based on the number of times each user pair engaged in co-quoting behavior. Diagonal elements (self-loops) are removed, and the matrix is fully completed to ensure that all users appear in both rows and columns, enabling comprehensive analysis of the co-quote network structure.


我们能确定关系的是retweeter of quoting tweet和retweeter of quoted tweet之间的关系

Co-Quote：
A retweeted 了某个 quoting tweet（引用了一条 misinformation tweet 的 tweet）。

B retweeted 了被引用的那条 misinformation tweet。

→ 连 A 和 B。

现实意义：

A 通过 retweet 了一个引用谣言的内容，参与了围绕谣言的传播和讨论。

B 直接 retweet 了这个谣言。

他们都围绕着同一 misinformation 内容参与了传播，但路径不同。


```{r}
# Co-Quote Edges
co_quote_edges <- read_csv("data/mumin_csv/reply_quote_of_tweet.csv") |>
  filter(tgt %in% misinfo_tweet_id | src %in% misinfo_tweet_id) |> 
  rename(
    quoted_tweet_id = tgt,    # 被引用的 tweet
    quoting_tweet_id = src    # 发起引用的 tweet
  ) |> 
  # 找 quoting tweet 是谁 retweeted 的（即 quoting user）
  left_join(retweet_map, by = c("quoting_tweet_id" = "tweet_id")) |> 
  rename(quoting_user = retweeter_id) |> 
  # 找 quoted tweet 是谁 retweeted 的（即 quoted user）
  left_join(retweet_map, by = c("quoted_tweet_id" = "tweet_id")) |> 
  rename(quoted_user = retweeter_id) |> 
  filter(!is.na(quoting_user) & !is.na(quoted_user)) |> 
  mutate(
    user_1 = pmin(quoting_user, quoted_user),
    user_2 = pmax(quoting_user, quoted_user)
  ) |> 
  select(user_1, user_2) |> 
  group_by(user_1, user_2) |> 
  summarise(weight = n(), .groups = "drop") |> 
  mutate(type = "co-quote") |> 
  mutate(type = "co-quote") |>
  filter(user_1 != user_2) |>
  mutate(
    user_1 = as.character(user_1),
    user_2 = as.character(user_2)
  )

# Step 1: 获取完整 retweeter 列表（包含有无 co-quote 行为的）
all_retweeters <- unique(c(
  covid_wuhan_misinfo$retweeter_id,  # 核心传播者
  co_quote_edges$user_1, 
  co_quote_edges$user_2
)) %>% 
  as.character() %>% 
  sort()

# Step 2: 创建完整矩阵
adj_matrix_co_quote <- acast(
  co_quote_edges, 
  user_1 ~ user_2, 
  value.var = "weight", 
  fill = 0
)

# Step 3: 添加缺失行和列
missing_rows <- setdiff(all_retweeters, rownames(adj_matrix_co_quote))
missing_cols <- setdiff(all_retweeters, colnames(adj_matrix_co_quote))

if (length(missing_rows) > 0) {
  adj_matrix_co_quote <- rbind(
    adj_matrix_co_quote, 
    matrix(0, nrow = length(missing_rows), ncol = ncol(adj_matrix_co_quote), 
           dimnames = list(missing_rows, colnames(adj_matrix_co_quote)))
  )
}

if (length(missing_cols) > 0) {
  adj_matrix_co_quote <- cbind(
    adj_matrix_co_quote, 
    matrix(0, nrow = nrow(adj_matrix_co_quote), ncol = length(missing_cols), 
           dimnames = list(rownames(adj_matrix_co_quote), missing_cols))
  )
}

# Step 4: 确保矩阵对齐
adj_matrix_co_quote <- adj_matrix_co_quote[all_retweeters, all_retweeters]

# 保存为 CSV
write.csv(adj_matrix_co_quote, "data/adj_matrix_co_quote.csv", row.names = TRUE)


nrow(adj_matrix_co_quote)
ncol(adj_matrix_co_quote)

```

### Co-reply

我们能确定关系的是retweeter of replying tweet和retweeter of replyed tweet之间的关系

A retweeted 了一个 replying tweet（对一条 misinformation tweet 进行了 reply 的 tweet）。

B retweeted 了被 reply 的那条 misinformation tweet。

→ 连 A 和 B。

现实意义：

A 通过 retweet 了一个 reply 帖子，参与了围绕 misinformation 的讨论链。

B 是直接的传播者。

他们是围绕相同 misinformation 内容的 间接传播参与者。

#### co_reply_edges Explanation (General Co-Reply Network)
This adjacency matrix captures the co-reply relationship between users who have engaged with each other via the reply function on Twitter in the context of misinformation.
In this network, two users are connected if:

One replied to a tweet, and

The other either replied to the same tweet or authored the replied tweet.

However, due to limitations in the dataset (missing tweet author information), this matrix primarily reflects shared engagement with the same tweet rather than direct author-replier relationships.

Note: In this case, no edges were detected, possibly because the retweeters of misinformation tweets did not participate significantly in reply activities.

```{r}
# Co-reply
co_reply_edges <- read_csv("data/mumin_csv/reply_reply_to_tweet.csv") |>
  filter(tgt %in% misinfo_tweet_id | src %in% misinfo_tweet_id) |> 
  rename(
    replied_tweet_id = tgt, 
    replying_tweet_id = src
  ) |> 
  # 找出两条 tweet 各自的 retweeter
  left_join(retweet_map, by = c("replied_tweet_id" = "tweet_id")) |> 
  rename(user_replied = retweeter_id) |> 
  left_join(retweet_map, by = c("replying_tweet_id" = "tweet_id")) |> 
  rename(user_replying = retweeter_id) |> 
  filter(!is.na(user_replied) & !is.na(user_replying)) |> 
  mutate(
    user_1 = pmin(user_replied, user_replying),
    user_2 = pmax(user_replied, user_replying)
  ) |> 
  select(user_1, user_2) |> 
  group_by(user_1, user_2) |> 
  summarise(weight = n(), .groups = "drop") |> 
  mutate(type = "co-reply")

table(co_reply_edges$weight)

reply_data <- read_csv("data/mumin_csv/reply_reply_to_tweet.csv")
sum(reply_data$src %in% retweet_map$tweet_id)  # 有多少 replying tweets 被 retweeted？
sum(reply_data$tgt %in% retweet_map$tweet_id)  # 有多少 replied tweets 被 retweeted？


```

#### co_reply_edges_v2 Explanation (Focused Co-Reply on Misinformation Tweets)
This adjacency matrix focuses exclusively on replies to misinformation tweets.
It captures the relationship between users who retweeted the same misinformation tweet and also replied to it.

In this network, two users are connected if they both retweeted a misinformation tweet and subsequently replied to that tweet or engaged in discussions around it.

This captures shared attention and engagement specifically around misinformation content, providing insight into how users might form conversational clusters around these topics.

```{r}
co_reply_edges_v2 <- read_csv("data/mumin_csv/reply_reply_to_tweet.csv") |>
  filter(tgt %in% misinfo_tweet_id) |>  # 被 reply 的 tweet 是 misinformation
  rename(replied_tweet_id = tgt) |> 
  # 找出这个 misinformation tweet 被谁 retweeted 过
  left_join(retweet_map, by = c("replied_tweet_id" = "tweet_id")) |>
  rename(user_replied = retweeter_id) |> 
  filter(!is.na(user_replied)) |> 
  group_by(replied_tweet_id) |> 
  summarise(
    pairs = list(as.data.frame(t(combn(user_replied, 2)))), 
    .groups = "drop"
  ) |> 
  unnest(pairs) |> 
  mutate(
    user_1 = pmin(V1, V2),
    user_2 = pmax(V1, V2)
  ) |> 
  select(user_1, user_2) |> 
  group_by(user_1, user_2) |> 
  summarise(weight = n(), .groups = "drop") |> 
  mutate(type = "co-reply-v2")  |>
  filter(user_1 != user_2) |>
  mutate(
    user_1 = as.character(user_1),
    user_2 = as.character(user_2)
  )

# Step 1: 定义所有 retweeters（包括参与和未参与 reply 的）
all_retweeters_reply <- unique(c(
  covid_wuhan_misinfo$retweeter_id,  # 核心传播者
  co_reply_edges_v2$user_1, 
  co_reply_edges_v2$user_2
)) %>% 
  as.character() %>% 
  sort()

# Step 2: 创建 Adjacency Matrix
adj_matrix_co_reply_v2 <- acast(
  co_reply_edges_v2, 
  user_1 ~ user_2, 
  value.var = "weight", 
  fill = 0
)

# Step 3: 确保矩阵包含所有 retweeters
missing_rows <- setdiff(all_retweeters_reply, rownames(adj_matrix_co_reply_v2))
missing_cols <- setdiff(all_retweeters_reply, colnames(adj_matrix_co_reply_v2))

if (length(missing_rows) > 0) {
  adj_matrix_co_reply_v2 <- rbind(
    adj_matrix_co_reply_v2, 
    matrix(0, nrow = length(missing_rows), ncol = ncol(adj_matrix_co_reply_v2), 
           dimnames = list(missing_rows, colnames(adj_matrix_co_reply_v2)))
  )
}

if (length(missing_cols) > 0) {
  adj_matrix_co_reply_v2 <- cbind(
    adj_matrix_co_reply_v2, 
    matrix(0, nrow = nrow(adj_matrix_co_reply_v2), ncol = length(missing_cols), 
           dimnames = list(rownames(adj_matrix_co_reply_v2), missing_cols))
  )
}

# Step 4: Reorder to ensure rows and columns match
adj_matrix_co_reply_v2 <- adj_matrix_co_reply_v2[all_retweeters_reply, all_retweeters_reply]

# Step 5: 保存 CSV
write.csv(adj_matrix_co_reply_v2, "data/adj_matrix_co_reply_v2.csv", row.names = TRUE)

nrow(adj_matrix_co_reply_v2)
ncol(adj_matrix_co_reply_v2)


```

This step ensures that the adjacency matrix fully represents the social structure by including all users who participated in the retweet network, regardless of their direct involvement in reply behaviors.

Users who did not engage in replying are represented as isolated nodes (zero rows and columns), preserving the completeness of the network for structural analysis.


### Follow

#### Undirected follow

This edge represents an undirected tie between any two users who are both retweeters of misinformation tweets and have a recorded follower-followee relationship in either direction. However, the relationship is not necessarily mutual. It simply captures the existence of a connection in the follower network among the misinformation retweeters, regardless of direction.

src（user_a）是follower，tgt（user_b）是followee。

filter(user_a %in% retweeter_id_misinfo & user_b %in% retweeter_id_misinfo)：
→ 表示这条边仅要求双方都是 retweeters，不要求他们互相关注。

pmin/pmax 是为了去掉方向性，把边转成无向的。

这不是 mutual follow（互相关注），而是只要 follower 和 followee 都是 retweeter，就创建一条无向边。

```{r}
# Follow
# 获取 retweeter 列表
retweeter_id_misinfo <- unique(covid_wuhan_misinfo$retweeter_id)

# 构造 Follow 边
retweeter_follow_edges <- read_csv("data/mumin_csv/user_follows_user.csv") |>
  rename(user_a = src, user_b = tgt) |> 
  # 保留两者都在 retweeter 列表中的记录
  filter(user_a %in% retweeter_id_misinfo & user_b %in% retweeter_id_misinfo) |> 
  mutate(
    user_1 = pmin(user_a, user_b),  # 保持小的 ID 在前，去掉方向性
    user_2 = pmax(user_a, user_b)
  ) |> 
  select(user_1, user_2) |> 
  distinct() |>  # 去重，防止重复记录 A -> B 和 B -> A
  mutate(weight = 1, type = "follow")

retweeter_follow_edges

```

all 0 matrix:

```{r}
# 获取所有 retweeters
all_retweeters <- sort(unique(c(
  covid_wuhan_misinfo$retweeter_id, 
  retweeter_follow_edges$user_1, 
  retweeter_follow_edges$user_2
))) %>% as.character()

# 创建全 0 矩阵
adj_matrix_follow <- matrix(
  0, 
  nrow = length(all_retweeters), 
  ncol = length(all_retweeters),
  dimnames = list(all_retweeters, all_retweeters)
)

# 转成数据框导出
write.csv(adj_matrix_follow, "data/adj_matrix_follow.csv", row.names = TRUE)

```

#### Directed follow

This edge preserves the directionality of follower relationships between misinformation retweeters (e.g., User A follows User B). It allows for modeling influence flow and assessing asymmetric structures (e.g., hubs or hierarchies) in the spread of misinformation.

follower → followee 表示单向的关注。

同样地，只要两者都在 retweeter 列表中，就保留这个方向性关系。

这是真正的 directed edge，表示“谁关注了谁”，方向性保留。

```{r}
retweeter_follow_edges_directed <- read_csv("data/mumin_csv/user_follows_user.csv") |> 
  rename(follower = src, followee = tgt) |> 
  # 只保留 retweeter 之间的关注关系（有方向）
  filter(follower %in% retweeter_id_misinfo & followee %in% retweeter_id_misinfo) |> 
  mutate(
    weight = 1,          # 默认权重为 1
    type = "follow_directed"      # 明确说明是关注关系
  ) |> 
  select(follower, followee, weight, type)

```


```{r}
follow_data<-read_csv("data/mumin_csv/user_follows_user.csv") 
sum(follow_data$src %in% covid_wuhan_misinfo$retweeter_id)
sum(follow_data$tgt %in% covid_wuhan_misinfo$retweeter_id)

sum(covid_wuhan_misinfo$retweeter_id%in% follow_data$src)
sum(covid_wuhan_misinfo$retweeter_id%in% follow_data$tgt)
```



# Analysis

## Co-retweet Net

```{r}
# 读取 co-retweet adjacency matrix
adj_matrix_co_retweet <- read.csv("data/adj_matrix_co_retweet.csv", row.names = 1)

# 构建 network 对象（无向图）
net_co_retweet <- network(as.matrix(adj_matrix_co_retweet), directed = FALSE, matrix.type = "adjacency")


# 获取分组信息
retweeter_group <- covid_wuhan_misinfo %>%
  select(retweeter_id, date, keywords) %>%
  distinct() %>%
  arrange(date) %>%
  mutate(group = as.numeric(factor(paste(date, keywords), levels = unique(paste(date, keywords)))))

# 将 Group 信息添加到节点属性中
set.vertex.attribute(
  net_co_retweet, 
  "group", 
  retweeter_group$group[match(get.vertex.attribute(net_co_retweet, "vertex.names"), retweeter_group$retweeter_id)]
)



for (g in group_stages) {
  subgraph_nodes <- which(get.vertex.attribute(net_co_retweet, "group") <= g)
  
  if (length(subgraph_nodes) == 0) next  # 没有节点直接跳过
  
  sub_g <- get.inducedSubgraph(net_co_retweet, v = subgraph_nodes)
  
  plot.network(
    sub_g,
    displaylabels = FALSE,
    vertex.cex = 2,
    vertex.col = "skyblue",
    main = paste("Co-Retweet Network - Stage", g)
  )
  
  Sys.sleep(1)  # 每张图停留 1 秒
}


# 获取所有 group 阶段
group_stages <- sort(unique(get.vertex.attribute(net_co_retweet, "group")))


```

## Node Attributes  

```{r}
covid_wuhan_misinfo |>
  group_by(date, keywords) |>
  select(keywords, date) |>
  unique()|>
  arrange(date)

# 获取每个 retweeter 最早转发的 misinformation claim 的日期和关键词
# 按日期和关键词组合编码分组
retweeter_group <- covid_wuhan_misinfo %>%
  select(retweeter_id, date, keywords) %>%
  distinct() %>%
  arrange(date) |>
  mutate(group = as.numeric(factor(paste(date, keywords), 
                                   levels = unique(paste(date, keywords)))))

# 把 group 属性添加到 network 对象中
set.vertex.attribute(net, "group", 
            retweeter_group$group[match(get.vertex.attribute(net, "vertex.names"),                  retweeter_group$retweeter_id)])



# 选出 group == 1 的子图
subgraph_1 <- get.inducedSubgraph(net, 
                                  which(get.vertex.attribute(net, "group") == 1))

# 作图
plot.network(subgraph_1, 
              displaylabels = FALSE, 
              vertex.cex = 2, 
              vertex.col = "skyblue", 
              main = "Subgraph for Group 1")

for (g in 1:6) {
  sub_g <- get.inducedSubgraph(net, 
                               which(get.vertex.attribute(net, "group") == g))
  plot.network(sub_g, 
                displaylabels = FALSE, 
                vertex.cex = 2, 
                vertex.col = "skyblue", 
                main = paste("Subgraph for Group", g))
}

# 例如，group 1-3 是早期阶段，4-6 是后期阶段
early_phase <- get.inducedSubgraph(net, 
                                   which(get.vertex.attribute(net, "group") %in% 1:3))

late_phase <- get.inducedSubgraph(net, 
                                  which(get.vertex.attribute(net, "group") %in% 4:6))

# 分别作图
plot.network(early_phase, main = "Early Phase")
plot.network(late_phase, main = "Late Phase")

```



```{r}

# 逐个作图
plot.network(
  net,
  displaylabels = FALSE,
  vertex.cex = 0.2,
  vertex.col = "orange",
  edge.lwd = 0.5,  # 调小边的宽度
  edge.col = ifelse(get.edge.attribute(net, "co-retweet"), 
                    adjustcolor("red", alpha.f = 0.2),  # 更透明的红色
                    "gray95"),  # 不关注的边几乎看不到
  main = "Network with co-retweet Edges"
)

# 2. 换成 co-quote 的边
plot.network(
  net,
  displaylabels = FALSE,
  vertex.cex = 0.2,
  vertex.col = "orange",
  edge.lwd = 1,
  edge.col = ifelse(get.edge.attribute(net, "co-quote"), 
                    adjustcolor("blue", alpha.f = 0.3), 
                    "gray95"),
  main = "Network with co-quote Edges"
)


# 3. 再换 co-reply-v2
plot.network(
  net,
  displaylabels = FALSE,
  vertex.cex = 0.2,
  vertex.col = "orange",
  edge.lwd = 1,
  edge.col = ifelse(get.edge.attribute(net, "co-reply-v2"), 
                    adjustcolor("green", alpha.f = 0.3), 
                    "gray95"),
  main = "Network with co-reply-v2 Edges"
)

plot.network(
  net,
  displaylabels = FALSE,
  vertex.cex = 0.1,  # 调小节点
  vertex.col = "orange",
  edge.lwd = 0.5,  # 调细边
  edge.col = "gray80",
  edge.transparency = 0.5,  # 增加透明度（statnet中用 adjustcolor() 处理颜色）
  main = "Network with co-retweet Edges"
)


```

# Reference


# Appendix

Raw dataset download link: <https://data.bristol.ac.uk/data/en_GB/dataset/23yv276we2mll25fjakkfim2ml/resource/e63a98c4-b4d6-4a89-9be9-06875b83ce33?inner_span=True>

把这些文件下载完之后,创建一个data file,放在这个文件夹中

下载完数据后，我们要到指引处<https://colab.research.google.com/drive/1JCjgg3moGBOuZk4iVjBpQNqgsAYFyNoS#scrollTo=YS1uxj-59UmA>
按照引导 打开shell 用pip安装相关的文件

我们需要打开vs code，在python文件中运行：

```{python}
#| eval: false
#| include: true

import pandas as pd
import os

input_dir = "data/mumin"
output_dir = "data/mumin_csv"
os.makedirs(output_dir, exist_ok=True)

file_names = [
    "claim",
    "user",
    "tweet",
    "reply",
    "article",
    "tweet_discusses_claim",
    "article_discusses_claim",
    "user_follows_user",
    "user_retweeted_tweet",
    "reply_quote_of_tweet",
    "reply_reply_to_tweet"
]

for name in file_names:
    input_path = os.path.join(input_dir, name)
    output_path = os.path.join(output_dir, f"{name}.csv")
    try:
        df = pd.read_pickle(input_path, compression="xz")
        df.to_csv(output_path, index=False)
        print(f"Saved: {output_path}")
    except Exception as e:
        print(f"Failed to convert {name}: {e}")


```

这样我们就能得到csv文件

Take a glimpse of data:

```{r}
#| eval: false
#| include: true
# 设置数据路径（请替换为你自己电脑上的路径）
data_path <- "data/mumin_csv/"

# 定义要读取的文件列表
files <- c(
  "claim.csv", "user.csv", "tweet.csv", "reply.csv", "article.csv",
  "tweet_discusses_claim.csv", "article_discusses_claim.csv",
  "user_follows_user.csv", "user_retweeted_tweet.csv",
  "reply_quote_of_tweet.csv", "reply_reply_to_tweet.csv"
)

# 用lapply预览前几行（避免爆内存）
previews <- lapply(files, function(fname) {
  fpath <- file.path(data_path, fname)
  tryCatch(
    read_csv(fpath, n_max = 5),
    error = function(e) tibble::tibble(error = paste("Error:", e$message))
  )
})

names(previews) <- files

```

```{=html}
<script>
document.addEventListener("DOMContentLoaded", function() {
    const toc = document.getElementById("TOC");
    if (toc) {
        const sourceLink = document.createElement("div");
        sourceLink.innerHTML = `
            <div class="toc-source">
                <a href="https://github.com/troy-yu-cheng/sna-final-paper" 
                   target="_blank" 
                   class="github-button">
                   <svg xmlns="http://www.w3.org/2000/svg" 
                        viewBox="0 0 24 24" 
                        width="16" 
                        height="16" 
                        fill="currentColor"
                        style="vertical-align: middle; margin-right: 5px;">
                     <path d="M12 0C5.373 0 0 5.373 0 12c0 5.303 3.438 9.8 8.207 11.387.6.113.82-.26.82-.577v-2.157c-3.338.726-4.033-1.416-4.033-1.416-.546-1.386-1.332-1.756-1.332-1.756-1.09-.745.083-.73.083-.73 1.205.084 1.84 1.237 1.84 1.237 1.07 1.832 2.807 1.303 3.492.996.108-.774.418-1.303.76-1.602-2.665-.3-5.466-1.332-5.466-5.93 0-1.311.468-2.382 1.237-3.222-.124-.302-.536-1.52.118-3.163 0 0 1.008-.322 3.3 1.23a11.516 11.516 0 0 1 3.002-.403 11.486 11.486 0 0 1 3.002.403c2.292-1.552 3.3-1.23 3.3-1.23.654 1.644.242 2.861.118 3.163.77.84 1.236 1.911 1.236 3.222 0 4.61-2.807 5.627-5.48 5.922.43.372.812 1.103.812 2.222v3.293c0 .321.218.694.825.576C20.565 21.796 24 17.3 24 12 24 5.373 18.627 0 12 0z"/>
                   </svg>
                   View source
                </a>
            </div>
        `;
        toc.appendChild(sourceLink);
    }
});
</script>
```

