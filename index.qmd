---
title: "Social Network Analysis"
subtitle: "Temporal Patterns of Misinformation Diffusion: A Multi-Stage Network Analysis of COVID-19 Origin Narratives on Twitter"
author: 
  - name: "Troy (Yu) Cheng"
    email: yc1317@georgetown.edu
    affiliation: Georgetown University
    corresponding: true
df-print: kable
title-block-banner: "#0a0e1a"
title-block-banner-color: "#4DB8FF"
execute:
  warning: false
date: 2025-04-28
date-modified: last-modified
format:
  html:
    embed-resources: true
    toc: true                 
    toc-title: "Contents"     
    toc-location: right       
    number-sections: true
    number-depth: 3       
    smooth-scroll: true       
    css: trycstyle.css 
    code-overflow: wrap
include-in-header:
  text: |
    <link rel="shortcut icon" href="assets/gu.ico" type="image/x-icon">           
highlight-style: nord       
engine: knitr
---

--------

# Abstract

The amplification of misinformation on social media platforms remains a critical concern, particularly when false narratives gain widespread attention through collective user behaviors. While existing research often focuses on individual-level attributes or direct information cascades, less is known about how groups of users jointly contribute to the amplification of misinformation through co-dissemination behaviors.

This study focuses on retweeters of misinformation claims as the core agents of amplification, analyzing how different forms of shared retweeting behavior shape the structural characteristics of retweeter co-dissemination networks associated with misinformation claims. Retweeter nodes are connected through co-dissemination ties based on three distinct behaviors: (1) both retweeters retweeted the same misinformation tweet, (2) both retweeters retweeted misinformation tweet or content quoting it, and (3) both retweeters retweeted misinformation tweet or content replying to it.

By investigating the density, transitivity, and centralization of these networks, this research explores how distinct retweeter behaviors reflect patterns of collective amplification in misinformation networks. The research question guiding this analysis is: How do different co-dissemination behaviors, which are operationalized through direct, quote, and reply co-retweeting, shape the structural characteristics and potential amplification patterns of misinformation retweeter networks?

------

# Introduction

This study examines the temporal diffusion patterns of the misinformation narrative claiming that [COVID-19 was deliberately created/manufactured by China or the Wuhan laboratory](https://en.wikipedia.org/wiki/COVID-19_lab_leak_theory). The central research question asks: How did this narrative propagate across Twitter retweeter networks over time, and did early spreaders maintain structural advantages? Drawing on the Diffusion of Innovations Theory and Echo Chamber Theory, the study explores whether ideological homophily emerged as the narrative spread.

Using data from the [MuMiN](https://mumin-dataset.github.io/) project, six prominent misinformation claims between March 2020 and August 2021 were analyzed. Retweeters are treated as nodes, with ties defined by co-retweeting, co-replying, co-quoting, and following behaviors. The hypothesis posits that retweeters involved in earlier misinformation narratives occupy more central positions and retain higher connectivity over time.

Social Network Analysis (SNA) is employed to construct adjacency matrices, visualize evolving network structures, and compute centrality and modularity metrics. While temporal network growth is discontinuous across misinformation events, this study explores whether Temporal Exponential Random Graph Models (tERGM) can model these episodic formations by treating thematic similarity as a historical tie.

This research advances understanding of how misinformation narratives persist in online environments and how early participants shape long-term information diffusion.


Nodes: Retweeters directly involved in spreading misinformation claims.

Edges: Co-retweeting relationships defined by shared retweeting behaviors:

Direct Co-Retweet: Both retweeters retweeted the same misinformation tweet.

Co-Retweet tweets on quote pathway: Both retweeters retweeted content that quoted the misinformation tweet, or the misinformation tweet itself.

Co-Retweet tweets on reply pathway: Both retweeters retweeted content that replied to the misinformation tweet, or the misinformation tweet itself.



How do retweeter co-dissemination behaviors, operationalized through direct, quote, and reply co-retweeting, differ in their network density and clustering patterns?



# Literature Review

This study is grounded in social contagion theory, which posits that information diffuses through social networks in patterns analogous to viral infections. Additionally, the concept of homophily suggests that misinformation is more likely to spread within communities of like-minded individuals. This research also considers structural hole theory to explore whether a small set of influential users act as bridges, accelerating the spread of misinformation.

# Research Methods



# Data Collection & Graph

## Dataset

This study uses secondary data from the **MuMiN Project** (Multi-platform Misinformation Influence Network), publicly available at: <https://data.bristol.ac.uk/data/en_GB/dataset/23yv276we2mll25fjakkfim2ml/resource/e63a98c4-b4d6-4a89-9be9-06875b83ce33?inner_span=True>

The dataset includes information about social media users, tweets, misinformation claims, and their relational behaviors across various platforms.

## Data Preparation

### Loading Required Packages

```{r}
#| label: set up packages
library(tidyverse)
library(readr)
library(statnet)
library(intergraph)
library(reshape2)
library(btergm)
```

### Loading and Merging Data

```{r}
# Load data
tweets <- read_csv("data/mumin_csv/tweet.csv")
claims <- read_csv("data/mumin_csv/claim.csv")
tweet_claim <- read_csv("data/mumin_csv/tweet_discusses_claim.csv")
user_retweet <- read_csv("data/mumin_csv/user_retweeted_tweet.csv")

# Join tweet & claim via tweet_claim
tweet_claim_joined <- tweet_claim |> 
  rename(tweet_id = src, claim_id = tgt) |> 
  inner_join(claims, by = c("claim_id" = "id"))

# Join retweeters within users & claim via retweeted tweet
user_claim <- user_retweet |> 
  rename(retweeter_id = src, tweet_id = tgt) |> 
  inner_join(tweet_claim_joined, by = "tweet_id")

# Create a mapping of retweeters and tweets
retweet_map <- user_claim |> 
  select(retweeter_id, tweet_id) |> 
  distinct() 

# Basic data overview
table(user_claim$label)
head(table(user_claim$cluster_keywords))
```

### Filtering for Target Misinformation Narratives

This study focuses specifically on misinformation narratives claiming that **COVID-19 was deliberately created or spread by China or the Wuhan laboratory**. The following filtering steps were applied:

1. Filter keywords containing "china" or "wuhan".

2. Manually select misinformation topics directly related to the COVID-19 origin narrative.

3. Restrict the analysis to English-language posts labeled as "misinformation".

**Note: **

```{r}
user_claim_filtered <- user_claim |> 
  filter(str_detect(keywords, "china|wuhan")) 

head(unique(user_claim_filtered$keywords))

# Final filtered dataset
covid_wuhan_misinfo <- user_claim_filtered |>
  filter(keywords %in% c(
    "coronavirus comes biological laboratory wuhan",
    "including corona virus manufactured wuhan",
    "china created spread coronavirus",
    "announced coronavirus artificially created china",
    "china created coronavirus",
    "coronavirus created laboratory china",
    "honjo said china manufactured coronavirus",
    "said new coronavirus manufactured wuhan",
    "coronavirus tested biological weapon china",
    "china testing coronavirus biological weapon",
    "covid 19 lab china",
    "coronavirus natural worked wuhan laboratory",
    "coronavirus manufactured laboratory wuhan specifically",
    "doctor claimed coronavirus china create",
    "corona virus manufactured china",
    "says current coronavirus manufactured wuhan",
    "wuhan coronavirus created patented",
    "covid 19 disease manufactured china",
    "pandemic caused artificial virus china",
    "collaborator assures coronavirus manufactured wuhan",
    "concluded covid leaked wuhan lab",
    "coronavirus created united states china",
    "air comes china import coronavirus",
    "coronavirus released china"
  )) |>
  filter(language == "en") |>
  filter(label == "misinformation")

# Distribution of final misinformation topics
table(covid_wuhan_misinfo$keywords)
table(covid_wuhan_misinfo$cluster_keywords)
```

## Social Network Construction

This network models the co-dissemination behavior of misinformation retweeters. While the exact paths of information transmission are unknown, this co-spreader network captures the structural relationships that may facilitate misinformation diffusion.

### Co-Retweet Network

The `co-retweet` network represents a co-dissemination behavior among retweeters. A tie is created between two users only if they both retweeted the same specific misinformation tweet, which is identified by a shared `tweet_id` in `user_retweeted_tweet.csv` file. Each edge is weighted by the number of such co-retweeting events, reflecting how often the same pair of users jointly retweeted the same pieces of misinformation. Though this relationship does not suggest that a paired users share the same opinion, it captures direct and synchronous amplification of specific misinformation claim in tweets. Therefore, by analyzing the weighted connections among pairs of retweeters, this network checks which retweeters are central to the misinformation amplification/dissemination process, and whether specific communities or cliques form around the repeated propagation of misinformation. 

```{r}
# Extract misinformation-related tweets id
misinfo_tweet_id <- unique(covid_wuhan_misinfo$tweet_id)

# Identify pairs of users who co-retweeted the same misinformation tweet
co_retweet_edges <- user_retweet |> 
  filter(tgt %in% misinfo_tweet_id) |> 
  rename(tweet_id = tgt, retweeter_id = src) |> 
  group_by(tweet_id) |> 
  summarise(
    pairs = list(as.data.frame(t(combn(retweeter_id, 2)))), 
    .groups = "drop"
  ) |> 
  unnest(pairs) |> 
  mutate(
    user_1 = pmin(V1, V2), # Ensure lower ID comes first
    user_2 = pmax(V1, V2) # Ensure higher ID comes second
  ) |> 
  select(user_1, user_2) |> 
  group_by(user_1, user_2) |> 
  summarise(weight = n(), .groups = "drop") |> 
  mutate(type = "co-retweet") |>
  filter(user_1 != user_2) |>
  mutate(
    user_1 = as.character(user_1),
    user_2 = as.character(user_2)
  )

# Obtain the full list of unique users involved
all_retweeters <- unique(c(
  covid_wuhan_misinfo$retweeter_id,  
  co_retweet_edges$user_1, 
  co_retweet_edges$user_2
)) |> 
  as.character() |> 
  sort()

# Create initial matrix
adj_matrix_co_retweet <- acast(
  co_retweet_edges, 
  user_1 ~ user_2, 
  value.var = "weight", 
  fill = 0
)

# Ensure matrix completeness by adding missing rows and columns
missing_rows <- setdiff(all_retweeters, rownames(adj_matrix_co_retweet))
missing_cols <- setdiff(all_retweeters, colnames(adj_matrix_co_retweet))

if (length(missing_rows) > 0) {
  adj_matrix_co_retweet <- rbind(
    adj_matrix_co_retweet, 
    matrix(0, nrow = length(missing_rows), ncol = ncol(adj_matrix_co_retweet), 
           dimnames = list(missing_rows, colnames(adj_matrix_co_retweet)))
  )
}

if (length(missing_cols) > 0) {
  adj_matrix_co_retweet <- cbind(
    adj_matrix_co_retweet, 
    matrix(0, nrow = nrow(adj_matrix_co_retweet), ncol = length(missing_cols), 
           dimnames = list(rownames(adj_matrix_co_retweet), missing_cols))
  )
}

# Reorder the matrix to align rows and columns
adj_matrix_co_retweet <- adj_matrix_co_retweet[all_retweeters, all_retweeters]

# Export the adjacency matrix for further analysis
write.csv(adj_matrix_co_retweet, "data/adj_matrix_co_retweet.csv", row.names = TRUE)

# Check dimensions of the final matrix
ncol(adj_matrix_co_retweet)
nrow(adj_matrix_co_retweet)

table(co_retweet_edges$weight)
```

### Co-Retweet (Quote Pathway)

The **Co-Retweet (Quote Pathway)** Network captures relational ties between users who both engaged in the dissemination (i.e., retweeting) of misinformation content either by a) retweeting original misinformation tweets, or b) retweeting tweets that explicitly quoting misinformation tweets. In this network, a tie is formed between two users if they each retweeted at least one tweet that is either a misinformation tweet or a tweet quoting misinformation pieces. 

```{r}
# Load quote relationships between tweets (quoting tweet & quoted tweet)

quote_relations <- read_csv("data/mumin_csv/reply_quote_of_tweet.csv") |>
  filter(tgt %in% misinfo_tweet_id | src %in% misinfo_tweet_id) |> 
  rename(
    quoted_tweet_id = tgt, # The misinformation tweet being quoted
    quoting_tweet_id = src # The tweet that quotes the misinformation tweet
  )

# Create the complete set of tweets relevant to the quote pathway
quote_path_tweet_ids <- unique(c(
  quote_relations$quoted_tweet_id , # Original misinformation tweets
  quote_relations$quoting_tweet_id # Tweets that quoted misinformation
))

# Find all users who retweeted these tweets
quote_path_retweets <- covid_wuhan_misinfo |> 
  filter(tweet_id %in% quote_path_tweet_ids) 

# Generate co-retweet edges based on shared retweeting of these tweets
co_retweet_quote_path_edges <- quote_path_retweets |>
  group_by(tweet_id) |>
  summarise(
    pairs = list(as.data.frame(t(combn(retweeter_id, 2)))), 
    .groups = "drop"
  ) |>
  unnest(pairs) |>
  mutate(
    user_1 = pmin(V1, V2),
    user_2 = pmax(V1, V2)
  ) |>
  select(user_1, user_2) |>
  group_by(user_1, user_2) |>
  summarise(weight = n(), .groups = "drop") |>
  mutate(type = "co-retweet-quote-path") |>
  filter(user_1 != user_2) |> 
  mutate(
    user_1 = as.character(user_1),
    user_2 = as.character(user_2)
  )

# Prepare full user list
all_retweeters_quote <- unique(c(
  covid_wuhan_misinfo$retweeter_id, 
  co_retweet_quote_path_edges$user_1, 
  co_retweet_quote_path_edges$user_2
)) |> 
  as.character() |> 
  sort()

# Create the adjacency matrix
adj_matrix_co_retweet_quote_path <- acast(
  co_retweet_quote_path_edges, 
  user_1 ~ user_2, 
  value.var = "weight", 
  fill = 0
)

# Add missing rows and columns to complete the matrix
missing_rows <- setdiff(all_retweeters_quote, rownames(adj_matrix_co_retweet_quote_path))
missing_cols <- setdiff(all_retweeters_quote, colnames(adj_matrix_co_retweet_quote_path))

if (length(missing_rows) > 0) {
  adj_matrix_co_retweet_quote_path <- rbind(
    adj_matrix_co_retweet_quote_path, 
    matrix(0, nrow = length(missing_rows), ncol = ncol(adj_matrix_co_retweet_quote_path), 
           dimnames = list(missing_rows, colnames(adj_matrix_co_retweet_quote_path)))
  )
}

if (length(missing_cols) > 0) {
  adj_matrix_co_retweet_quote_path <- cbind(
    adj_matrix_co_retweet_quote_path, 
    matrix(0, nrow = nrow(adj_matrix_co_retweet_quote_path), ncol = length(missing_cols), 
           dimnames = list(rownames(adj_matrix_co_retweet_quote_path), missing_cols))
  )
}

# Ensure matrix symmetry and proper ordering
adj_matrix_co_retweet_quote_path <- adj_matrix_co_retweet_quote_path[all_retweeters_quote, all_retweeters_quote]

# Save the matrix for further analysis
write.csv(adj_matrix_co_retweet_quote_path, "data/adj_matrix_co_retweet_quote_path.csv", row.names = TRUE)

# Output matrix dimensions for verification
nrow(adj_matrix_co_retweet_quote_path)
ncol(adj_matrix_co_retweet_quote_path)

table(co_retweet_quote_path_edges$weight)

```

```{r}
quote_data <-read_csv("data/mumin_csv/reply_quote_of_tweet.csv")

sum(quote_data$src %in% misinfo_tweet_id)

sum(quote_data$tgt %in% misinfo_tweet_id)

sum(misinfo_tweet_id %in% quote_data$tgt)

sum(misinfo_tweet_id %in% c(quote_data$src,quote_data$tgt))

```


### Co-Retweet (Reply Pathway)

The **Co-Retweet (Reply Pathway)** Network captures relational ties between users who both retweeted tweets directly involved in misinformation discussions, either by a) retweeting misinformation tweets themselves, or b) retweeting the tweets that explicitly replied to such misinformation content.

```{r}
# Load reply relationships to identify reply chains around misinformation
reply_relations <- read_csv("data/mumin_csv/reply_reply_to_tweet.csv") |>
  filter(tgt %in% misinfo_tweet_id | src %in% misinfo_tweet_id) |> 
  rename(
    replied_tweet_id = tgt, # The misinformation tweet being replied to
    replying_tweet_id = src # The tweet that replies to the misinformation tweet
  )

# Step 1: Create complete set of tweets involved in reply chains related to misinformation
reply_path_tweet_ids <- unique(c(
  reply_relations$replied_tweet_id, 
  reply_relations$replying_tweet_id
))

# Step 2: Find all users who retweeted these tweets (participating in the reply pathway)
reply_path_retweets <- covid_wuhan_misinfo |> 
  filter(tweet_id %in% reply_path_tweet_ids)

# Step 3: Generate Co-Reply Edges based on shared retweeting of reply-path tweets
co_retweet_reply_path_edges <- reply_path_retweets |>
  group_by(tweet_id) |>
  summarise(
    pairs = list(as.data.frame(t(combn(retweeter_id, 2)))), 
    .groups = "drop"
  ) |>
  unnest(pairs) |>
  mutate(
    user_1 = pmin(V1, V2), 
    user_2 = pmax(V1, V2)
  ) |>
  select(user_1, user_2) |>
  group_by(user_1, user_2) |>
  summarise(weight = n(), .groups = "drop") |>
  mutate(type = "co-retweet-reply-path") |>
  filter(user_1 != user_2) |>
  mutate(
    user_1 = as.character(user_1),
    user_2 = as.character(user_2)
  )

# Prepare full user list
all_retweeters_reply <- unique(c(
  covid_wuhan_misinfo$retweeter_id, 
  co_retweet_reply_path_edges$user_1, 
  co_retweet_reply_path_edges$user_2
)) |> 
  as.character() |> 
  sort()

# Create the adjacency matrix
adj_matrix_co_retweet_reply_path <- acast(
  co_retweet_reply_path_edges, 
  user_1 ~ user_2, 
  value.var = "weight", 
  fill = 0
)

# Add missing rows and columns to complete the matrix
missing_rows <- setdiff(all_retweeters_reply, rownames(adj_matrix_co_retweet_reply_path))
missing_cols <- setdiff(all_retweeters_reply, colnames(adj_matrix_co_retweet_reply_path))

if (length(missing_rows) > 0) {
  adj_matrix_co_retweet_reply_path <- rbind(
    adj_matrix_co_retweet_reply_path, 
    matrix(0, nrow = length(missing_rows), ncol = ncol(adj_matrix_co_retweet_reply_path), 
           dimnames = list(missing_rows, colnames(adj_matrix_co_retweet_reply_path)))
  )
}

if (length(missing_cols) > 0) {
  adj_matrix_co_retweet_reply_path <- cbind(
    adj_matrix_co_retweet_reply_path, 
    matrix(0, nrow = nrow(adj_matrix_co_retweet_reply_path), ncol = length(missing_cols), 
           dimnames = list(rownames(adj_matrix_co_retweet_reply_path), missing_cols))
  )
}

# Ensure matrix symmetry and proper ordering
adj_matrix_co_retweet_reply_path <- adj_matrix_co_retweet_reply_path[all_retweeters_reply, all_retweeters_reply]

# Save the matrix for further analysis
write.csv(adj_matrix_co_retweet_reply_path, "data/adj_matrix_co_retweet_reply_path.csv", row.names = TRUE)

# Output matrix dimensions for verification
nrow(adj_matrix_co_retweet_reply_path)
ncol(adj_matrix_co_retweet_reply_path)

table(co_retweet_reply_path_edges$weight)
```

### Follow

A directed edge from User A to User B indicates that User A follows User B. This network captures the potential flow of influence among misinformation retweeters and allows for the identification of opinion leaders and hierarchical structures in misinformation diffusion.

```{r}
# Load retweeter list
retweeter_id_misinfo <- unique(covid_wuhan_misinfo$retweeter_id)

# Load and filter directed follow edges
retweeter_follow_edges_directed <- read_csv("data/mumin_csv/user_follows_user.csv") |> 
  rename(follower = src, followee = tgt) |> 
  filter(follower %in% retweeter_id_misinfo & followee %in% retweeter_id_misinfo) |> 
  mutate(weight = 1, type = "follow_directed") |> 
  select(follower, followee, weight, type)

# Check if any edges exist
if (nrow(retweeter_follow_edges_directed) == 0) {
  message("No directed follow relationships found among misinformation retweeters.")
} else {
  # Create adjacency matrix
  all_retweeters <- sort(unique(c(
    covid_wuhan_misinfo$retweeter_id, 
    retweeter_follow_edges_directed$follower, 
    retweeter_follow_edges_directed$followee
  ))) |> as.character()

  adj_matrix_follow_directed <- matrix(
    0, 
    nrow = length(all_retweeters), 
    ncol = length(all_retweeters),
    dimnames = list(all_retweeters, all_retweeters)
  )

  # Fill matrix with edges
  apply(retweeter_follow_edges_directed, 1, function(row) {
    adj_matrix_follow_directed[row["follower"], row["followee"]] <<- 1
  })

  # Save matrix
  write.csv(adj_matrix_follow_directed, "data/adj_matrix_follow_directed.csv", row.names = TRUE)
}
```

Analysis of the follower network among misinformation retweeters revealed no recorded follower-followee relationships within this group. This indicates that users involved in the dissemination of COVID-19 origin misinformation acted largely as isolated agents rather than as members of a tightly connected social network. Such a pattern suggests that the spread of misinformation in this case was driven primarily by content virality and opportunistic engagement, rather than through established social ties or influencer-led dissemination.


# Analysis

## Visualization

### Co-retweet Net

#### Stage 1 Plot (Co-retweet Net)

```{r}
#| output: false
# Load Data and Build Full Network
adj_matrix <- read.csv("data/adj_matrix_co_retweet.csv", row.names = 1, check.names = FALSE)

net_full <- network(as.matrix(adj_matrix), directed = FALSE, matrix.type = "adjacency")

retweeter_stage <- covid_wuhan_misinfo |>
  mutate(retweeter_id = as.character(retweeter_id)) |>
  select(retweeter_id, date, keywords) |>
  distinct() |>
  arrange(date) |>
  mutate(
    group = as.numeric(factor(paste(date, keywords), levels = unique(paste(date, keywords))))
  ) |>
  select(retweeter_id, group, date, keywords)

node_names <- net_full %v% "vertex.names"

assigned_groups <- retweeter_stage$group[match(node_names, retweeter_stage$retweeter_id)]

set.vertex.attribute(net_full, "group", assigned_groups)

# Assign Current Stage Info
target_group <- 1  

stage_info <- retweeter_stage |> 
  filter(group == target_group) |> 
  distinct(date, keywords)

stage_date <- unique(stage_info$date)

stage_keywords <- unique(stage_info$keywords)

# Get Edge List and Filter Edges for Current Stage
edgelist <- as.edgelist(net_full)
v1 <- edgelist[, 1]
v2 <- edgelist[, 2]

group_v1 <- assigned_groups[v1]
group_v2 <- assigned_groups[v2]
keep_edges <- which(group_v1 == target_group & group_v2 == target_group)

# Build Stage Adjacency Matrix
adj_stage1 <- matrix(0, nrow = length(node_names), ncol = length(node_names))
rownames(adj_stage1) <- colnames(adj_stage1) <- node_names

if (length(keep_edges) > 0) {
  for (idx in keep_edges) {
    adj_stage1[v1[idx], v2[idx]] <- 1
    adj_stage1[v2[idx], v1[idx]] <- 1
  }
}

# Save Stage 1 Adjacency Matrix
write.csv(adj_stage1, "data/adj_matrix_stage1.csv", row.names = TRUE)

# Build Network Object for Stage 1
net_stage1 <- network(adj_stage1, directed = FALSE, matrix.type = "adjacency")

# Visualization Settings
plot_title <- paste0("Co-Retweet Network: Stage ", target_group)

plot_subtitle <- paste0("Misinformation Claim: ", stage_keywords, " | Claim Uttered on: ", stage_date)

edge_alpha <- 0.1 
edge_width <- 0.2  

set.seed(42)
layout_coords <- gplot(
  net_stage1, 
  gmode = "graph", 
  mode = "kamadakawai"
)
```
```{r}
vertex_colors <- ifelse(
  assigned_groups == target_group, 
  "steelblue", 
  "gray"
)

# Save PNG
png("plot/co_retweet_net/Co-Retweet-Stage1.png", width = 2200, height = 2100, res = 300)
par(family = "serif", mar = c(6, 0, 3, 1))

plot.network(
  net_stage1,
  displaylabels = FALSE,
  vertex.cex = 1,
  vertex.col = vertex_colors,
  coord = layout_coords,
  edge.lwd = edge_width,
  edge.col = adjustcolor("black", alpha.f = edge_alpha),
  main = plot_title
)

# Add Subtitle
mtext(
  text = plot_subtitle,
  side = 1, 
  line = 3, 
  cex = 0.8, 
  family = "serif"
)

# Add Data Source as Footer Note
mtext(
  text = "Data Source: MuMiN Dataset (https://data.bristol.ac.uk/data/en_GB/dataset/23yv276we2mll25fjakkfim2ml)", 
  side = 1, 
  line = 4.2,
  cex = 0.6, 
  family = "serif"
)

# Add Legend
legend(
  "right",
  legend = c("Stage 1 Retweeters", "Other Retweeters"), 
  col = c("steelblue", "gray"), 
  pch = 19, 
  pt.cex = 1,  
  cex = 0.6,                    
  text.col = "black", 
  bty = "n",                    
  y.intersp = 1.5                      
)
```

#### Stage 2 Plot (Co-retweet Net)

```{r}
#| output: false
# Assign Current Stage Info
target_group <- 2  

stage_info <- retweeter_stage |> 
  filter(group == target_group) |> 
  distinct(date, keywords)

stage_date <- unique(stage_info$date)
stage_keywords <- unique(stage_info$keywords)

# Get Edge List and Filter Edges for Current Stage
group_v1 <- assigned_groups[v1]
group_v2 <- assigned_groups[v2]
keep_edges <- which(group_v1 == target_group & group_v2 == target_group)

# Build Stage 2 Adjacency Matrix
adj_stage2 <- matrix(0, nrow = length(node_names), ncol = length(node_names))
rownames(adj_stage2) <- colnames(adj_stage2) <- node_names

if (length(keep_edges) > 0) {
  for (idx in keep_edges) {
    adj_stage2[v1[idx], v2[idx]] <- 1
    adj_stage2[v2[idx], v1[idx]] <- 1
  }
}

# Save Stage 2 Adjacency Matrix
write.csv(adj_stage2, "data/adj_matrix_stage2.csv", row.names = TRUE)

# Build Network Object for Stage 2
net_stage2 <- network(adj_stage2, directed = FALSE, matrix.type = "adjacency")

# Visualization Settings
plot_title <- paste0("Co-Retweet Network: Stage ", target_group)
plot_subtitle <- paste0("Misinformation Claim: ", stage_keywords, " | Claim Uttered on: ", stage_date)

edge_alpha <- 0.1 
edge_width <- 0.2  

set.seed(42)
layout_coords <- gplot(
  net_stage2, 
  gmode = "graph", 
  mode = "kamadakawai"
)
```
```{r}
vertex_colors <- ifelse(
  assigned_groups == target_group, 
  "steelblue", 
  "gray"
)

# Save PNG for Stage 2
png("plot/co_retweet_net/Co-Retweet-Stage2.png", width = 2200, height = 2100, res = 300)
par(family = "serif", mar = c(6, 0, 3, 1))

plot.network(
  net_stage2,
  displaylabels = FALSE,
  vertex.cex = 1,
  vertex.col = vertex_colors,
  coord = layout_coords,
  edge.lwd = edge_width,
  edge.col = adjustcolor("black", alpha.f = edge_alpha),
  main = plot_title
)

# Add Subtitle
mtext(
  text = plot_subtitle,
  side = 1, 
  line = 3, 
  cex = 0.8, 
  family = "serif"
)

# Add Data Source as Footer Note
mtext(
  text = "Data Source: MuMiN Dataset (https://data.bristol.ac.uk/data/en_GB/dataset/23yv276we2mll25fjakkfim2ml)", 
  side = 1, 
  line = 4.2,
  cex = 0.6, 
  family = "serif"
)

# Add Legend
legend(
  "right",
  legend = c("Stage 2 Retweeters", "Other Retweeters"), 
  col = c("steelblue", "gray"), 
  pch = 19, 
  pt.cex = 1,  
  cex = 0.6,                    
  text.col = "black", 
  bty = "n",                    
  y.intersp = 1.5                      
)

```

#### Stage 3 Plot (Co-retweet Net)

```{r}
#| output: false
# Assign Current Stage Info
target_group <- 3  

stage_info <- retweeter_stage |> 
  filter(group == target_group) |> 
  distinct(date, keywords)

stage_date <- unique(stage_info$date)
stage_keywords <- unique(stage_info$keywords)

# Get Edge List and Filter Edges for Current Stage
group_v1 <- assigned_groups[v1]
group_v2 <- assigned_groups[v2]
keep_edges <- which(group_v1 == target_group & group_v2 == target_group)

# Build Stage 3 Adjacency Matrix
adj_stage3 <- matrix(0, nrow = length(node_names), ncol = length(node_names))
rownames(adj_stage3) <- colnames(adj_stage3) <- node_names

if (length(keep_edges) > 0) {
  for (idx in keep_edges) {
    adj_stage3[v1[idx], v2[idx]] <- 1
    adj_stage3[v2[idx], v1[idx]] <- 1
  }
}

# Save Stage 3 Adjacency Matrix
write.csv(adj_stage3, "data/adj_matrix_stage3.csv", row.names = TRUE)

# Build Network Object for Stage 3
net_stage3 <- network(adj_stage3, directed = FALSE, matrix.type = "adjacency")

# Visualization Settings
plot_title <- paste0("Co-Retweet Network: Stage ", target_group)
plot_subtitle <- paste0("Misinformation Claim: ", stage_keywords, " | Claim Uttered on: ", stage_date)

edge_alpha <- 0.1 
edge_width <- 0.2  

set.seed(42)
layout_coords <- gplot(
  net_stage3, 
  gmode = "graph", 
  mode = "kamadakawai"
)
```
```{r}
vertex_colors <- ifelse(
  assigned_groups == target_group, 
  "steelblue", 
  "gray"
)

# Save PNG for Stage 3
png("plot/co_retweet_net/Co-Retweet-Stage3.png", width = 2200, height = 2100, res = 300)
par(family = "serif", mar = c(6, 0, 3, 1))

plot.network(
  net_stage3,
  displaylabels = FALSE,
  vertex.cex = 1,
  vertex.col = vertex_colors,
  coord = layout_coords,
  edge.lwd = edge_width,
  edge.col = adjustcolor("black", alpha.f = edge_alpha),
  main = plot_title
)

# Add Subtitle
mtext(
  text = plot_subtitle,
  side = 1, 
  line = 3, 
  cex = 0.8, 
  family = "serif"
)

# Add Data Source as Footer Note
mtext(
  text = "Data Source: MuMiN Dataset (https://data.bristol.ac.uk/data/en_GB/dataset/23yv276we2mll25fjakkfim2ml)", 
  side = 1, 
  line = 4.2,
  cex = 0.6, 
  family = "serif"
)

# Add Legend
legend(
  "right",
  legend = c("Stage 3 Retweeters", "Other Retweeters"), 
  col = c("steelblue", "gray"), 
  pch = 19, 
  pt.cex = 1,  
  cex = 0.6,                    
  text.col = "black", 
  bty = "n",                    
  y.intersp = 1.5                      
)

```

#### Stage 4 Plot (Co-retweet Net)

```{r}
#| output: false
# Assign Current Stage Info
target_group <- 4  

stage_info <- retweeter_stage |> 
  filter(group == target_group) |> 
  distinct(date, keywords)

stage_date <- unique(stage_info$date)
stage_keywords <- unique(stage_info$keywords)

# Get Edge List and Filter Edges for Current Stage
group_v1 <- assigned_groups[v1]
group_v2 <- assigned_groups[v2]
keep_edges <- which(group_v1 == target_group & group_v2 == target_group)

# Build Stage 4 Adjacency Matrix
adj_stage4 <- matrix(0, nrow = length(node_names), ncol = length(node_names))
rownames(adj_stage4) <- colnames(adj_stage4) <- node_names

if (length(keep_edges) > 0) {
  for (idx in keep_edges) {
    adj_stage4[v1[idx], v2[idx]] <- 1
    adj_stage4[v2[idx], v1[idx]] <- 1
  }
}

# Save Stage 4 Adjacency Matrix
write.csv(adj_stage4, "data/adj_matrix_stage4.csv", row.names = TRUE)

# Build Network Object for Stage 4
net_stage4 <- network(adj_stage4, directed = FALSE, matrix.type = "adjacency")

# Visualization Settings
plot_title <- paste0("Co-Retweet Network: Stage ", target_group)
plot_subtitle <- paste0("Misinformation Claim: ", stage_keywords, " | Claim Uttered on: ", stage_date)

edge_alpha <- 0.1 
edge_width <- 0.2  

set.seed(42)
layout_coords <- gplot(
  net_stage4, 
  gmode = "graph", 
  mode = "kamadakawai"
)
```
```{r}
vertex_colors <- ifelse(
  assigned_groups == target_group, 
  "steelblue", 
  "gray"
)

# Save PNG for Stage 4
png("plot/co_retweet_net/Co-Retweet-Stage4.png", width = 2200, height = 2100, res = 300)
par(family = "serif", mar = c(6, 0, 3, 1))

plot.network(
  net_stage4,
  displaylabels = FALSE,
  vertex.cex = 1,
  vertex.col = vertex_colors,
  coord = layout_coords,
  edge.lwd = edge_width,
  edge.col = adjustcolor("black", alpha.f = edge_alpha),
  main = plot_title
)

# Add Subtitle
mtext(
  text = plot_subtitle,
  side = 1, 
  line = 3, 
  cex = 0.8, 
  family = "serif"
)

# Add Data Source as Footer Note
mtext(
  text = "Data Source: MuMiN Dataset (https://data.bristol.ac.uk/data/en_GB/dataset/23yv276we2mll25fjakkfim2ml)", 
  side = 1, 
  line = 4.2,
  cex = 0.6, 
  family = "serif"
)

# Add Legend
legend(
  "right",
  legend = c("Stage 4 Retweeters", "Other Retweeters"), 
  col = c("steelblue", "gray"), 
  pch = 19, 
  pt.cex = 1,  
  cex = 0.6,                    
  text.col = "black", 
  bty = "n",                    
  y.intersp = 1.5                      
)

```

#### Stage 5 Plot (Co-retweet Net)

```{r}
#| output: false
# Assign Current Stage Info
target_group <- 5  

stage_info <- retweeter_stage |> 
  filter(group == target_group) |> 
  distinct(date, keywords)

stage_date <- unique(stage_info$date)
stage_keywords <- unique(stage_info$keywords)

# Get Edge List and Filter Edges for Current Stage
group_v1 <- assigned_groups[v1]
group_v2 <- assigned_groups[v2]
keep_edges <- which(group_v1 == target_group & group_v2 == target_group)

# Build Stage 5 Adjacency Matrix
adj_stage5 <- matrix(0, nrow = length(node_names), ncol = length(node_names))
rownames(adj_stage5) <- colnames(adj_stage5) <- node_names

if (length(keep_edges) > 0) {
  for (idx in keep_edges) {
    adj_stage5[v1[idx], v2[idx]] <- 1
    adj_stage5[v2[idx], v1[idx]] <- 1
  }
}

# Save Stage 5 Adjacency Matrix
write.csv(adj_stage5, "data/adj_matrix_stage5.csv", row.names = TRUE)

# Build Network Object for Stage 5
net_stage5 <- network(adj_stage5, directed = FALSE, matrix.type = "adjacency")

# Visualization Settings
plot_title <- paste0("Co-Retweet Network: Stage ", target_group)
plot_subtitle <- paste0("Misinformation Claim: ", stage_keywords, " | Claim Uttered on: ", stage_date)

edge_alpha <- 0.1 
edge_width <- 0.2  

set.seed(42)
layout_coords <- gplot(
  net_stage5, 
  gmode = "graph", 
  mode = "kamadakawai"
)

```
```{r}
vertex_colors <- ifelse(
  assigned_groups == target_group, 
  "steelblue", 
  "gray"
)

# Save PNG for Stage 5
png("plot/co_retweet_net/Co-Retweet-Stage5.png", width = 2200, height = 2100, res = 300)
par(family = "serif", mar = c(6, 0, 3, 1))

plot.network(
  net_stage5,
  displaylabels = FALSE,
  vertex.cex = 1,
  vertex.col = vertex_colors,
  coord = layout_coords,
  edge.lwd = edge_width,
  edge.col = adjustcolor("black", alpha.f = edge_alpha),
  main = plot_title
)

# Add Subtitle
mtext(
  text = plot_subtitle,
  side = 1, 
  line = 3, 
  cex = 0.8, 
  family = "serif"
)

# Add Data Source as Footer Note
mtext(
  text = "Data Source: MuMiN Dataset (https://data.bristol.ac.uk/data/en_GB/dataset/23yv276we2mll25fjakkfim2ml)", 
  side = 1, 
  line = 4.2,
  cex = 0.6, 
  family = "serif"
)

# Add Legend
legend(
  "right",
  legend = c("Stage 5 Retweeters", "Other Retweeters"), 
  col = c("steelblue", "gray"), 
  pch = 19, 
  pt.cex = 1,  
  cex = 0.6,                    
  text.col = "black", 
  bty = "n",                    
  y.intersp = 1.5                      
)

```

#### Stage 6 Plot (Co-retweet Net)

```{r}
#| output: false
# Assign Current Stage Info
target_group <- 6  

stage_info <- retweeter_stage |> 
  filter(group == target_group) |> 
  distinct(date, keywords)

stage_date <- unique(stage_info$date)
stage_keywords <- unique(stage_info$keywords)

group_v1 <- assigned_groups[v1]
group_v2 <- assigned_groups[v2]
keep_edges <- which(group_v1 == target_group & group_v2 == target_group)

adj_stage6 <- matrix(0, nrow = length(node_names), ncol = length(node_names))
rownames(adj_stage6) <- colnames(adj_stage6) <- node_names

if (length(keep_edges) > 0) {
  for (idx in keep_edges) {
    adj_stage6[v1[idx], v2[idx]] <- 1
    adj_stage6[v2[idx], v1[idx]] <- 1
  }
}

write.csv(adj_stage6, "data/adj_matrix_stage6.csv", row.names = TRUE)

net_stage6 <- network(adj_stage6, directed = FALSE, matrix.type = "adjacency")

plot_title <- paste0("Co-Retweet Network: Stage ", target_group)
plot_subtitle <- paste0("Misinformation Claim: ", stage_keywords, " | Claim Uttered on: ", stage_date)

edge_alpha <- 0.1 
edge_width <- 0.2  

set.seed(42)
layout_coords <- gplot(
  net_stage6, 
  gmode = "graph", 
  mode = "kamadakawai"
)
```
```{r}
vertex_colors <- ifelse(
  assigned_groups == target_group, 
  "steelblue", 
  "gray"
)

png("plot/co_retweet_net/Co-Retweet-Stage6.png", width = 2200, height = 2100, res = 300)
par(family = "serif", mar = c(6, 0, 3, 1))

plot.network(
  net_stage6,
  displaylabels = FALSE,
  vertex.cex = 1,
  vertex.col = vertex_colors,
  coord = layout_coords,
  edge.lwd = edge_width,
  edge.col = adjustcolor("black", alpha.f = edge_alpha),
  main = plot_title
)

mtext(
  text = plot_subtitle,
  side = 1, 
  line = 3, 
  cex = 0.8, 
  family = "serif"
)

# Add Data Source as Footer Note
mtext(
  text = "Data Source: MuMiN Dataset (https://data.bristol.ac.uk/data/en_GB/dataset/23yv276we2mll25fjakkfim2ml)", 
  side = 1, 
  line = 4.2,
  cex = 0.6, 
  family = "serif"
)

legend(
  "right",
  legend = c("Stage 6 Retweeters", "Other Retweeters"), 
  col = c("steelblue", "gray"), 
  pch = 19, 
  pt.cex = 1,  
  cex = 0.6,                    
  text.col = "black", 
  bty = "n",                    
  y.intersp = 1.5                      
)

```



## Basic Network Metrics

### Compare 3 Networks overall difference

```{r}
# 加载必要包
library(statnet)

# 1. 读入三个网络的邻接矩阵
adj_direct <- as.matrix(read.csv("data/adj_matrix_co_retweet.csv", row.names = 1, check.names = FALSE))
adj_quote <- as.matrix(read.csv("data/adj_matrix_co_retweet_quote_path.csv", row.names = 1, check.names = FALSE))
adj_reply <- as.matrix(read.csv("data/adj_matrix_co_retweet_reply_path.csv", row.names = 1, check.names = FALSE))

# 2. 转换为 statnet 的 network 对象
net_direct <- network(adj_direct, directed = FALSE, matrix.type = "adjacency")
net_quote <- network(adj_quote, directed = FALSE, matrix.type = "adjacency")
net_reply <- network(adj_reply, directed = FALSE, matrix.type = "adjacency")

# 3. 定义计算函数
compute_network_metrics <- function(net) {
  data.frame(
    Nodes = network.size(net),
    Edges = network.edgecount(net),
    Density = gden(net),
    Average_Degree = mean(degree(net), na.rm = TRUE),
    Transitivity = gtrans(net, mode = "graph"),
    Centralization_Degree = centralization(net, degree, mode = "freeman")
  )
}

# 4. 计算各网络的指标
metrics_direct <- compute_network_metrics(net_direct)
metrics_quote <- compute_network_metrics(net_quote)
metrics_reply <- compute_network_metrics(net_reply)

# 5. 合并结果输出
metrics_result <- rbind(
  cbind(Network = "Direct Co-Retweet", metrics_direct),
  cbind(Network = "Quote Pathway", metrics_quote),
  cbind(Network = "Reply Pathway", metrics_reply)
)

print(metrics_result)


plot(net_direct)
plot(net_quote)
plot(net_reply)
```

### T-Test

```{r}
# # 创建数据框手动输入结果
# metrics_df <- data.frame(
#   Network = c("Direct", "Quote", "Reply"),
#   Density = c(0.1309, 0.0838, 0.0894),
#   Centralization = c(0.0868, 0.1348, 0.1291)
# )
# 
# # t-test: Density Direct vs Quote
# t.test_density_dq <- t.test(
#   x = rep(metrics_df$Density[1], 112),  # Direct
#   y = rep(metrics_df$Density[2], 112)   # Quote
# )
# 
# # t-test: Density Direct vs Reply
# t.test_density_dr <- t.test(
#   x = rep(metrics_df$Density[1], 112),  # Direct
#   y = rep(metrics_df$Density[3], 112)   # Reply
# )
# 
# # t-test: Centralization Direct vs Quote
# t.test_cent_dq <- t.test(
#   x = rep(metrics_df$Centralization[1], 112),
#   y = rep(metrics_df$Centralization[2], 112)
# )
# 
# # 查看结果
# t.test_density_dq
# t.test_density_dr
# t.test_cent_dq


```

### Co-retweet Net

```{r}
# Load 6 Stage Net
co_retweet_stage_networks <- list(
  Stage1 = read.csv("data/adj_matrix_stage1.csv", row.names = 1) |> 
    as.matrix() |> 
    network(directed = FALSE, matrix.type = "adjacency"),
  
  Stage2 = read.csv("data/adj_matrix_stage2.csv", row.names = 1) |> 
    as.matrix() |> 
    network(directed = FALSE, matrix.type = "adjacency"),
  
  Stage3 = read.csv("data/adj_matrix_stage3.csv", row.names = 1) |> 
    as.matrix() |> 
    network(directed = FALSE, matrix.type = "adjacency"),
  
  Stage4 = read.csv("data/adj_matrix_stage4.csv", row.names = 1) |> 
    as.matrix() |> 
    network(directed = FALSE, matrix.type = "adjacency"),
  
  Stage5 = read.csv("data/adj_matrix_stage5.csv", row.names = 1) |> 
    as.matrix() |> 
    network(directed = FALSE, matrix.type = "adjacency"),
  
  Stage6 = read.csv("data/adj_matrix_stage6.csv", row.names = 1) |> 
    as.matrix() |> 
    network(directed = FALSE, matrix.type = "adjacency")
)

```

```{r}

compute_local_clustering <- function(net) {
  adj_mat <- as.matrix.network.adjacency(net)
  n <- nrow(adj_mat)
  
  clustering_vals <- numeric(n)
  
  for (i in 1:n) {
    neighbors <- which(adj_mat[i, ] == 1)
    k <- length(neighbors)
    if (k < 2) {
      clustering_vals[i] <- NA  # 无法形成三角形，设为 NA
    } else {
      subgraph <- adj_mat[neighbors, neighbors]
      actual_edges <- sum(subgraph) / 2  # 无向图
      possible_edges <- k * (k - 1) / 2
      clustering_vals[i] <- actual_edges / possible_edges
    }
  }
  
  return(clustering_vals)
}


compute_metrics <- function(net) {
  data.frame(
    Nodes = network.size(net),
    Edges = network.edgecount(net),
    Density = gden(net),
    Average_Degree = mean(degree(net), na.rm = TRUE),
    Degree_Centralization = centralization(net, degree, mode = "freeman"),
    Closeness_Centralization = centralization(net, closeness, mode = "freeman"),
    Betweenness_Centralization = centralization(net, betweenness, mode = "freeman"),
    Transitivity_Global = gtrans(net, mode = "graph"),
    Transitivity_Local = mean(compute_local_clustering(net), na.rm = TRUE)  # 替代 clustering.coefficient
  )
}


```


```{r}
metrics_results <- lapply(co_retweet_stage_networks, compute_metrics)
metrics_df <- do.call(rbind, metrics_results)
metrics_df$Stage <- rownames(metrics_df)

# reorder columns
metrics_df <- metrics_df[, c("Stage", setdiff(names(metrics_df), "Stage"))]

print(metrics_df)

```

The analysis of basic network metrics across the six stages reveals a highly clustered network structure with consistently high global and local transitivity values, suggesting that misinformation retweet activities predominantly occurred within tightly-knit groups. Notably, Stage 2 exhibits the highest average degree and network density, indicating peak activity and diffusion potential at this stage. Conversely, low centralization scores across closeness and betweenness measures imply the absence of prominent gatekeepers or highly influential intermediaries within the network.



# Reference


# Appendix

## Data Collection

This study uses secondary data from the **MuMiN Project** (Multi-platform Misinformation Influence Network), publicly available at: <https://data.bris.ac.uk/datasets/23yv276we2mll25fjakkfim2ml/mumin.zip> The dataset includes information about retweeter ids, tweets ids, misinformation claims, and the date when specific misinformation claims uttered etc.

**Note: About the `date`, [the explanation of dataset's authours](https://arxiv.org/abs/2202.11684):** 

*"`date`: The date the claim was uttered. If this date was not available then the date of the review was used. If neither of those two were available then we extracted a potential date from the URL of the fact-checking article using the regular expression [0-9]{4}-[0-9]{2}-[0-9]{2}."*

After downloading all files, create a `data` folder in your working directory and place the files inside it. Then, follow the setup instructions provided [here](https://colab.research.google.com/drive/1JCjgg3moGBOuZk4iVjBpQNqgsAYFyNoS#scrollTo=YS1uxj-59UmA). Use the shell to install required packages via `pip` as directed. Next, open `VS Code`, and run the following Python script to convert `.pkl` files to `.csv`:

```{python}
#| eval: false
#| include: true

import pandas as pd
import os

input_dir = "data/mumin"
output_dir = "data/mumin_csv"
os.makedirs(output_dir, exist_ok=True)

file_names = [
    "claim",
    "user",
    "tweet",
    "reply",
    "article",
    "tweet_discusses_claim",
    "article_discusses_claim",
    "user_follows_user",
    "user_retweeted_tweet",
    "reply_quote_of_tweet",
    "reply_reply_to_tweet"
]

for name in file_names:
    input_path = os.path.join(input_dir, name)
    output_path = os.path.join(output_dir, f"{name}.csv")
    try:
        df = pd.read_pickle(input_path, compression="xz")
        df.to_csv(output_path, index=False)
        print(f"Saved: {output_path}")
    except Exception as e:
        print(f"Failed to convert {name}: {e}")

```

This script will generate the corresponding CSV files for further analysis.

**Note:** *If you have a [X Developer API Pro Account](https://developer.x.com/en/portal/products/pro), you can directly follow the dataset's authors' [MuMiN Tutorial](https://colab.research.google.com/drive/1JCjgg3moGBOuZk4iVjBpQNqgsAYFyNoS#scrollTo=YS1uxj-59UmA) and conduct a deeper analysis with more enriched variables when [rehydrating the original datasets](https://colab.research.google.com/drive/1JCjgg3moGBOuZk4iVjBpQNqgsAYFyNoS#scrollTo=bOQqaJOa_PbF&line=1&uniqifier=1).*

After all steps above done, you can review the data in R:

```{r}
#| eval: false
#| include: true
# Set the data path 
data_path <- "data/mumin_csv/"

# Define the list of files to read
files <- c(
  "claim.csv", "user.csv", "tweet.csv", "reply.csv", "article.csv",
  "tweet_discusses_claim.csv", "article_discusses_claim.csv",
  "user_follows_user.csv", "user_retweeted_tweet.csv",
  "reply_quote_of_tweet.csv", "reply_reply_to_tweet.csv"
)

# Preview the first few rows of each file 
previews <- lapply(files, function(fname) {
  fpath <- file.path(data_path, fname)
  tryCatch(
    read_csv(fpath, n_max = 5),
    error = function(e) tibble::tibble(error = paste("Error:", e$message))
  )
})

names(previews) <- files

```

## Data Preparation

### Loading Required Packages

```{r}
#| eval: false
library(tidyverse)
library(readr)
library(statnet)
library(intergraph)
library(reshape2)
library(btergm)
```

### Loading and Merging Data

```{r}
#| eval: false
# Load data
tweets <- read_csv("data/mumin_csv/tweet.csv")
claims <- read_csv("data/mumin_csv/claim.csv")
tweet_claim <- read_csv("data/mumin_csv/tweet_discusses_claim.csv")
user_retweet <- read_csv("data/mumin_csv/user_retweeted_tweet.csv")

# Join tweet & claim via tweet_claim
tweet_claim_joined <- tweet_claim |> 
  rename(tweet_id = src, claim_id = tgt) |> 
  inner_join(claims, by = c("claim_id" = "id"))

# Join retweeters within users & claim via retweeted tweet
user_claim <- user_retweet |> 
  rename(retweeter_id = src, tweet_id = tgt) |> 
  inner_join(tweet_claim_joined, by = "tweet_id")

# Create a mapping of retweeters and tweets
retweet_map <- user_claim |> 
  select(retweeter_id, tweet_id) |> 
  distinct() 

# Basic data overview
table(user_claim$label)
head(table(user_claim$cluster_keywords))
```

### Filtering for Target Misinformation Narratives

This study focuses specifically on misinformation narratives claiming that **COVID-19 was deliberately created or spread by China or the Wuhan laboratory**. The following filtering steps were applied:

```{r}
#| eval: false
# Filter keywords containing "china" or "wuhan"
user_claim_filtered <- user_claim |> 
  filter(str_detect(keywords, "china|wuhan")) 

head(unique(user_claim_filtered$keywords))

# Manually select misinformation topics directly related to the COVID-19 origin narrative
covid_wuhan_misinfo <- user_claim_filtered |>
  filter(keywords %in% c(
    "coronavirus comes biological laboratory wuhan",
    "including corona virus manufactured wuhan",
    "china created spread coronavirus",
    "announced coronavirus artificially created china",
    "china created coronavirus",
    "coronavirus created laboratory china",
    "honjo said china manufactured coronavirus",
    "said new coronavirus manufactured wuhan",
    "coronavirus tested biological weapon china",
    "china testing coronavirus biological weapon",
    "covid 19 lab china",
    "coronavirus natural worked wuhan laboratory",
    "coronavirus manufactured laboratory wuhan specifically",
    "doctor claimed coronavirus china create",
    "corona virus manufactured china",
    "says current coronavirus manufactured wuhan",
    "wuhan coronavirus created patented",
    "covid 19 disease manufactured china",
    "pandemic caused artificial virus china",
    "collaborator assures coronavirus manufactured wuhan",
    "concluded covid leaked wuhan lab",
    "coronavirus created united states china",
    "air comes china import coronavirus",
    "coronavirus released china"
  )) |>
  #Restrict the analysis to English-language posts labeled as "misinformation"
  filter(language == "en") |>
  filter(label == "misinformation")

# Distribution of final misinformation topics
table(covid_wuhan_misinfo$keywords)
table(covid_wuhan_misinfo$cluster_keywords)
```

## Social Network Construction

This network models the co-dissemination behavior of misinformation retweeters. While the exact paths of information transmission are unknown, this co-spreader network captures the structural relationships that may facilitate misinformation diffusion.

### Co-Retweet Network

The `co-retweet` network represents a co-dissemination behavior among retweeters. A tie is created between two users only if they both retweeted the same specific misinformation tweet, which is identified by a shared `tweet_id` in `user_retweeted_tweet.csv` file. Each edge is weighted by the number of such co-retweeting events, reflecting how often the same pair of users jointly retweeted the same pieces of misinformation. Though this relationship does not suggest that a paired users share the same opinion, it captures direct and synchronous amplification of specific misinformation claim in tweets. Therefore, by analyzing the weighted connections among pairs of retweeters, this network checks which retweeters are central to the misinformation amplification/dissemination process, and whether specific communities or cliques form around the repeated propagation of misinformation. 

```{r}
#| eval: false
# Extract misinformation-related tweets id
misinfo_tweet_id <- unique(covid_wuhan_misinfo$tweet_id)

# Identify pairs of users who co-retweeted the same misinformation tweet
co_retweet_edges <- user_retweet |> 
  filter(tgt %in% misinfo_tweet_id) |> 
  rename(tweet_id = tgt, retweeter_id = src) |> 
  group_by(tweet_id) |> 
  summarise(
    pairs = list(as.data.frame(t(combn(retweeter_id, 2)))), 
    .groups = "drop"
  ) |> 
  unnest(pairs) |> 
  mutate(
    user_1 = pmin(V1, V2), # Ensure lower ID comes first
    user_2 = pmax(V1, V2) # Ensure higher ID comes second
  ) |> 
  select(user_1, user_2) |> 
  group_by(user_1, user_2) |> 
  summarise(weight = n(), .groups = "drop") |> 
  mutate(type = "co-retweet") |>
  filter(user_1 != user_2) |>
  mutate(
    user_1 = as.character(user_1),
    user_2 = as.character(user_2)
  )

# Obtain the full list of unique users involved
all_retweeters <- unique(c(
  covid_wuhan_misinfo$retweeter_id,  
  co_retweet_edges$user_1, 
  co_retweet_edges$user_2
)) |> 
  as.character() |> 
  sort()

# Create initial matrix
adj_matrix_co_retweet <- acast(
  co_retweet_edges, 
  user_1 ~ user_2, 
  value.var = "weight", 
  fill = 0
)

# Ensure matrix completeness by adding missing rows and columns
missing_rows <- setdiff(all_retweeters, rownames(adj_matrix_co_retweet))
missing_cols <- setdiff(all_retweeters, colnames(adj_matrix_co_retweet))

if (length(missing_rows) > 0) {
  adj_matrix_co_retweet <- rbind(
    adj_matrix_co_retweet, 
    matrix(0, nrow = length(missing_rows), ncol = ncol(adj_matrix_co_retweet), 
           dimnames = list(missing_rows, colnames(adj_matrix_co_retweet)))
  )
}

if (length(missing_cols) > 0) {
  adj_matrix_co_retweet <- cbind(
    adj_matrix_co_retweet, 
    matrix(0, nrow = nrow(adj_matrix_co_retweet), ncol = length(missing_cols), 
           dimnames = list(rownames(adj_matrix_co_retweet), missing_cols))
  )
}

# Reorder the matrix to align rows and columns
adj_matrix_co_retweet <- adj_matrix_co_retweet[all_retweeters, all_retweeters]

# Export the adjacency matrix for further analysis
write.csv(adj_matrix_co_retweet, "data/adj_matrix_co_retweet.csv", row.names = TRUE)

# Check dimensions of the final matrix
ncol(adj_matrix_co_retweet)
nrow(adj_matrix_co_retweet)

table(co_retweet_edges$weight)
```

## Graph

### Stage 1 Plot (Co-retweet Net)

```{r}
#| output: false
# Load Data and Build Full Network
adj_matrix <- read.csv("data/adj_matrix_co_retweet.csv", row.names = 1, check.names = FALSE)

net_full <- network(as.matrix(adj_matrix), directed = FALSE, matrix.type = "adjacency")

retweeter_stage <- covid_wuhan_misinfo |>
  mutate(retweeter_id = as.character(retweeter_id)) |>
  select(retweeter_id, date, keywords) |>
  distinct() |>
  arrange(date) |>
  mutate(
    group = as.numeric(factor(paste(date, keywords), levels = unique(paste(date, keywords))))
  ) |>
  select(retweeter_id, group, date, keywords)

node_names <- net_full %v% "vertex.names"

assigned_groups <- retweeter_stage$group[match(node_names, retweeter_stage$retweeter_id)]

set.vertex.attribute(net_full, "group", assigned_groups)

# Assign Current Stage Info
target_group <- 1  

stage_info <- retweeter_stage |> 
  filter(group == target_group) |> 
  distinct(date, keywords)

stage_date <- unique(stage_info$date)

stage_keywords <- unique(stage_info$keywords)

# Get Edge List and Filter Edges for Current Stage
edgelist <- as.edgelist(net_full)
v1 <- edgelist[, 1]
v2 <- edgelist[, 2]

group_v1 <- assigned_groups[v1]
group_v2 <- assigned_groups[v2]
keep_edges <- which(group_v1 == target_group & group_v2 == target_group)

# Build Stage Adjacency Matrix
adj_stage1 <- matrix(0, nrow = length(node_names), ncol = length(node_names))
rownames(adj_stage1) <- colnames(adj_stage1) <- node_names

if (length(keep_edges) > 0) {
  for (idx in keep_edges) {
    adj_stage1[v1[idx], v2[idx]] <- 1
    adj_stage1[v2[idx], v1[idx]] <- 1
  }
}

# Save Stage 1 Adjacency Matrix
write.csv(adj_stage1, "data/adj_matrix_stage1.csv", row.names = TRUE)

# Build Network Object for Stage 1
net_stage1 <- network(adj_stage1, directed = FALSE, matrix.type = "adjacency")

# Visualization Settings
plot_title <- paste0("Co-Retweet Network: Stage ", target_group)

plot_subtitle <- paste0("Misinformation Claim: ", stage_keywords, " | Claim Uttered on: ", stage_date)

edge_alpha <- 0.1 
edge_width <- 0.2  

set.seed(42)
layout_coords <- gplot(
  net_stage1, 
  gmode = "graph", 
  mode = "kamadakawai"
)
```
```{r}
vertex_colors <- ifelse(
  assigned_groups == target_group, 
  "steelblue", 
  "gray"
)

# Save PNG
# png("plot/co_retweet_net/Co-Retweet-Stage1.png", width = 2200, height = 2100, res = 300)
par(family = "serif", mar = c(6, 0, 3, 1))

plot.network(
  net_stage1,
  displaylabels = FALSE,
  vertex.cex = 1,
  vertex.col = vertex_colors,
  coord = layout_coords,
  edge.lwd = edge_width,
  edge.col = adjustcolor("black", alpha.f = edge_alpha),
  main = plot_title
)

# Add Subtitle
mtext(
  text = plot_subtitle,
  side = 1, 
  line = 3, 
  cex = 0.8, 
  family = "serif"
)

# Add Data Source as Footer Note
mtext(
  text = "Data Source: MuMiN Dataset (https://data.bristol.ac.uk/data/en_GB/dataset/23yv276we2mll25fjakkfim2ml)", 
  side = 1, 
  line = 4.2,
  cex = 0.6, 
  family = "serif"
)

# Add Legend
legend(
  "right",
  legend = c("Stage 1 Retweeters", "Other Retweeters"), 
  col = c("steelblue", "gray"), 
  pch = 19, 
  pt.cex = 1,  
  cex = 0.6,                    
  text.col = "black", 
  bty = "n",                    
  y.intersp = 1.5                      
)
```

### Stage 2 Plot (Co-retweet Net)

```{r}
#| output: false
# Assign Current Stage Info
target_group <- 2  

stage_info <- retweeter_stage |> 
  filter(group == target_group) |> 
  distinct(date, keywords)

stage_date <- unique(stage_info$date)
stage_keywords <- unique(stage_info$keywords)

# Get Edge List and Filter Edges for Current Stage
group_v1 <- assigned_groups[v1]
group_v2 <- assigned_groups[v2]
keep_edges <- which(group_v1 == target_group & group_v2 == target_group)

# Build Stage 2 Adjacency Matrix
adj_stage2 <- matrix(0, nrow = length(node_names), ncol = length(node_names))
rownames(adj_stage2) <- colnames(adj_stage2) <- node_names

if (length(keep_edges) > 0) {
  for (idx in keep_edges) {
    adj_stage2[v1[idx], v2[idx]] <- 1
    adj_stage2[v2[idx], v1[idx]] <- 1
  }
}

# Save Stage 2 Adjacency Matrix
write.csv(adj_stage2, "data/adj_matrix_stage2.csv", row.names = TRUE)

# Build Network Object for Stage 2
net_stage2 <- network(adj_stage2, directed = FALSE, matrix.type = "adjacency")

# Visualization Settings
plot_title <- paste0("Co-Retweet Network: Stage ", target_group)
plot_subtitle <- paste0("Misinformation Claim: ", stage_keywords, " | Claim Uttered on: ", stage_date)

edge_alpha <- 0.1 
edge_width <- 0.2  

set.seed(42)
layout_coords <- gplot(
  net_stage2, 
  gmode = "graph", 
  mode = "kamadakawai"
)
```
```{r}
vertex_colors <- ifelse(
  assigned_groups == target_group, 
  "steelblue", 
  "gray"
)

# Save PNG for Stage 2
# png("plot/co_retweet_net/Co-Retweet-Stage2.png", width = 2200, height = 2100, res = 300)
par(family = "serif", mar = c(6, 0, 3, 1))

plot.network(
  net_stage2,
  displaylabels = FALSE,
  vertex.cex = 1,
  vertex.col = vertex_colors,
  coord = layout_coords,
  edge.lwd = edge_width,
  edge.col = adjustcolor("black", alpha.f = edge_alpha),
  main = plot_title
)

# Add Subtitle
mtext(
  text = plot_subtitle,
  side = 1, 
  line = 3, 
  cex = 0.8, 
  family = "serif"
)

# Add Data Source as Footer Note
mtext(
  text = "Data Source: MuMiN Dataset (https://data.bristol.ac.uk/data/en_GB/dataset/23yv276we2mll25fjakkfim2ml)", 
  side = 1, 
  line = 4.2,
  cex = 0.6, 
  family = "serif"
)

# Add Legend
legend(
  "right",
  legend = c("Stage 2 Retweeters", "Other Retweeters"), 
  col = c("steelblue", "gray"), 
  pch = 19, 
  pt.cex = 1,  
  cex = 0.6,                    
  text.col = "black", 
  bty = "n",                    
  y.intersp = 1.5                      
)

```

### Stage 3 Plot (Co-retweet Net)

```{r}
#| output: false
# Assign Current Stage Info
target_group <- 3  

stage_info <- retweeter_stage |> 
  filter(group == target_group) |> 
  distinct(date, keywords)

stage_date <- unique(stage_info$date)
stage_keywords <- unique(stage_info$keywords)

# Get Edge List and Filter Edges for Current Stage
group_v1 <- assigned_groups[v1]
group_v2 <- assigned_groups[v2]
keep_edges <- which(group_v1 == target_group & group_v2 == target_group)

# Build Stage 3 Adjacency Matrix
adj_stage3 <- matrix(0, nrow = length(node_names), ncol = length(node_names))
rownames(adj_stage3) <- colnames(adj_stage3) <- node_names

if (length(keep_edges) > 0) {
  for (idx in keep_edges) {
    adj_stage3[v1[idx], v2[idx]] <- 1
    adj_stage3[v2[idx], v1[idx]] <- 1
  }
}

# Save Stage 3 Adjacency Matrix
write.csv(adj_stage3, "data/adj_matrix_stage3.csv", row.names = TRUE)

# Build Network Object for Stage 3
net_stage3 <- network(adj_stage3, directed = FALSE, matrix.type = "adjacency")

# Visualization Settings
plot_title <- paste0("Co-Retweet Network: Stage ", target_group)
plot_subtitle <- paste0("Misinformation Claim: ", stage_keywords, " | Claim Uttered on: ", stage_date)

edge_alpha <- 0.1 
edge_width <- 0.2  

set.seed(42)
layout_coords <- gplot(
  net_stage3, 
  gmode = "graph", 
  mode = "kamadakawai"
)
```
```{r}
vertex_colors <- ifelse(
  assigned_groups == target_group, 
  "steelblue", 
  "gray"
)

# Save PNG for Stage 3
# png("plot/co_retweet_net/Co-Retweet-Stage3.png", width = 2200, height = 2100, res = 300)
par(family = "serif", mar = c(6, 0, 3, 1))

plot.network(
  net_stage3,
  displaylabels = FALSE,
  vertex.cex = 1,
  vertex.col = vertex_colors,
  coord = layout_coords,
  edge.lwd = edge_width,
  edge.col = adjustcolor("black", alpha.f = edge_alpha),
  main = plot_title
)

# Add Subtitle
mtext(
  text = plot_subtitle,
  side = 1, 
  line = 3, 
  cex = 0.8, 
  family = "serif"
)

# Add Data Source as Footer Note
mtext(
  text = "Data Source: MuMiN Dataset (https://data.bristol.ac.uk/data/en_GB/dataset/23yv276we2mll25fjakkfim2ml)", 
  side = 1, 
  line = 4.2,
  cex = 0.6, 
  family = "serif"
)

# Add Legend
legend(
  "right",
  legend = c("Stage 3 Retweeters", "Other Retweeters"), 
  col = c("steelblue", "gray"), 
  pch = 19, 
  pt.cex = 1,  
  cex = 0.6,                    
  text.col = "black", 
  bty = "n",                    
  y.intersp = 1.5                      
)
```

### Stage 4 Plot (Co-retweet Net)

```{r}
#| output: false
# Assign Current Stage Info
target_group <- 4  

stage_info <- retweeter_stage |> 
  filter(group == target_group) |> 
  distinct(date, keywords)

stage_date <- unique(stage_info$date)
stage_keywords <- unique(stage_info$keywords)

# Get Edge List and Filter Edges for Current Stage
group_v1 <- assigned_groups[v1]
group_v2 <- assigned_groups[v2]
keep_edges <- which(group_v1 == target_group & group_v2 == target_group)

# Build Stage 4 Adjacency Matrix
adj_stage4 <- matrix(0, nrow = length(node_names), ncol = length(node_names))
rownames(adj_stage4) <- colnames(adj_stage4) <- node_names

if (length(keep_edges) > 0) {
  for (idx in keep_edges) {
    adj_stage4[v1[idx], v2[idx]] <- 1
    adj_stage4[v2[idx], v1[idx]] <- 1
  }
}

# Save Stage 4 Adjacency Matrix
write.csv(adj_stage4, "data/adj_matrix_stage4.csv", row.names = TRUE)

# Build Network Object for Stage 4
net_stage4 <- network(adj_stage4, directed = FALSE, matrix.type = "adjacency")

# Visualization Settings
plot_title <- paste0("Co-Retweet Network: Stage ", target_group)
plot_subtitle <- paste0("Misinformation Claim: ", stage_keywords, " | Claim Uttered on: ", stage_date)

edge_alpha <- 0.1 
edge_width <- 0.2  

set.seed(42)
layout_coords <- gplot(
  net_stage4, 
  gmode = "graph", 
  mode = "kamadakawai"
)
```
```{r}
vertex_colors <- ifelse(
  assigned_groups == target_group, 
  "steelblue", 
  "gray"
)

# Save PNG for Stage 4
# png("plot/co_retweet_net/Co-Retweet-Stage4.png", width = 2200, height = 2100, res = 300)
par(family = "serif", mar = c(6, 0, 3, 1))

plot.network(
  net_stage4,
  displaylabels = FALSE,
  vertex.cex = 1,
  vertex.col = vertex_colors,
  coord = layout_coords,
  edge.lwd = edge_width,
  edge.col = adjustcolor("black", alpha.f = edge_alpha),
  main = plot_title
)

# Add Subtitle
mtext(
  text = plot_subtitle,
  side = 1, 
  line = 3, 
  cex = 0.8, 
  family = "serif"
)

# Add Data Source as Footer Note
mtext(
  text = "Data Source: MuMiN Dataset (https://data.bristol.ac.uk/data/en_GB/dataset/23yv276we2mll25fjakkfim2ml)", 
  side = 1, 
  line = 4.2,
  cex = 0.6, 
  family = "serif"
)

# Add Legend
legend(
  "right",
  legend = c("Stage 4 Retweeters", "Other Retweeters"), 
  col = c("steelblue", "gray"), 
  pch = 19, 
  pt.cex = 1,  
  cex = 0.6,                    
  text.col = "black", 
  bty = "n",                    
  y.intersp = 1.5                      
)

```

### Stage 5 Plot (Co-retweet Net)

```{r}
#| output: false
# Assign Current Stage Info
target_group <- 5  

stage_info <- retweeter_stage |> 
  filter(group == target_group) |> 
  distinct(date, keywords)

stage_date <- unique(stage_info$date)
stage_keywords <- unique(stage_info$keywords)

# Get Edge List and Filter Edges for Current Stage
group_v1 <- assigned_groups[v1]
group_v2 <- assigned_groups[v2]
keep_edges <- which(group_v1 == target_group & group_v2 == target_group)

# Build Stage 5 Adjacency Matrix
adj_stage5 <- matrix(0, nrow = length(node_names), ncol = length(node_names))
rownames(adj_stage5) <- colnames(adj_stage5) <- node_names

if (length(keep_edges) > 0) {
  for (idx in keep_edges) {
    adj_stage5[v1[idx], v2[idx]] <- 1
    adj_stage5[v2[idx], v1[idx]] <- 1
  }
}

# Save Stage 5 Adjacency Matrix
write.csv(adj_stage5, "data/adj_matrix_stage5.csv", row.names = TRUE)

# Build Network Object for Stage 5
net_stage5 <- network(adj_stage5, directed = FALSE, matrix.type = "adjacency")

# Visualization Settings
plot_title <- paste0("Co-Retweet Network: Stage ", target_group)
plot_subtitle <- paste0("Misinformation Claim: ", stage_keywords, " | Claim Uttered on: ", stage_date)

edge_alpha <- 0.1 
edge_width <- 0.2  

set.seed(42)
layout_coords <- gplot(
  net_stage5, 
  gmode = "graph", 
  mode = "kamadakawai"
)

```
```{r}
vertex_colors <- ifelse(
  assigned_groups == target_group, 
  "steelblue", 
  "gray"
)

# Save PNG for Stage 5
# png("plot/co_retweet_net/Co-Retweet-Stage5.png", width = 2200, height = 2100, res = 300)
par(family = "serif", mar = c(6, 0, 3, 1))

plot.network(
  net_stage5,
  displaylabels = FALSE,
  vertex.cex = 1,
  vertex.col = vertex_colors,
  coord = layout_coords,
  edge.lwd = edge_width,
  edge.col = adjustcolor("black", alpha.f = edge_alpha),
  main = plot_title
)

# Add Subtitle
mtext(
  text = plot_subtitle,
  side = 1, 
  line = 3, 
  cex = 0.8, 
  family = "serif"
)

# Add Data Source as Footer Note
mtext(
  text = "Data Source: MuMiN Dataset (https://data.bristol.ac.uk/data/en_GB/dataset/23yv276we2mll25fjakkfim2ml)", 
  side = 1, 
  line = 4.2,
  cex = 0.6, 
  family = "serif"
)

# Add Legend
legend(
  "right",
  legend = c("Stage 5 Retweeters", "Other Retweeters"), 
  col = c("steelblue", "gray"), 
  pch = 19, 
  pt.cex = 1,  
  cex = 0.6,                    
  text.col = "black", 
  bty = "n",                    
  y.intersp = 1.5                      
)

```

### Stage 6 Plot (Co-retweet Net)

```{r}
#| output: false
# Assign Current Stage Info
target_group <- 6  

stage_info <- retweeter_stage |> 
  filter(group == target_group) |> 
  distinct(date, keywords)

stage_date <- unique(stage_info$date)
stage_keywords <- unique(stage_info$keywords)

group_v1 <- assigned_groups[v1]
group_v2 <- assigned_groups[v2]
keep_edges <- which(group_v1 == target_group & group_v2 == target_group)

adj_stage6 <- matrix(0, nrow = length(node_names), ncol = length(node_names))
rownames(adj_stage6) <- colnames(adj_stage6) <- node_names

if (length(keep_edges) > 0) {
  for (idx in keep_edges) {
    adj_stage6[v1[idx], v2[idx]] <- 1
    adj_stage6[v2[idx], v1[idx]] <- 1
  }
}

write.csv(adj_stage6, "data/adj_matrix_stage6.csv", row.names = TRUE)

net_stage6 <- network(adj_stage6, directed = FALSE, matrix.type = "adjacency")

plot_title <- paste0("Co-Retweet Network: Stage ", target_group)
plot_subtitle <- paste0("Misinformation Claim: ", stage_keywords, " | Claim Uttered on: ", stage_date)

edge_alpha <- 0.1 
edge_width <- 0.2  

set.seed(42)
layout_coords <- gplot(
  net_stage6, 
  gmode = "graph", 
  mode = "kamadakawai"
)
```
```{r}
vertex_colors <- ifelse(
  assigned_groups == target_group, 
  "steelblue", 
  "gray"
)

# png("plot/co_retweet_net/Co-Retweet-Stage6.png", width = 2200, height = 2100, res = 300)
par(family = "serif", mar = c(6, 0, 3, 1))

plot.network(
  net_stage6,
  displaylabels = FALSE,
  vertex.cex = 1,
  vertex.col = vertex_colors,
  coord = layout_coords,
  edge.lwd = edge_width,
  edge.col = adjustcolor("black", alpha.f = edge_alpha),
  main = plot_title
)

mtext(
  text = plot_subtitle,
  side = 1, 
  line = 3, 
  cex = 0.8, 
  family = "serif"
)

# Add Data Source as Footer Note
mtext(
  text = "Data Source: MuMiN Dataset (https://data.bristol.ac.uk/data/en_GB/dataset/23yv276we2mll25fjakkfim2ml)", 
  side = 1, 
  line = 4.2,
  cex = 0.6, 
  family = "serif"
)

legend(
  "right",
  legend = c("Stage 6 Retweeters", "Other Retweeters"), 
  col = c("steelblue", "gray"), 
  pch = 19, 
  pt.cex = 1,  
  cex = 0.6,                    
  text.col = "black", 
  bty = "n",                    
  y.intersp = 1.5                      
)

```

```{=html}
<script>
document.addEventListener("DOMContentLoaded", function() {
    const toc = document.getElementById("TOC");
    if (toc) {
        const sourceLink = document.createElement("div");
        sourceLink.innerHTML = `
            <div class="toc-source">
                <a href="https://github.com/troy-yu-cheng/sna-final-paper" 
                   target="_blank" 
                   class="github-button">
                   <svg xmlns="http://www.w3.org/2000/svg" 
                        viewBox="0 0 24 24" 
                        width="16" 
                        height="16" 
                        fill="currentColor"
                        style="vertical-align: middle; margin-right: 5px;">
                     <path d="M12 0C5.373 0 0 5.373 0 12c0 5.303 3.438 9.8 8.207 11.387.6.113.82-.26.82-.577v-2.157c-3.338.726-4.033-1.416-4.033-1.416-.546-1.386-1.332-1.756-1.332-1.756-1.09-.745.083-.73.083-.73 1.205.084 1.84 1.237 1.84 1.237 1.07 1.832 2.807 1.303 3.492.996.108-.774.418-1.303.76-1.602-2.665-.3-5.466-1.332-5.466-5.93 0-1.311.468-2.382 1.237-3.222-.124-.302-.536-1.52.118-3.163 0 0 1.008-.322 3.3 1.23a11.516 11.516 0 0 1 3.002-.403 11.486 11.486 0 0 1 3.002.403c2.292-1.552 3.3-1.23 3.3-1.23.654 1.644.242 2.861.118 3.163.77.84 1.236 1.911 1.236 3.222 0 4.61-2.807 5.627-5.48 5.922.43.372.812 1.103.812 2.222v3.293c0 .321.218.694.825.576C20.565 21.796 24 17.3 24 12 24 5.373 18.627 0 12 0z"/>
                   </svg>
                   View source
                </a>
            </div>
        `;
        toc.appendChild(sourceLink);
    }
});
</script>
```

