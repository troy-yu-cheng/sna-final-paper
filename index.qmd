---
title: "Social Network Analysis"
subtitle: "Final Paper"
author: 
  - name: "Troy (Yu) Cheng"
    email: yc1317@georgetown.edu
    affiliation: Georgetown University
    corresponding: true
df-print: kable
title-block-banner: "#0a0e1a"
title-block-banner-color: "#4DB8FF"
execute:
  warning: false
date: 2025-04-28
date-modified: last-modified
format:
  html:
    embed-resources: true
    toc: true                 
    toc-title: "Contents"     
    toc-location: right       
    number-sections: true
    number-depth: 3       
    smooth-scroll: true       
    css: trycstyle.css 
    code-overflow: wrap
include-in-header:
  text: |
    <link rel="shortcut icon" href="assets/gu.ico" type="image/x-icon">           
highlight-style: nord       
engine: knitr
---
# Abstract

我现在对covid病毒是在中国/wuhan爆发这条谣言在推特用户间的传播规律（随时间）很感兴趣

# Literature Review


# Data Set

Raw dataset download link: <https://data.bristol.ac.uk/data/en_GB/dataset/23yv276we2mll25fjakkfim2ml/resource/e63a98c4-b4d6-4a89-9be9-06875b83ce33?inner_span=True>

## Set up

```{r}
#| label: set up packages
library(tidyverse)
library(readr)
library(haven)
library(lubridate)
library(tidymodels)
library(statnet)
```


```{r}
# 1. 读入必要数据
tweets <- read_csv("data/mumin_csv/tweet.csv")
claims <- read_csv("data/mumin_csv/claim.csv")
tweet_claim <- read_csv("data/mumin_csv/tweet_discusses_claim.csv")
user_retweet <- read_csv("data/mumin_csv/user_retweeted_tweet.csv")

# 2. Tweet 与 Claim join
tweet_claim_joined <- tweet_claim |> 
  rename(tweet_id = src, claim_id = tgt) |> 
  inner_join(tweets, by = "tweet_id") |> 
  inner_join(claims, by = c("claim_id" = "id"))

# 3. 再与 User-行为 join（举例：retweet）
user_claim <- user_retweet |> 
  rename(user_id = src, tweet_id = tgt) |> 
  inner_join(tweet_claim_joined, by = "tweet_id")


table(user_claim$label)
table(user_claim$cluster_keywords)
table(user_claim$keywords)


# 现在 user_claim 就有 user_id, tweet_id, claim_id, keywords, label 等字段

```

```{r}
user_claim_filtered <- user_claim |> 
  filter(str_detect(keywords, "china|wuhan")) 

unique(user_claim_filtered$keywords)

unique(user_claim$language)


covid_wuhan_misinfo <- user_claim_filtered |>
  filter(keywords %in% c(
    "coronavirus comes biological laboratory wuhan",
    "including corona virus manufactured wuhan",
    "china created spread coronavirus",
    "announced coronavirus artificially created china",
    "china created coronavirus",
    "coronavirus created laboratory china",
    "honjo said china manufactured coronavirus",
    "said new coronavirus manufactured wuhan",
    "coronavirus tested biological weapon china",
    "china testing coronavirus biological weapon",
    "covid 19 lab china",
    "coronavirus natural worked wuhan laboratory",
    "coronavirus manufactured laboratory wuhan specifically",
    "doctor claimed coronavirus china create",
    "corona virus manufactured china",
    "says current coronavirus manufactured wuhan",
    "wuhan coronavirus created patented",
    "covid 19 disease manufactured china",
    "pandemic caused artificial virus china",
    "collaborator assures coronavirus manufactured wuhan",
    "concluded covid leaked wuhan lab",
    "coronavirus created united states china",
    "air comes china import coronavirus",
    "coronavirus released china"
  )) |>
  filter(language == "en")


table(covid_wuhan_misinfo$keywords)
table(covid_wuhan_misinfo$cluster_keywords)

```
```{r}
# tweet_user_map 事先准备
tweet_user_map <- user_claim |> 
  select(tweet_id, user_id) |> 
  distinct()

# retweet 边
edges_retweet <- read_csv("data/mumin_csv/user_retweeted_tweet.csv") |>
  left_join(tweet_user_map, by = c("tgt" = "tweet_id")) |>
  rename(src_user = src, tgt_user = user_id) |>
  filter(!is.na(tgt_user)) |>
  mutate(type = "retweet") |>
  select(src_user, tgt_user, type)

# quote 边
edges_quote <- read_csv("data/mumin_csv/reply_quote_of_tweet.csv") |>
  left_join(tweet_user_map, by = c("tgt" = "tweet_id")) |>
  rename(src_user = src, tgt_user = user_id) |>
  filter(!is.na(tgt_user)) |>
  mutate(type = "quote") |>
  select(src_user, tgt_user, type)

# reply 边
edges_reply <- read_csv("data/mumin_csv/reply_reply_to_tweet.csv") |>
  left_join(tweet_user_map, by = c("tgt" = "tweet_id")) |>
  rename(src_user = src, tgt_user = user_id) |>
  filter(!is.na(tgt_user)) |>
  mutate(type = "reply") |>
  select(src_user, tgt_user, type)

# follow 边（直接是 user-user）
edges_follow <- read_csv("data/mumin_csv/user_follows_user.csv") |>
  rename(src_user = src, tgt_user = tgt) |>
  mutate(type = "follow") |>
  select(src_user, tgt_user, type)

# 合并全部边
user_edges_all <- bind_rows(edges_retweet, edges_quote, edges_reply, edges_follow) |>
  distinct()

```


```{r}

# 过滤出传播 misinformation 的边
edges_misinfo <- user_claim |> 
  filter(label == "misinformation") |> 
  select(user_id, tweet_id, claim_id, keywords, label)

# 然后构建传播边（例如：用户A转发了含 misinformation 的 tweet）
edges <- user_retweet |> 
  inner_join(edges_misinfo, by = c("tgt" = "tweet_id")) |> 
  rename(from = src, to = tgt) |> 
  select(from, to, claim_id, keywords, label)

# 去掉loops
edges <- edges |> filter(from != to)


```

```{r}
edges_follow <- read_csv("data/mumin_csv/user_follows_user.csv") |> 
  mutate(type = "follow")

edges_retweet <- read_csv("data/mumin_csv/user_retweeted_tweet.csv") |> 
  mutate(type = "retweet")

edges_reply <- read_csv("data/mumin_csv/reply_reply_to_tweet.csv") |> 
  mutate(type = "reply")

edges_quote <- read_csv("data/mumin_csv/reply_quote_of_tweet.csv") |> 
  mutate(type = "quote")

# 统一格式并合并
user_edges_all <- bind_rows(
  edges_follow,
  edges_retweet,
  edges_reply,
  edges_quote
) |> 
  rename(from = src, to = tgt) |> 
  select(from, to, type)W

# 过滤掉 from == to 的记录
user_edges_all_clean <- user_edges_all |> 
  filter(from != to) |> 
  distinct(from, to, .keep_all = TRUE)

# 然后再建图
net <- network(user_edges_all_clean, directed = TRUE, matrix.type = "edgelist")
set.edge.attribute(net, "type", user_edges_all_clean$type)


# 简要可视化
plot(net, displaylabels = FALSE, edge.col = as.factor(user_edges_all$type))
```

# Analysis


# Reference


# Appendix

Take a glimpse of data:

```{r}
# 设置数据路径（请替换为你自己电脑上的路径）
data_path <- "data/mumin_csv/"

# 定义要读取的文件列表
files <- c(
  "claim.csv", "user.csv", "tweet.csv", "reply.csv", "article.csv",
  "tweet_discusses_claim.csv", "article_discusses_claim.csv",
  "user_follows_user.csv", "user_retweeted_tweet.csv",
  "reply_quote_of_tweet.csv", "reply_reply_to_tweet.csv"
)

# 用lapply预览前几行（避免爆内存）
previews <- lapply(files, function(fname) {
  fpath <- file.path(data_path, fname)
  tryCatch(
    read_csv(fpath, n_max = 5),
    error = function(e) tibble::tibble(error = paste("Error:", e$message))
  )
})
names(previews) <- files
previews$`claim.csv`

previews$`user.csv`                  
previews$`tweet.csv`
previews$`reply.csv`                  
previews$`article.csv`
previews$`tweet_discusses_claim.csv`  
previews$`article_discusses_claim.csv` 
previews$`user_follows_user.csv`      
previews$`user_retweeted_tweet.csv`
previews$`reply_quote_of_tweet.csv`   
previews$`reply_reply_to_tweet.csv` 

```

```{=html}
<script>
document.addEventListener("DOMContentLoaded", function() {
    const toc = document.getElementById("TOC");
    if (toc) {
        const sourceLink = document.createElement("div");
        sourceLink.innerHTML = `
            <div class="toc-source">
                <a href="https://github.com/troy-yu-cheng/sna-final-paper" 
                   target="_blank" 
                   class="github-button">
                   <svg xmlns="http://www.w3.org/2000/svg" 
                        viewBox="0 0 24 24" 
                        width="16" 
                        height="16" 
                        fill="currentColor"
                        style="vertical-align: middle; margin-right: 5px;">
                     <path d="M12 0C5.373 0 0 5.373 0 12c0 5.303 3.438 9.8 8.207 11.387.6.113.82-.26.82-.577v-2.157c-3.338.726-4.033-1.416-4.033-1.416-.546-1.386-1.332-1.756-1.332-1.756-1.09-.745.083-.73.083-.73 1.205.084 1.84 1.237 1.84 1.237 1.07 1.832 2.807 1.303 3.492.996.108-.774.418-1.303.76-1.602-2.665-.3-5.466-1.332-5.466-5.93 0-1.311.468-2.382 1.237-3.222-.124-.302-.536-1.52.118-3.163 0 0 1.008-.322 3.3 1.23a11.516 11.516 0 0 1 3.002-.403 11.486 11.486 0 0 1 3.002.403c2.292-1.552 3.3-1.23 3.3-1.23.654 1.644.242 2.861.118 3.163.77.84 1.236 1.911 1.236 3.222 0 4.61-2.807 5.627-5.48 5.922.43.372.812 1.103.812 2.222v3.293c0 .321.218.694.825.576C20.565 21.796 24 17.3 24 12 24 5.373 18.627 0 12 0z"/>
                   </svg>
                   View source
                </a>
            </div>
        `;
        toc.appendChild(sourceLink);
    }
});
</script>
```

