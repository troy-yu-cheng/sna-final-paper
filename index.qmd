---
title: "Social Network Analysis"
subtitle: "Temporal Patterns of Misinformation Diffusion: A Multi-Stage Network Analysis of COVID-19 Origin Narratives on Twitter"
author: 
  - name: "Troy (Yu) Cheng"
    email: yc1317@georgetown.edu
    affiliation: Georgetown University
    corresponding: true
df-print: kable
title-block-banner: "#0a0e1a"
title-block-banner-color: "#4DB8FF"
execute:
  warning: false
date: 2025-04-28
date-modified: last-modified
format:
  html:
    embed-resources: true
    toc: true                 
    toc-title: "Contents"     
    toc-location: right       
    number-sections: true
    number-depth: 3       
    smooth-scroll: true       
    css: trycstyle.css 
    code-overflow: wrap
include-in-header:
  text: |
    <link rel="shortcut icon" href="assets/gu.ico" type="image/x-icon">           
highlight-style: nord       
engine: knitr
---
# Abstract

This study examines the temporal diffusion patterns of the misinformation narrative claiming that [COVID-19 was deliberately created/manufactured by China or the Wuhan laboratory](https://en.wikipedia.org/wiki/COVID-19_lab_leak_theory). The central research question asks: How did this narrative propagate across Twitter retweeter networks over time, and did early spreaders maintain structural advantages? Drawing on the Diffusion of Innovations Theory and Echo Chamber Theory, the study explores whether ideological homophily emerged as the narrative spread.

Using data from the [MuMiN](https://mumin-dataset.github.io/) project, six prominent misinformation claims between March 2020 and August 2021 were analyzed. Retweeters are treated as nodes, with ties defined by co-retweeting, co-replying, co-quoting, and following behaviors. The hypothesis posits that retweeters involved in earlier misinformation narratives occupy more central positions and retain higher connectivity over time.

Social Network Analysis (SNA) is employed to construct adjacency matrices, visualize evolving network structures, and compute centrality and modularity metrics. While temporal network growth is discontinuous across misinformation events, this study explores whether Temporal Exponential Random Graph Models (tERGM) can model these episodic formations by treating thematic similarity as a historical tie.

This research advances understanding of how misinformation narratives persist in online environments and how early participants shape long-term information diffusion.

# Introduction

# Literature Review


# Data Collection & Graph

## Dataset

This study uses secondary data from the **MuMiN Project** (Multi-platform Misinformation Influence Network), publicly available at: <https://data.bristol.ac.uk/data/en_GB/dataset/23yv276we2mll25fjakkfim2ml/resource/e63a98c4-b4d6-4a89-9be9-06875b83ce33?inner_span=True>

The dataset includes information about social media users, tweets, misinformation claims, and their relational behaviors across various platforms.

## Data Preparation

### Loading Required Packages

```{r}
#| label: set up packages
library(tidyverse)
library(readr)
library(statnet)
library(intergraph)
library(reshape2)
library(btergm)
```

### Loading and Merging Data

```{r}
# Load data
tweets <- read_csv("data/mumin_csv/tweet.csv")
claims <- read_csv("data/mumin_csv/claim.csv")
tweet_claim <- read_csv("data/mumin_csv/tweet_discusses_claim.csv")
user_retweet <- read_csv("data/mumin_csv/user_retweeted_tweet.csv")

# Join tweet & claim via tweet_claim
tweet_claim_joined <- tweet_claim |> 
  rename(tweet_id = src, claim_id = tgt) |> 
  inner_join(claims, by = c("claim_id" = "id"))

# Join retweeters within users & claim via retweeted tweet
user_claim <- user_retweet |> 
  rename(retweeter_id = src, tweet_id = tgt) |> 
  inner_join(tweet_claim_joined, by = "tweet_id")

# Create a mapping of retweeters and tweets
retweet_map <- user_claim |> 
  select(retweeter_id, tweet_id) |> 
  distinct() 

# Basic data overview
table(user_claim$label)
head(table(user_claim$cluster_keywords))
```

### Filtering for Target Misinformation Narratives

This study focuses specifically on misinformation narratives claiming that **COVID-19 was deliberately created or spread by China or the Wuhan laboratory**. The following filtering steps were applied:

1. Filter keywords containing "china" or "wuhan".

2. Manually select misinformation topics directly related to the COVID-19 origin narrative.

3. Restrict the analysis to English-language posts labeled as "misinformation".

**Note: **

```{r}
user_claim_filtered <- user_claim |> 
  filter(str_detect(keywords, "china|wuhan")) 

head(unique(user_claim_filtered$keywords))

# Final filtered dataset
covid_wuhan_misinfo <- user_claim_filtered |>
  filter(keywords %in% c(
    "coronavirus comes biological laboratory wuhan",
    "including corona virus manufactured wuhan",
    "china created spread coronavirus",
    "announced coronavirus artificially created china",
    "china created coronavirus",
    "coronavirus created laboratory china",
    "honjo said china manufactured coronavirus",
    "said new coronavirus manufactured wuhan",
    "coronavirus tested biological weapon china",
    "china testing coronavirus biological weapon",
    "covid 19 lab china",
    "coronavirus natural worked wuhan laboratory",
    "coronavirus manufactured laboratory wuhan specifically",
    "doctor claimed coronavirus china create",
    "corona virus manufactured china",
    "says current coronavirus manufactured wuhan",
    "wuhan coronavirus created patented",
    "covid 19 disease manufactured china",
    "pandemic caused artificial virus china",
    "collaborator assures coronavirus manufactured wuhan",
    "concluded covid leaked wuhan lab",
    "coronavirus created united states china",
    "air comes china import coronavirus",
    "coronavirus released china"
  )) |>
  filter(language == "en") |>
  filter(label == "misinformation")

# Distribution of final misinformation topics
table(covid_wuhan_misinfo$keywords)
table(covid_wuhan_misinfo$cluster_keywords)
```

## Social Network Construction

This network models the co-dissemination behavior of misinformation retweeters. While the exact paths of information transmission are unknown, this co-spreader network captures the structural relationships that may facilitate misinformation diffusion.

### Co-Retweet Network

The `co-retweet` network represents a co-dissemination behavior among retweeters. A tie is created between two users only if they both retweeted the same specific misinformation tweet, which is identified by a shared `tweet_id` in `user_retweeted_tweet.csv` file. Each edge is weighted by the number of such co-retweeting events, reflecting how often the same pair of users jointly retweeted the same pieces of misinformation. Though this relationship does not suggest that a paired users share the same opinion, it captures direct and synchronous amplification of specific misinformation claim in tweets. Therefore, by analyzing the weighted connections among pairs of retweeters, this network checks which retweeters are central to the misinformation amplification/dissemination process, and whether specific communities or cliques form around the repeated propagation of misinformation. 

```{r}
# Extract misinformation-related tweets id
misinfo_tweet_id <- unique(covid_wuhan_misinfo$tweet_id)

# Identify pairs of users who co-retweeted the same misinformation tweet
co_retweet_edges <- user_retweet |> 
  filter(tgt %in% misinfo_tweet_id) |> 
  rename(tweet_id = tgt, retweeter_id = src) |> 
  group_by(tweet_id) |> 
  summarise(
    pairs = list(as.data.frame(t(combn(retweeter_id, 2)))), 
    .groups = "drop"
  ) |> 
  unnest(pairs) |> 
  mutate(
    user_1 = pmin(V1, V2), # Ensure lower ID comes first
    user_2 = pmax(V1, V2) # Ensure higher ID comes second
  ) |> 
  select(user_1, user_2) |> 
  group_by(user_1, user_2) |> 
  summarise(weight = n(), .groups = "drop") |> 
  mutate(type = "co-retweet") |>
  filter(user_1 != user_2) |>
  mutate(
    user_1 = as.character(user_1),
    user_2 = as.character(user_2)
  )

# Obtain the full list of unique users involved
all_retweeters <- unique(c(
  covid_wuhan_misinfo$retweeter_id,  
  co_retweet_edges$user_1, 
  co_retweet_edges$user_2
)) |> 
  as.character() |> 
  sort()

# Create initial matrix
adj_matrix_co_retweet <- acast(
  co_retweet_edges, 
  user_1 ~ user_2, 
  value.var = "weight", 
  fill = 0
)

# Ensure matrix completeness by adding missing rows and columns
missing_rows <- setdiff(all_retweeters, rownames(adj_matrix_co_retweet))
missing_cols <- setdiff(all_retweeters, colnames(adj_matrix_co_retweet))

if (length(missing_rows) > 0) {
  adj_matrix_co_retweet <- rbind(
    adj_matrix_co_retweet, 
    matrix(0, nrow = length(missing_rows), ncol = ncol(adj_matrix_co_retweet), 
           dimnames = list(missing_rows, colnames(adj_matrix_co_retweet)))
  )
}

if (length(missing_cols) > 0) {
  adj_matrix_co_retweet <- cbind(
    adj_matrix_co_retweet, 
    matrix(0, nrow = nrow(adj_matrix_co_retweet), ncol = length(missing_cols), 
           dimnames = list(rownames(adj_matrix_co_retweet), missing_cols))
  )
}

# Reorder the matrix to align rows and columns
adj_matrix_co_retweet <- adj_matrix_co_retweet[all_retweeters, all_retweeters]

# Export the adjacency matrix for further analysis
write.csv(adj_matrix_co_retweet, "data/adj_matrix_co_retweet.csv", row.names = TRUE)

# Check dimensions of the final matrix
ncol(adj_matrix_co_retweet)
nrow(adj_matrix_co_retweet)

table(co_retweet_edges$weight)
```
### Co-Retweet (Quote Pathway)

The **Co-Retweet (Quote Pathway)** Network captures relational ties between users who both engaged in the dissemination (i.e., retweeting) of misinformation content either by a) retweeting original misinformation tweets, or b) retweeting tweets that explicitly quoting misinformation tweets. In this network, a tie is formed between two users if they each retweeted at least one tweet that is either a misinformation tweet or a tweet quoting misinformation pieces. This approach treats both direct and indirect engagement through the quoting mechanism as part of the broader misinformation propagation process, enabling analyzing how users contribute to narrative amplification across different dissemination paths. The weight of each edge represents the number of times two users jointly engaged in this form of retweet behavior.

```{r}
# Load quote relationships between tweets (quoting tweet & quoted tweet)

quote_relations <- read_csv("data/mumin_csv/reply_quote_of_tweet.csv") |>
  filter(tgt %in% misinfo_tweet_id | src %in% misinfo_tweet_id) |> 
  rename(
    quoted_tweet_id = tgt, # The misinformation tweet being quoted
    quoting_tweet_id = src # The tweet that quotes the misinformation tweet
  )

# Create the complete set of tweets relevant to the quote pathway
quote_path_tweet_ids <- unique(c(
  quote_relations$quoted_tweet_id , # Original misinformation tweets
  quote_relations$quoting_tweet_id # Tweets that quoted misinformation
))

# Find all users who retweeted these tweets
quote_path_retweets <- covid_wuhan_misinfo |> 
  filter(tweet_id %in% quote_path_tweet_ids) 

# Generate co-retweet edges based on shared retweeting of these tweets
co_retweet_quote_path_edges <- quote_path_retweets |>
  group_by(tweet_id) |>
  summarise(
    pairs = list(as.data.frame(t(combn(retweeter_id, 2)))), 
    .groups = "drop"
  ) |>
  unnest(pairs) |>
  mutate(
    user_1 = pmin(V1, V2),
    user_2 = pmax(V1, V2)
  ) |>
  select(user_1, user_2) |>
  group_by(user_1, user_2) |>
  summarise(weight = n(), .groups = "drop") |>
  mutate(type = "co-retweet-quote-path") |>
  filter(user_1 != user_2) |> 
  mutate(
    user_1 = as.character(user_1),
    user_2 = as.character(user_2)
  )

# Prepare full user list
all_retweeters_quote <- unique(c(
  covid_wuhan_misinfo$retweeter_id, 
  co_retweet_quote_path_edges$user_1, 
  co_retweet_quote_path_edges$user_2
)) |> 
  as.character() |> 
  sort()

# Create the adjacency matrix
adj_matrix_co_retweet_quote_path <- acast(
  co_retweet_quote_path_edges, 
  user_1 ~ user_2, 
  value.var = "weight", 
  fill = 0
)

# Add missing rows and columns to complete the matrix
missing_rows <- setdiff(all_retweeters_quote, rownames(adj_matrix_co_retweet_quote_path))
missing_cols <- setdiff(all_retweeters_quote, colnames(adj_matrix_co_retweet_quote_path))

if (length(missing_rows) > 0) {
  adj_matrix_co_retweet_quote_path <- rbind(
    adj_matrix_co_retweet_quote_path, 
    matrix(0, nrow = length(missing_rows), ncol = ncol(adj_matrix_co_retweet_quote_path), 
           dimnames = list(missing_rows, colnames(adj_matrix_co_retweet_quote_path)))
  )
}

if (length(missing_cols) > 0) {
  adj_matrix_co_retweet_quote_path <- cbind(
    adj_matrix_co_retweet_quote_path, 
    matrix(0, nrow = nrow(adj_matrix_co_retweet_quote_path), ncol = length(missing_cols), 
           dimnames = list(rownames(adj_matrix_co_retweet_quote_path), missing_cols))
  )
}

# Ensure matrix symmetry and proper ordering
adj_matrix_co_retweet_quote_path <- adj_matrix_co_retweet_quote_path[all_retweeters_quote, all_retweeters_quote]

# Save the matrix for further analysis
write.csv(adj_matrix_co_retweet_quote_path, "data/adj_matrix_co_retweet_quote_path.csv", row.names = TRUE)

# Output matrix dimensions for verification
nrow(adj_matrix_co_retweet_quote_path)
ncol(adj_matrix_co_retweet_quote_path)

table(co_retweet_quote_path_edges$weight)

```
```{r}
quote_data <-read_csv("data/mumin_csv/reply_quote_of_tweet.csv")

sum(quote_data$src %in% misinfo_tweet_id)

sum(quote_data$tgt %in% misinfo_tweet_id)

sum(misinfo_tweet_id %in% quote_data$tgt)

sum(misinfo_tweet_id %in% c(quote_data$src,quote_data$tgt))

covid_wuhan_misinfo
```


### Co-Retweet (Reply Pathway)

A tie is created between two users if they both retweeted tweets that are either:

A misinformation tweet (replied tweet), or

A tweet that replied to a misinformation tweet (replying tweet).


The **Co-Retweet (Reply Pathway)** Network captures relational ties between users who both retweeted tweets directly involved in misinformation discussions, either by a) retweeting misinformation tweets themselves, or b) retweeting the tweets that explicitly replied to such misinformation content.

This network reflects shared participation in the discourse and propagation surrounding misinformation narratives, regardless of whether users directly spread the misinformation or amplified discussions around it. The weight of each edge reflects the frequency of this shared engagement, providing insight into how conversations and content amplification coalesce to sustain misinformation diffusion.

```{r}
# Load reply relationships to identify reply chains around misinformation
reply_relations <- read_csv("data/mumin_csv/reply_reply_to_tweet.csv") |>
  filter(tgt %in% misinfo_tweet_id | src %in% misinfo_tweet_id) |> 
  rename(
    replied_tweet_id = tgt, # The misinformation tweet being replied to
    replying_tweet_id = src # The tweet that replies to the misinformation tweet
  )

# Step 1: Create complete set of tweets involved in reply chains related to misinformation
reply_path_tweet_ids <- unique(c(
  reply_relations$replied_tweet_id, 
  reply_relations$replying_tweet_id
))

# Step 2: Find all users who retweeted these tweets (participating in the reply pathway)
reply_path_retweets <- covid_wuhan_misinfo |> 
  filter(tweet_id %in% reply_path_tweet_ids)

# Step 3: Generate Co-Reply Edges based on shared retweeting of reply-path tweets
co_retweet_reply_path_edges <- reply_path_retweets |>
  group_by(tweet_id) |>
  summarise(
    pairs = list(as.data.frame(t(combn(retweeter_id, 2)))), 
    .groups = "drop"
  ) |>
  unnest(pairs) |>
  mutate(
    user_1 = pmin(V1, V2), 
    user_2 = pmax(V1, V2)
  ) |>
  select(user_1, user_2) |>
  group_by(user_1, user_2) |>
  summarise(weight = n(), .groups = "drop") |>
  mutate(type = "co-retweet-reply-path") |>
  filter(user_1 != user_2) |>
  mutate(
    user_1 = as.character(user_1),
    user_2 = as.character(user_2)
  )

# Prepare full user list
all_retweeters_reply <- unique(c(
  covid_wuhan_misinfo$retweeter_id, 
  co_retweet_reply_path_edges$user_1, 
  co_retweet_reply_path_edges$user_2
)) |> 
  as.character() |> 
  sort()

# Create the adjacency matrix
adj_matrix_co_retweet_reply_path <- acast(
  co_retweet_reply_path_edges, 
  user_1 ~ user_2, 
  value.var = "weight", 
  fill = 0
)

# Add missing rows and columns to complete the matrix
missing_rows <- setdiff(all_retweeters_reply, rownames(adj_matrix_co_retweet_reply_path))
missing_cols <- setdiff(all_retweeters_reply, colnames(adj_matrix_co_retweet_reply_path))

if (length(missing_rows) > 0) {
  adj_matrix_co_retweet_reply_path <- rbind(
    adj_matrix_co_retweet_reply_path, 
    matrix(0, nrow = length(missing_rows), ncol = ncol(adj_matrix_co_retweet_reply_path), 
           dimnames = list(missing_rows, colnames(adj_matrix_co_retweet_reply_path)))
  )
}

if (length(missing_cols) > 0) {
  adj_matrix_co_retweet_reply_path <- cbind(
    adj_matrix_co_retweet_reply_path, 
    matrix(0, nrow = nrow(adj_matrix_co_retweet_reply_path), ncol = length(missing_cols), 
           dimnames = list(rownames(adj_matrix_co_retweet_reply_path), missing_cols))
  )
}

# Ensure matrix symmetry and proper ordering
adj_matrix_co_retweet_reply_path <- adj_matrix_co_retweet_reply_path[all_retweeters_reply, all_retweeters_reply]

# Save the matrix for further analysis
write.csv(adj_matrix_co_retweet_reply_path, "data/adj_matrix_co_retweet_reply_path.csv", row.names = TRUE)

# Output matrix dimensions for verification
nrow(adj_matrix_co_retweet_reply_path)
ncol(adj_matrix_co_retweet_reply_path)

table(co_retweet_reply_path_edges$weight)
```

### Follow

A directed edge from User A to User B indicates that User A follows User B. This network captures the potential flow of influence among misinformation retweeters and allows for the identification of opinion leaders and hierarchical structures in misinformation diffusion.

```{r}
# Load retweeter list
retweeter_id_misinfo <- unique(covid_wuhan_misinfo$retweeter_id)

# Load and filter directed follow edges
retweeter_follow_edges_directed <- read_csv("data/mumin_csv/user_follows_user.csv") |> 
  rename(follower = src, followee = tgt) |> 
  filter(follower %in% retweeter_id_misinfo & followee %in% retweeter_id_misinfo) |> 
  mutate(weight = 1, type = "follow_directed") |> 
  select(follower, followee, weight, type)

# Check if any edges exist
if (nrow(retweeter_follow_edges_directed) == 0) {
  message("No directed follow relationships found among misinformation retweeters.")
} else {
  # Create adjacency matrix
  all_retweeters <- sort(unique(c(
    covid_wuhan_misinfo$retweeter_id, 
    retweeter_follow_edges_directed$follower, 
    retweeter_follow_edges_directed$followee
  ))) |> as.character()

  adj_matrix_follow_directed <- matrix(
    0, 
    nrow = length(all_retweeters), 
    ncol = length(all_retweeters),
    dimnames = list(all_retweeters, all_retweeters)
  )

  # Fill matrix with edges
  apply(retweeter_follow_edges_directed, 1, function(row) {
    adj_matrix_follow_directed[row["follower"], row["followee"]] <<- 1
  })

  # Save matrix
  write.csv(adj_matrix_follow_directed, "data/adj_matrix_follow_directed.csv", row.names = TRUE)
}



```

Analysis of the follower network among misinformation retweeters revealed no recorded follower-followee relationships within this group. This indicates that users involved in the dissemination of COVID-19 origin misinformation acted largely as isolated agents rather than as members of a tightly connected social network. Such a pattern suggests that the spread of misinformation in this case was driven primarily by content virality and opportunistic engagement, rather than through established social ties or influencer-led dissemination.


# Analysis

## Visualization

### Co-retweet Net

#### Co-retweet Net 1st version

```{r}
# Load adjacency matrix
adj_matrix_co_retweet <- read.csv(
  "data/adj_matrix_co_retweet.csv", 
  row.names = 1, 
  check.names = FALSE
)

# Ensure all 112 nodes are included
all_retweeters <- as.character(sort(unique(c(
  rownames(adj_matrix_co_retweet), 
  colnames(adj_matrix_co_retweet), 
  covid_wuhan_misinfo$retweeter_id
))))

# Add missing rows/columns to adjacency matrix
missing_nodes <- setdiff(all_retweeters, rownames(adj_matrix_co_retweet))

if (length(missing_nodes) > 0) {
  adj_matrix_co_retweet <- rbind(
    adj_matrix_co_retweet, 
    matrix(0, nrow = length(missing_nodes), ncol = ncol(adj_matrix_co_retweet), 
           dimnames = list(missing_nodes, colnames(adj_matrix_co_retweet)))
  )
  adj_matrix_co_retweet <- cbind(
    adj_matrix_co_retweet, 
    matrix(0, nrow = nrow(adj_matrix_co_retweet), ncol = length(missing_nodes), 
           dimnames = list(rownames(adj_matrix_co_retweet), missing_nodes))
  )
}

# Ensure matrix is correctly ordered
adj_matrix_co_retweet <- adj_matrix_co_retweet[all_retweeters, all_retweeters]

# Build network object (undirected)
net_co_retweet <- network(as.matrix(adj_matrix_co_retweet), directed = FALSE, matrix.type = "adjacency")

# Assign group information
retweeter_group <- covid_wuhan_misinfo |>
  mutate(retweeter_id = as.character(retweeter_id)) |>
  select(retweeter_id, date, keywords) |>
  distinct() |>
  arrange(date) |>
  mutate(group = as.numeric(factor(paste(date, keywords), levels = unique(paste(date, keywords)))))

# Map group to all nodes, assign 0 to those without a group
node_groups <- retweeter_group$group[match(
  get.vertex.attribute(net_co_retweet, "vertex.names"), 
  retweeter_group$retweeter_id
)]
node_groups[is.na(node_groups)] <- 0  # Assign group 0 to unclassified nodes

set.vertex.attribute(net_co_retweet, "group", node_groups)

# Assign colors based on group
group_colors <- c("grey", "skyblue", "tomato", "orange", "forestgreen", "purple", "gold")  # Extend if needed
vertex_colors <- group_colors[pmin(node_groups + 1, length(group_colors))]  # +1 because group 0 is "grey"

# Final Network Plot - Full Graph
plot.network(
  net_co_retweet, 
  displaylabels = FALSE, 
  vertex.cex = 2, 
  vertex.col = vertex_colors, 
  main = "Co-Retweet Network (Including Isolated Nodes)"
)

# Optional: Plot Subgraphs by Group (if meaningful)
for (g in unique(node_groups)) {
  sub_g <- get.inducedSubgraph(
    net_co_retweet, 
    which(get.vertex.attribute(net_co_retweet, "group") == g)
  )
  plot.network(
    sub_g, 
    displaylabels = FALSE, 
    vertex.cex = 2, 
    vertex.col = group_colors[pmin(g + 1, length(group_colors))], 
    main = paste("Subgraph for Group", g)
  )
}


```




```{r}
# Load adjacency matrix
adj_matrix_co_retweet <- read.csv(
  "data/adj_matrix_co_retweet.csv", 
  row.names = 1, 
  check.names = FALSE
)

# Ensure all 112 nodes are included
all_retweeters <- as.character(sort(unique(c(
  rownames(adj_matrix_co_retweet), 
  colnames(adj_matrix_co_retweet), 
  covid_wuhan_misinfo$retweeter_id
))))

missing_nodes <- setdiff(all_retweeters, rownames(adj_matrix_co_retweet))

if (length(missing_nodes) > 0) {
  adj_matrix_co_retweet <- rbind(
    adj_matrix_co_retweet, 
    matrix(0, nrow = length(missing_nodes), ncol = ncol(adj_matrix_co_retweet), 
           dimnames = list(missing_nodes, colnames(adj_matrix_co_retweet)))
  )
  adj_matrix_co_retweet <- cbind(
    adj_matrix_co_retweet, 
    matrix(0, nrow = nrow(adj_matrix_co_retweet), ncol = length(missing_nodes), 
           dimnames = list(rownames(adj_matrix_co_retweet), missing_nodes))
  )
}

adj_matrix_co_retweet <- adj_matrix_co_retweet[all_retweeters, all_retweeters]

# Build network object
net_co_retweet <- network(as.matrix(adj_matrix_co_retweet), directed = FALSE, matrix.type = "adjacency")

# Assign Stage using (date, keywords) combinations
retweeter_stage <- covid_wuhan_misinfo |>
  mutate(retweeter_id = as.character(retweeter_id)) |>
  select(retweeter_id, date, keywords) |>
  distinct() |>
  arrange(date) |>
  mutate(
    combined_group = paste(date, keywords),
    stage = as.numeric(factor(combined_group, levels = unique(combined_group)))
  ) |>
  select(retweeter_id, stage)

# Map stage to nodes
node_stages <- retweeter_stage$stage[match(
  get.vertex.attribute(net_co_retweet, "vertex.names"), 
  retweeter_stage$retweeter_id
)]
node_stages[is.na(node_stages)] <- 0  # Assign "0" for undefined stage

set.vertex.attribute(net_co_retweet, "stage", node_stages)

# Assign colors based on stage (0-6)
stage_colors <- c("grey", "skyblue", "tomato", "orange", "forestgreen", "purple", "gold")  
vertex_colors <- stage_colors[pmin(node_stages + 1, length(stage_colors))]  # "+1" for stage 0

# Plot full network with stage-based coloring
plot.network(
  net_co_retweet, 
  displaylabels = FALSE, 
  vertex.cex = 2, 
  vertex.col = vertex_colors, 
  main = "Co-Retweet Network Colored by Stage"
)

```


#### Stage 1 Plot (Co-retweet Net)

```{r}
# Load Data and Build Full Network
adj_matrix <- read.csv("data/adj_matrix_co_retweet.csv", row.names = 1, check.names = FALSE)

net_full <- network(as.matrix(adj_matrix), directed = FALSE, matrix.type = "adjacency")

retweeter_stage <- covid_wuhan_misinfo |>
  mutate(retweeter_id = as.character(retweeter_id)) |>
  select(retweeter_id, date, keywords) |>
  distinct() |>
  arrange(date) |>
  mutate(
    group = as.numeric(factor(paste(date, keywords), levels = unique(paste(date, keywords))))
  ) |>
  select(retweeter_id, group, date, keywords)

node_names <- net_full %v% "vertex.names"

assigned_groups <- retweeter_stage$group[match(node_names, retweeter_stage$retweeter_id)]

set.vertex.attribute(net_full, "group", assigned_groups)

# Assign Current Stage Info
target_group <- 1  

stage_info <- retweeter_stage |> 
  filter(group == target_group) |> 
  distinct(date, keywords)

stage_date <- unique(stage_info$date)

stage_keywords <- unique(stage_info$keywords)

# Get Edge List and Filter Edges for Current Stage
edgelist <- as.edgelist(net_full)
v1 <- edgelist[, 1]
v2 <- edgelist[, 2]

group_v1 <- assigned_groups[v1]
group_v2 <- assigned_groups[v2]
keep_edges <- which(group_v1 == target_group & group_v2 == target_group)

# Build Stage Adjacency Matrix
adj_stage1 <- matrix(0, nrow = length(node_names), ncol = length(node_names))
rownames(adj_stage1) <- colnames(adj_stage1) <- node_names

if (length(keep_edges) > 0) {
  for (idx in keep_edges) {
    adj_stage1[v1[idx], v2[idx]] <- 1
    adj_stage1[v2[idx], v1[idx]] <- 1
  }
}

# Save Stage 1 Adjacency Matrix
write.csv(adj_stage1, "data/adj_matrix_stage1.csv", row.names = TRUE)

# Build Network Object for Stage 1
net_stage1 <- network(adj_stage1, directed = FALSE, matrix.type = "adjacency")

# Visualization Settings
plot_title <- paste0("Co-Retweet Network: Stage ", target_group)

plot_subtitle <- paste0("Misinformation Claim: ", stage_keywords, " | Claim Utterd on: ", stage_date)

edge_alpha <- 0.1 
edge_width <- 0.2  

set.seed(42)
layout_coords <- gplot(
  net_stage1, 
  gmode = "graph", 
  mode = "kamadakawai"
)

vertex_colors <- ifelse(
  assigned_groups == target_group, 
  "steelblue", 
  "gray"
)

# Save PNG
png("data/Co-Retweet-Stage1.png", width = 2200, height = 2100, res = 300)
par(family = "serif", mar = c(6, 0, 3, 1))

plot.network(
  net_stage1,
  displaylabels = FALSE,
  vertex.cex = 1,
  vertex.col = vertex_colors,
  coord = layout_coords,
  edge.lwd = edge_width,
  edge.col = adjustcolor("black", alpha.f = edge_alpha),
  main = plot_title
)

# Add Subtitle
mtext(
  text = plot_subtitle,
  side = 1, 
  line = 3, 
  cex = 0.8, 
  family = "serif"
)

# Add Legend
legend(
  "right",
  legend = c("Stage 1 Retweeters", "Other Retweeters"), 
  col = c("steelblue", "gray"), 
  pch = 19, 
  pt.cex = 1,  
  cex = 0.6,                    
  text.col = "black", 
  bty = "n",                    
  y.intersp = 1.5                      
)
```

#### Stage 2 Plot (Co-retweet Net)

```{r}
# Assign Current Stage Info
target_group <- 2  

stage_info <- retweeter_stage |> 
  filter(group == target_group) |> 
  distinct(date, keywords)

stage_date <- unique(stage_info$date)
stage_keywords <- unique(stage_info$keywords)

# Get Edge List and Filter Edges for Current Stage
group_v1 <- assigned_groups[v1]
group_v2 <- assigned_groups[v2]
keep_edges <- which(group_v1 == target_group & group_v2 == target_group)

# Build Stage 2 Adjacency Matrix
adj_stage2 <- matrix(0, nrow = length(node_names), ncol = length(node_names))
rownames(adj_stage2) <- colnames(adj_stage2) <- node_names

if (length(keep_edges) > 0) {
  for (idx in keep_edges) {
    adj_stage2[v1[idx], v2[idx]] <- 1
    adj_stage2[v2[idx], v1[idx]] <- 1
  }
}

# Save Stage 2 Adjacency Matrix
write.csv(adj_stage2, "data/adj_matrix_stage2.csv", row.names = TRUE)

# Build Network Object for Stage 2
net_stage2 <- network(adj_stage2, directed = FALSE, matrix.type = "adjacency")

# Visualization Settings
plot_title <- paste0("Co-Retweet Network: Stage ", target_group)
plot_subtitle <- paste0("Misinformation Claim: ", stage_keywords, " | Claim Utterd on: ", stage_date)

edge_alpha <- 0.1 
edge_width <- 0.2  

set.seed(42)
layout_coords <- gplot(
  net_stage2, 
  gmode = "graph", 
  mode = "kamadakawai"
)

vertex_colors <- ifelse(
  assigned_groups == target_group, 
  "steelblue", 
  "gray"
)

# Save PNG for Stage 2
png("data/Co-Retweet-Stage2.png", width = 2200, height = 2100, res = 300)
par(family = "serif", mar = c(6, 0, 3, 1))

plot.network(
  net_stage2,
  displaylabels = FALSE,
  vertex.cex = 1,
  vertex.col = vertex_colors,
  coord = layout_coords,
  edge.lwd = edge_width,
  edge.col = adjustcolor("black", alpha.f = edge_alpha),
  main = plot_title
)

# Add Subtitle
mtext(
  text = plot_subtitle,
  side = 1, 
  line = 3, 
  cex = 0.8, 
  family = "serif"
)

# Add Legend
legend(
  "right",
  legend = c("Stage 2 Retweeters", "Other Retweeters"), 
  col = c("steelblue", "gray"), 
  pch = 19, 
  pt.cex = 1,  
  cex = 0.6,                    
  text.col = "black", 
  bty = "n",                    
  y.intersp = 1.5                      
)

```

#### Stage 3 Plot (Co-retweet Net)

```{r}
# Assign Current Stage Info
target_group <- 3  

stage_info <- retweeter_stage |> 
  filter(group == target_group) |> 
  distinct(date, keywords)

stage_date <- unique(stage_info$date)
stage_keywords <- unique(stage_info$keywords)

# Get Edge List and Filter Edges for Current Stage
group_v1 <- assigned_groups[v1]
group_v2 <- assigned_groups[v2]
keep_edges <- which(group_v1 == target_group & group_v2 == target_group)

# Build Stage 3 Adjacency Matrix
adj_stage3 <- matrix(0, nrow = length(node_names), ncol = length(node_names))
rownames(adj_stage3) <- colnames(adj_stage3) <- node_names

if (length(keep_edges) > 0) {
  for (idx in keep_edges) {
    adj_stage3[v1[idx], v2[idx]] <- 1
    adj_stage3[v2[idx], v1[idx]] <- 1
  }
}

# Save Stage 3 Adjacency Matrix
write.csv(adj_stage3, "data/adj_matrix_stage3.csv", row.names = TRUE)

# Build Network Object for Stage 3
net_stage3 <- network(adj_stage3, directed = FALSE, matrix.type = "adjacency")

# Visualization Settings
plot_title <- paste0("Co-Retweet Network: Stage ", target_group)
plot_subtitle <- paste0("Misinformation Claim: ", stage_keywords, " | Claim Utterd on: ", stage_date)

edge_alpha <- 0.1 
edge_width <- 0.2  

set.seed(42)
layout_coords <- gplot(
  net_stage3, 
  gmode = "graph", 
  mode = "kamadakawai"
)

vertex_colors <- ifelse(
  assigned_groups == target_group, 
  "steelblue", 
  "gray"
)

# Save PNG for Stage 3
png("data/Co-Retweet-Stage3.png", width = 2200, height = 2100, res = 300)
par(family = "serif", mar = c(6, 0, 3, 1))

plot.network(
  net_stage3,
  displaylabels = FALSE,
  vertex.cex = 1,
  vertex.col = vertex_colors,
  coord = layout_coords,
  edge.lwd = edge_width,
  edge.col = adjustcolor("black", alpha.f = edge_alpha),
  main = plot_title
)

# Add Subtitle
mtext(
  text = plot_subtitle,
  side = 1, 
  line = 3, 
  cex = 0.8, 
  family = "serif"
)

# Add Legend
legend(
  "right",
  legend = c("Stage 3 Retweeters", "Other Retweeters"), 
  col = c("steelblue", "gray"), 
  pch = 19, 
  pt.cex = 1,  
  cex = 0.6,                    
  text.col = "black", 
  bty = "n",                    
  y.intersp = 1.5                      
)

dev.off()  # Close the PNG device

```

#### Stage 4 Plot (Co-retweet Net)

```{r}
# Assign Current Stage Info
target_group <- 4  

stage_info <- retweeter_stage |> 
  filter(group == target_group) |> 
  distinct(date, keywords)

stage_date <- unique(stage_info$date)
stage_keywords <- unique(stage_info$keywords)

# Get Edge List and Filter Edges for Current Stage
group_v1 <- assigned_groups[v1]
group_v2 <- assigned_groups[v2]
keep_edges <- which(group_v1 == target_group & group_v2 == target_group)

# Build Stage 4 Adjacency Matrix
adj_stage4 <- matrix(0, nrow = length(node_names), ncol = length(node_names))
rownames(adj_stage4) <- colnames(adj_stage4) <- node_names

if (length(keep_edges) > 0) {
  for (idx in keep_edges) {
    adj_stage4[v1[idx], v2[idx]] <- 1
    adj_stage4[v2[idx], v1[idx]] <- 1
  }
}

# Save Stage 4 Adjacency Matrix
write.csv(adj_stage4, "data/adj_matrix_stage4.csv", row.names = TRUE)

# Build Network Object for Stage 4
net_stage4 <- network(adj_stage4, directed = FALSE, matrix.type = "adjacency")

# Visualization Settings
plot_title <- paste0("Co-Retweet Network: Stage ", target_group)
plot_subtitle <- paste0("Misinformation Claim: ", stage_keywords, " | Claim Utterd on: ", stage_date)

edge_alpha <- 0.1 
edge_width <- 0.2  

set.seed(42)
layout_coords <- gplot(
  net_stage4, 
  gmode = "graph", 
  mode = "kamadakawai"
)

vertex_colors <- ifelse(
  assigned_groups == target_group, 
  "steelblue", 
  "gray"
)

# Save PNG for Stage 4
png("data/Co-Retweet-Stage4.png", width = 2200, height = 2100, res = 300)
par(family = "serif", mar = c(6, 0, 3, 1))

plot.network(
  net_stage4,
  displaylabels = FALSE,
  vertex.cex = 1,
  vertex.col = vertex_colors,
  coord = layout_coords,
  edge.lwd = edge_width,
  edge.col = adjustcolor("black", alpha.f = edge_alpha),
  main = plot_title
)

# Add Subtitle
mtext(
  text = plot_subtitle,
  side = 1, 
  line = 3, 
  cex = 0.8, 
  family = "serif"
)

# Add Legend
legend(
  "right",
  legend = c("Stage 4 Retweeters", "Other Retweeters"), 
  col = c("steelblue", "gray"), 
  pch = 19, 
  pt.cex = 1,  
  cex = 0.6,                    
  text.col = "black", 
  bty = "n",                    
  y.intersp = 1.5                      
)

```

#### Stage 5 Plot (Co-retweet Net)

```{r}
# Assign Current Stage Info
target_group <- 5  

stage_info <- retweeter_stage |> 
  filter(group == target_group) |> 
  distinct(date, keywords)

stage_date <- unique(stage_info$date)
stage_keywords <- unique(stage_info$keywords)

# Get Edge List and Filter Edges for Current Stage
group_v1 <- assigned_groups[v1]
group_v2 <- assigned_groups[v2]
keep_edges <- which(group_v1 == target_group & group_v2 == target_group)

# Build Stage 5 Adjacency Matrix
adj_stage5 <- matrix(0, nrow = length(node_names), ncol = length(node_names))
rownames(adj_stage5) <- colnames(adj_stage5) <- node_names

if (length(keep_edges) > 0) {
  for (idx in keep_edges) {
    adj_stage5[v1[idx], v2[idx]] <- 1
    adj_stage5[v2[idx], v1[idx]] <- 1
  }
}

# Save Stage 5 Adjacency Matrix
write.csv(adj_stage5, "data/adj_matrix_stage5.csv", row.names = TRUE)

# Build Network Object for Stage 5
net_stage5 <- network(adj_stage5, directed = FALSE, matrix.type = "adjacency")

# Visualization Settings
plot_title <- paste0("Co-Retweet Network: Stage ", target_group)
plot_subtitle <- paste0("Misinformation Claim: ", stage_keywords, " | Claim Utterd on: ", stage_date)

edge_alpha <- 0.1 
edge_width <- 0.2  

set.seed(42)
layout_coords <- gplot(
  net_stage5, 
  gmode = "graph", 
  mode = "kamadakawai"
)

vertex_colors <- ifelse(
  assigned_groups == target_group, 
  "steelblue", 
  "gray"
)

# Save PNG for Stage 5
png("data/Co-Retweet-Stage5.png", width = 2200, height = 2100, res = 300)
par(family = "serif", mar = c(6, 0, 3, 1))

plot.network(
  net_stage5,
  displaylabels = FALSE,
  vertex.cex = 1,
  vertex.col = vertex_colors,
  coord = layout_coords,
  edge.lwd = edge_width,
  edge.col = adjustcolor("black", alpha.f = edge_alpha),
  main = plot_title
)

# Add Subtitle
mtext(
  text = plot_subtitle,
  side = 1, 
  line = 3, 
  cex = 0.8, 
  family = "serif"
)

# Add Legend
legend(
  "right",
  legend = c("Stage 5 Retweeters", "Other Retweeters"), 
  col = c("steelblue", "gray"), 
  pch = 19, 
  pt.cex = 1,  
  cex = 0.6,                    
  text.col = "black", 
  bty = "n",                    
  y.intersp = 1.5                      
)

```

#### Stage 6 Plot (Co-retweet Net)

```{r}
# Assign Current Stage Info
target_group <- 6  

stage_info <- retweeter_stage |> 
  filter(group == target_group) |> 
  distinct(date, keywords)

stage_date <- unique(stage_info$date)
stage_keywords <- unique(stage_info$keywords)

group_v1 <- assigned_groups[v1]
group_v2 <- assigned_groups[v2]
keep_edges <- which(group_v1 == target_group & group_v2 == target_group)

adj_stage6 <- matrix(0, nrow = length(node_names), ncol = length(node_names))
rownames(adj_stage6) <- colnames(adj_stage6) <- node_names

if (length(keep_edges) > 0) {
  for (idx in keep_edges) {
    adj_stage6[v1[idx], v2[idx]] <- 1
    adj_stage6[v2[idx], v1[idx]] <- 1
  }
}

write.csv(adj_stage6, "data/adj_matrix_stage6.csv", row.names = TRUE)

net_stage6 <- network(adj_stage6, directed = FALSE, matrix.type = "adjacency")

plot_title <- paste0("Co-Retweet Network: Stage ", target_group)
plot_subtitle <- paste0("Misinformation Claim: ", stage_keywords, " | Claim Utterd on: ", stage_date)

edge_alpha <- 0.1 
edge_width <- 0.2  

set.seed(42)
layout_coords <- gplot(
  net_stage6, 
  gmode = "graph", 
  mode = "kamadakawai"
)

vertex_colors <- ifelse(
  assigned_groups == target_group, 
  "steelblue", 
  "gray"
)

png("data/Co-Retweet-Stage6.png", width = 2200, height = 2100, res = 300)
par(family = "serif", mar = c(6, 0, 3, 1))

plot.network(
  net_stage6,
  displaylabels = FALSE,
  vertex.cex = 1,
  vertex.col = vertex_colors,
  coord = layout_coords,
  edge.lwd = edge_width,
  edge.col = adjustcolor("black", alpha.f = edge_alpha),
  main = plot_title
)

mtext(
  text = plot_subtitle,
  side = 1, 
  line = 3, 
  cex = 0.8, 
  family = "serif"
)

legend(
  "right",
  legend = c("Stage 6 Retweeters", "Other Retweeters"), 
  col = c("steelblue", "gray"), 
  pch = 19, 
  pt.cex = 1,  
  cex = 0.6,                    
  text.col = "black", 
  bty = "n",                    
  y.intersp = 1.5                      
)

```



## Basic Network Metrics

### Co-retweet Net

```{r}
# Load 6 Stage Net
co_retweet_stage_networks <- list(
  Stage1 = read.csv("data/adj_matrix_stage1.csv", row.names = 1) |> 
    as.matrix() |> 
    network(directed = FALSE, matrix.type = "adjacency"),
  
  Stage2 = read.csv("data/adj_matrix_stage2.csv", row.names = 1) |> 
    as.matrix() |> 
    network(directed = FALSE, matrix.type = "adjacency"),
  
  Stage3 = read.csv("data/adj_matrix_stage3.csv", row.names = 1) |> 
    as.matrix() |> 
    network(directed = FALSE, matrix.type = "adjacency"),
  
  Stage4 = read.csv("data/adj_matrix_stage4.csv", row.names = 1) |> 
    as.matrix() |> 
    network(directed = FALSE, matrix.type = "adjacency"),
  
  Stage5 = read.csv("data/adj_matrix_stage5.csv", row.names = 1) |> 
    as.matrix() |> 
    network(directed = FALSE, matrix.type = "adjacency"),
  
  Stage6 = read.csv("data/adj_matrix_stage6.csv", row.names = 1) |> 
    as.matrix() |> 
    network(directed = FALSE, matrix.type = "adjacency")
)

```

```{r}

compute_local_clustering <- function(net) {
  adj_mat <- as.matrix.network.adjacency(net)
  n <- nrow(adj_mat)
  
  clustering_vals <- numeric(n)
  
  for (i in 1:n) {
    neighbors <- which(adj_mat[i, ] == 1)
    k <- length(neighbors)
    if (k < 2) {
      clustering_vals[i] <- NA  # Êó†Ê≥ïÂΩ¢Êàê‰∏âËßíÂΩ¢ÔºåËÆæ‰∏∫ NA
    } else {
      subgraph <- adj_mat[neighbors, neighbors]
      actual_edges <- sum(subgraph) / 2  # Êó†ÂêëÂõæ
      possible_edges <- k * (k - 1) / 2
      clustering_vals[i] <- actual_edges / possible_edges
    }
  }
  
  return(clustering_vals)
}


compute_metrics <- function(net) {
  data.frame(
    Nodes = network.size(net),
    Edges = network.edgecount(net),
    Density = gden(net),
    Average_Degree = mean(degree(net), na.rm = TRUE),
    Degree_Centralization = centralization(net, degree, mode = "freeman"),
    Closeness_Centralization = centralization(net, closeness, mode = "freeman"),
    Betweenness_Centralization = centralization(net, betweenness, mode = "freeman"),
    Transitivity_Global = gtrans(net, mode = "graph"),
    Transitivity_Local = mean(compute_local_clustering(net), na.rm = TRUE)  # Êõø‰ª£ clustering.coefficient
  )
}


```


```{r}
metrics_results <- lapply(co_retweet_stage_networks, compute_metrics)
metrics_df <- do.call(rbind, metrics_results)
metrics_df$Stage <- rownames(metrics_df)

# reorder columns
metrics_df <- metrics_df[, c("Stage", setdiff(names(metrics_df), "Stage"))]

print(metrics_df)

```

The analysis of basic network metrics across the six stages reveals a highly clustered network structure with consistently high global and local transitivity values, suggesting that misinformation retweet activities predominantly occurred within tightly-knit groups. Notably, Stage 2 exhibits the highest average degree and network density, indicating peak activity and diffusion potential at this stage. Conversely, low centralization scores across closeness and betweenness measures imply the absence of prominent gatekeepers or highly influential intermediaries within the network.


## tERGM


```{r}

```


```{r}

```

```{r}
# ËØªÂèñ co-retweet adjacency matrix
adj_matrix_co_retweet <- read.csv(
  "data/adj_matrix_co_retweet.csv", 
  row.names = 1, 
  check.names = FALSE  # ÂÖ≥ÈîÆÂèÇÊï∞ÔºåÁ¶ÅÊ≠¢Ëá™Âä®Âä† x ÂâçÁºÄ
)

# ÊûÑÂª∫ network ÂØπË±°ÔºàÊó†ÂêëÂõæÔºâ
net_co_retweet <- network(as.matrix(adj_matrix_co_retweet), directed = FALSE, matrix.type = "adjacency")

get.vertex.attribute(net_co_retweet, "vertex.names")

# Ëé∑ÂèñÂàÜÁªÑ‰ø°ÊÅØ
retweeter_group <- covid_wuhan_misinfo |>
  mutate(retweeter_id = as.character(retweeter_id)) |>
  select(retweeter_id, date, keywords) |>
  distinct() |>
  arrange(date) |>
  mutate(group = as.numeric(factor(paste(date, keywords), levels = unique(paste(date, keywords)))))

# Â∞Ü Group ‰ø°ÊÅØÊ∑ªÂä†Âà∞ËäÇÁÇπÂ±ûÊÄß‰∏≠
set.vertex.attribute(
  net_co_retweet, 
  "group", 
  retweeter_group$group[match(get.vertex.attribute(net_co_retweet, "vertex.names"), retweeter_group$retweeter_id)]
)

get.vertex.attribute(net_co_retweet, "group")

for (g in 1:6) {
  sub_g <- get.inducedSubgraph(net_co_retweet, 
                               which(get.vertex.attribute(net_co_retweet, "group") == g))
  plot.network(sub_g, 
                displaylabels = FALSE, 
                vertex.cex = 1, 
                vertex.col = "skyblue", 
                main = paste("Subgraph for Group", g))
}


```

```{r}
# 1. Ëé∑ÂèñÈò∂ÊÆµ‰ø°ÊÅØ
group_stages <- sort(unique(get.vertex.attribute(net_co_retweet, "group")))

results <- data.frame()  # Ê∏ÖÁ©∫ÊàñÂàùÂßãÂåñ

for (g in group_stages) {
  sub_nodes <- which(get.vertex.attribute(net_co_retweet, "group") <= g)
  sub_g <- get.inducedSubgraph(net_co_retweet, v = sub_nodes)
  
  adj_mat <- as.matrix.network(sub_g, matrix.type = "adjacency")
  
  results <- rbind(results, data.frame(
    Stage = g,
    Nodes = network.size(sub_g),
    Edges = network.edgecount(sub_g),
    Density = gden(sub_g),
    Degree_Centralization = centralization(adj_mat, FUN = degree, mode = "graph"),
    Closeness_Centralization = centralization(adj_mat, FUN = closeness, mode = "graph"),
    Betweenness_Centralization = centralization(adj_mat, FUN = betweenness, mode = "graph"),
    Transitivity = gtrans(sub_g, mode = "graph")
  ))
}
# 4. Êü•ÁúãÁªìÊûú
print(results)
```


1Ô∏è‚É£ ÂØÜÂ∫¶ (Density) ‰∏ãÈôçÊ∏ÖÊô∞ÂèØËßÅ
Á¨¨‰∏ÄÈò∂ÊÆµÂØÜÂ∫¶ = 1.0ÔºåÂÆåÂÖ®ÂõæÔºàÊØè‰∏™ËäÇÁÇπÈÉΩ‰∫íÁõ∏ÂÖ≥ËÅîÔºâ„ÄÇ

ÈöèÁùÄËäÇÁÇπÂ¢ûÂä†ÔºåÂØÜÂ∫¶ËøÖÈÄü‰∏ãÈôçÂà∞ 0.13 Â∑¶Âè≥„ÄÇ

üìå Ëß£ÈáäÔºö

ÊúÄÂàùÁöÑÊ†∏ÂøÉ‰º†Êí≠ËÄÖÈ´òÂ∫¶‰∫íÂä®ÔºåÂΩ¢Êàê‰∫ÜÂ∞èËßÑÊ®°ÁöÑ‚ÄúÁ≤æËã±‰º†Êí≠Âúà‚ÄùÔºàÂ¶ÇÂØÜÈó≠Â∞èÂõ¢‰ΩìÔºâ„ÄÇ

ÈöèÁùÄ‰º†Êí≠Êâ©Êï£ÔºåËæπÁºòÁî®Êà∑ÔºàÂ§ñÂõ¥ retweetersÔºâË¢´ÈÄêÊ∏êÂê∏ÂºïËøõÊù•Ôºå‰ΩÜ‰ªñ‰ª¨‰πãÈó¥Âπ∂Ê≤°ÊúâÂ§ßÈáèÁöÑÁõ∏‰∫íËÅîÁ≥ªÔºå‰ªÖ‰∏éÊ†∏ÂøÉ‰º†Êí≠ËÄÖÊàñÂ∞ëÊï∞Áî®Êà∑ËøûÊé•ÔºåÂØºËá¥ÁΩëÁªúË∂äÊù•Ë∂äÁ®ÄÁñè„ÄÇ

2Ô∏è‚É£ Degree Centralization Á®çÂæÆ‰∏äÂçáÔºå‰ΩÜÂßãÁªàÂÅè‰Ωé
‰ªé 0.048 Á®≥ÂÆö‰∏äÂçáÂà∞ 0.086„ÄÇ

Ë°®ÊòéÔºö

ËôΩÁÑ∂ÊúâÈÉ®ÂàÜ‚ÄúË∂ÖÁ∫ß‰º†Êí≠ËÄÖ‚ÄùËäÇÁÇπÂá∫Áé∞ÔºàÊã•ÊúâÊõ¥Â§öËøûÊé•ÔºâÔºå

‰ΩÜÊï¥‰∏™ÁΩëÁªúÂπ∂Ê≤°ÊúâÂΩ¢ÊàêÂº∫ÁÉàÁöÑ‚ÄúÂçï‰∏ÄÊ†∏ÂøÉÊéßÂà∂‚ÄùÁé∞Ë±°ÔºåËøòÊòØËæÉ‰∏∫ÂàÜÊï£ÁöÑ„ÄÇ

üìå ÂØπÊØîÂàÜÊûêÔºö

ËøôÁ¨¶ÂêàË∞£Ë®Ä‰º†Êí≠‰∏≠ÁöÑ‚ÄúÂéª‰∏≠ÂøÉÂåñÁâπÂæÅ‚ÄùÔºö

ËôΩÁÑ∂ÊúâÂΩ±ÂìçÂäõÂ§ßÁöÑÁî®Êà∑Ôºå‰ΩÜ‰πüÊúâÂ§ßÈáè‰∏≠Â∞èËäÇÁÇπÂèÇ‰∏é‰º†Êí≠ÔºåÂΩ¢Êàê‰∫Ü‚ÄúÂàÜÂ∏ÉÂºèÊâ©Êï£‚Äù„ÄÇ

3Ô∏è‚É£ Closeness Âíå Betweenness Centralization ‰∏ÄÁõ¥‰∏∫ 0
üìå Ëß£ÈáäÔºö

ËøôÊÑèÂë≥ÁùÄÔºö

Ê≤°ÊúâËäÇÁÇπÁúüÊ≠£ÊâøÊãÖ‚Äú‰∏≠‰ªãÊ°•Ê¢Å‚ÄùÁöÑËßíËâ≤Ôºàbetweenness = 0Ôºâ„ÄÇ

Ê≤°ÊúâËäÇÁÇπÂú®‰ø°ÊÅØ‰º†ÈÄíË∑ØÂæÑ‰∏≠Âç†ÊçÆÊòæËëó‰ΩçÁΩÆÔºàcloseness = 0Ôºâ„ÄÇ

ÂæàÂèØËÉΩÊòØÂõ†‰∏∫Ëøô‰∏™ÁΩëÁªúÊòØ Êó†ÂêëÂõæ‰∏îÂ∞èÂõ¢‰ΩìÂÜÖÈÉ®Âº∫ËøûÊé•ÔºåÂØºËá¥Â§ßÈÉ®ÂàÜËäÇÁÇπË∑ØÂæÑÈïøÂ∫¶Áõ∏‰ººÔºåÊàñÊ†πÊú¨‰∏çÈúÄË¶ÅÈÄöËøá‰∏≠‰ªãËäÇÁÇπÂ∞±ËÉΩÁõ¥Êé•ËøûÊé•„ÄÇ

üìå Ê¥ûÂØüÔºö

ËøôÊòØÂÖ∏ÂûãÁöÑ‚ÄúÁæ§Âõ¢Âºè‰º†Êí≠‚ÄùÔºå‰∏çÂêåÁæ§‰ΩìÂÜÖÈÉ®ËøûÈÄöÁ¥ßÂØÜÔºå‰ΩÜÁæ§‰Ωì‰πãÈó¥ÁöÑÊ°•Ê¢ÅËäÇÁÇπÁ®ÄÁº∫„ÄÇ

Á¨¶Âêà Echo Chamber Theory ÁöÑÊèèËø∞ ‚Äî‚Äî ‰ø°ÊÅØÂú®Áæ§‰ΩìÂÜÖÈÉ®ÂèçÂ§ç‰º†Êí≠ÔºåÂæàÈöæË∑®Áæ§‰Ωì‰º†ÈÄí„ÄÇ

4Ô∏è‚É£ Transitivity (ÂÖ®Â±ÄËÅöÁ±ªÁ≥ªÊï∞) ÊûÅÈ´ò
‰∏ÄÁõ¥Áª¥ÊåÅÂú® Êé•Ëøë 1.0ÔºåÂì™ÊÄïËäÇÁÇπÊï∞ÈáèÂ¢ûÂä†‰πüÂè™ÊúâÊûÅÂæÆÂº±‰∏ãÈôç„ÄÇ

üìå Ëß£ÈáäÔºö

ÁΩëÁªú‰∏≠ÁªùÂ§ßÈÉ®ÂàÜ‰∏âÂÖÉÈó≠ÁéØÈÉΩÂ≠òÂú® ‚Äî‚Äî Êç¢Âè•ËØùËØ¥Ôºå‚ÄúÊúãÂèãÁöÑÊúãÂèã‰πüÊòØÊúãÂèã‚Äù„ÄÇ

ÂÜçÊ¨°Âç∞ËØÅ‰∫ÜÈ´òÂ∫¶Áæ§‰ΩìÂåñ„ÄÅÂ∞èÂúàÂ≠êÂº∫ËøûÊé•ÁöÑ‰º†Êí≠Ê®°Âºè„ÄÇ

üìä ÁªºÂêàÊ¥ûÂØüÊÄªÁªì
ÂàùÊúüÊ†∏ÂøÉÂ∞èÂõ¢‰Ωì‰∏ªÂØºÔºåÈöèÁùÄ‰º†Êí≠ÊºîÂåñÔºåÁΩëÁªúËßÑÊ®°Êâ©Â§ß‰ΩÜËÅîÁ≥ªÁ®ÄÁñè„ÄÇ

ÁΩëÁªú‰øùÊåÅÈ´òÂ∫¶ÁöÑËÅöÁ±ªÂíåÂ±ÄÈÉ®ÊÄßÔºåÁæ§‰Ωì‰πãÈó¥ÁöÑ‰º†Êí≠Â£ÅÂûíÂº∫ÁÉà„ÄÇ

‰ø°ÊÅØÁöÑË∑®Áæ§‰ΩìÊâ©Êï£ËÉΩÂäõËæÉÂº±ÔºåÁ¨¶Âêà ÂõûÈü≥ÂÆ§ÊïàÂ∫îÔºàEcho ChamberÔºâ Âíå Âéª‰∏≠ÂøÉÂåñÁöÑÂàÜÊï£‰º†Êí≠ÁâπÂæÅ„ÄÇ

Ê≤°ÊúâÂΩ¢ÊàêÂÖ∏ÂûãÁöÑ‚ÄúÊòéÊòüÁî®Êà∑‰∏ªÂØºÁöÑ‰∏≠ÂøÉÂåñÊâ©Êï£‚ÄùÔºåËÄåÊòØÂ§öÁæ§‰Ωì„ÄÅÂ∞èÂúàÂ≠êÂú®Áã¨Á´ã‰º†Êí≠„ÄÇ


```{r}
results <- data.frame()  # Ê∏ÖÁ©∫ÊàñÂàùÂßãÂåñ

for (g in group_stages) {
  sub_nodes <- which(get.vertex.attribute(net_co_retweet, "group") == g)
  sub_g <- get.inducedSubgraph(net_co_retweet, v = sub_nodes)
  
  adj_mat <- as.matrix.network(sub_g, matrix.type = "adjacency")
  
  results <- rbind(results, data.frame(
    Stage = g,
    Nodes = network.size(sub_g),
    Edges = network.edgecount(sub_g),
    Density = gden(sub_g),
    Degree_Centralization = centralization(adj_mat, FUN = degree, mode = "graph"),
    Closeness_Centralization = centralization(adj_mat, FUN = closeness, mode = "graph"),
    Betweenness_Centralization = centralization(adj_mat, FUN = betweenness, mode = "graph"),
    Transitivity = gtrans(sub_g, mode = "graph")
  ))
}
# 4. Êü•ÁúãÁªìÊûú
print(results)


```


1Ô∏è‚É£ ÂàùÂßãÈò∂ÊÆµ (Stage 1)
ÂÆåÁæéÁöÑ ÂÆåÂÖ®Âõæ (Density=1)ÔºåËäÇÁÇπ‰πãÈó¥ÂÖ®ËøûÊé•„ÄÇ

ÂêÑÁßç‰∏≠ÂøÉÊÄß‰∏∫ 0 ‚Üí ÊùÉÂäõÊûÅÂ∫¶ÂùáË°°ÔºåÊ≤°ÊúâÊòéÊòæÁöÑÊ†∏ÂøÉËäÇÁÇπ„ÄÇ

Transitivity = 1 ‚Üí ÂÆåÁæéÁöÑ‰∏âËßíÈó≠ÁéØÔºåËøôÈÄöÂ∏∏ÂèëÁîüÂú®Â∞èÂõ¢‰Ωì„ÄÅÂêåË¥®ÊÄßÊûÅÈ´òÁöÑÂúàÂ≠ê„ÄÇ

2Ô∏è‚É£ ‰º†Êí≠ÁàÜÂèë (Stage 2)
Density ÈôçÂà∞ 0.51Ôºå‰ΩÜÁΩëÁªúËßÑÊ®°Êâ©Â§ßÔºåEdges Â¢ûÂ§ö„ÄÇ

Degree Centralization ÂºÄÂßã‰∏äÂçáÔºåË°®ÊòéÂá∫Áé∞‰∫ÜÂÖ≥ÈîÆ‰º†Êí≠ËÄÖÔºàÊ†∏ÂøÉËäÇÁÇπÈÄêÊ∏êÂΩ¢ÊàêÔºâ„ÄÇ

‰æùÁÑ∂ÊòØÈ´òÈó≠ÂåÖÔºàTransitivity=1ÔºâÔºåËØ¥ÊòéÁ§æÁæ§ÂÜÖÈÉ®ËÅîÁ≥ªÁ¥ßÂØÜÔºå‰ΩÜÂºÄÂßãÊòæÁé∞‰º†Êí≠ÂàÜÂ∑•„ÄÇ

3Ô∏è‚É£ Áü≠ÊöÇÊî∂Áº© (Stage 3)
ËäÇÁÇπÊï∞ÂíåËæπÊï∞Â§ßÂπÖÂáèÂ∞ëÔºåÁΩëÁªúÂÜçÊ¨°ÂèòÊàêÂÆåÂÖ®Âõæ„ÄÇ

ÂèØËÉΩÊòØ‰ø°ÊÅØ‰º†Êí≠ÁöÑ Áü≠ÊöÇÂÅúÊªû Êàñ Â∞èÂúàÂ±ÇÁã¨Á´ã‰º†Êí≠„ÄÇ

4Ô∏è‚É£ Êâ©Â±ïÂ∞ùËØï (Stage 4)
ËäÇÁÇπÊï∞ÂÜçÊ¨°‰∏äÂçáÔºå‰ΩÜ Density Âæà‰ΩéÔºà0.24ÔºâÔºåÁΩëÁªúÊùæÊï£„ÄÇ

ËØ¥Êòé‰ø°ÊÅØÊâ©Êï£Âà∞‰∫ÜÊõ¥ÂπøÊ≥õÁöÑÂèó‰ºóÔºå‰ΩÜÂΩºÊ≠§‰πãÈó¥ËÅîÁ≥ª‰∏çÂº∫„ÄÇ

‰∏≠ÂøÉÊÄß‰ªç‰ΩéÔºåÊú™ÂΩ¢ÊàêÁ®≥ÂÆöÁöÑ‰ø°ÊÅØ‰º†Êí≠‰∏ªÂØºËÄÖ„ÄÇ

5Ô∏è‚É£ Ê†∏ÂøÉÊâ©Êï£ (Stage 5)
ËôΩÁÑ∂ËäÇÁÇπÊï∞‰∏çÂ§öÔºå‰ΩÜÂá∫Áé∞‰∫ÜÊòæËëóÁöÑ‰∏≠ÂøÉÊÄßÁâπÂæÅÔºö

Degree Centralization È´òËææ 0.36

Closeness Centralization ËææÂà∞ 0.47

Betweenness Centralization ‰πüÊúâ 0.16

Ëøô‰∏ÄÈò∂ÊÆµÂèØËÉΩÂá∫Áé∞‰∫ÜÂÖ≥ÈîÆÊÑèËßÅÈ¢ÜË¢ñÊàñË∂ÖÁ∫ß‰º†Êí≠ËÄÖÔºåÂØπ‰ø°ÊÅØÊâ©Êï£Ëµ∑Âà∞ÊòæËëó‰ΩúÁî®„ÄÇ

Transitivity Èôç‰ΩéÂà∞ 0.85 ‚Üí ÁΩëÁªúÂÜÖÈó≠ÁéØÂáèÂ∞ëÔºåÊõ¥Â§ö Ê°•Êé•ÂûãËäÇÁÇπ Âá∫Áé∞„ÄÇ

6Ô∏è‚É£ ÊúÄÊú´Èò∂ÊÆµ (Stage 6)
ÁΩëÁªúÂÜçÊ¨°Êî∂Áº©ÊàêÂÆåÂÖ®ÂõæÔºåÁæ§‰ΩìÈùûÂ∏∏Â∞èÔºå‰ΩÜËÅîÁ≥ªÈùûÂ∏∏Á¥ßÂØÜ„ÄÇ

ÂèØËÉΩÊòØÊ†∏ÂøÉÁæ§‰ΩìÁöÑ‰ΩôÊ≥¢‰∫§ÊµÅÔºå‰ΩÜÊú™ÂÜçÁªßÁª≠ÂêëÂ§ñ‰º†Êí≠„ÄÇ

## tERGM sample

```{r}

# # Step 1: ÂáÜÂ§áÁΩëÁªúÂàóË°®ÔºàÊØè‰∏™Êó∂Èó¥ÁÇπ‰∏Ä‰∏™ networkÔºâ
# network_list <- list()
# for (g in group_stages) {
#   sub_nodes <- which(get.vertex.attribute(net_co_retweet, "group") <= g)
#   sub_g <- get.inducedSubgraph(net_co_retweet, v = sub_nodes)
#   network_list[[as.character(g)]] <- sub_g
# }
# 
# # Step 2: ÊûÑÂª∫Ê®°Âûã
# # ‰ΩøÁî®ÁÆÄÂçïÁªìÊûÑÊÄßÁâπÂæÅ‰Ωú‰∏∫‰æãÂ≠ê
# model <- tergm(
#   network_list ~ Form(~edges + gwesp(0.5, fixed = TRUE)) + 
#     Dissolution(~edges), 
#   estimate = "CMLE"
# )
# 
# summary(model)

```


# Reference


# Appendix

Raw dataset download link: <https://data.bristol.ac.uk/data/en_GB/dataset/23yv276we2mll25fjakkfim2ml/resource/e63a98c4-b4d6-4a89-9be9-06875b83ce33?inner_span=True>


After downloading all files, create a `data` folder in your working directory and place the files inside it.

Follow the setup instructions provided [here](https://colab.research.google.com/drive/1JCjgg3moGBOuZk4iVjBpQNqgsAYFyNoS#scrollTo=YS1uxj-59UmA). Use the shell to install required packages via `pip` as directed.

Next, open `VS Code`, and run the following Python script to convert `.pkl` files to `.csv`:

```{python}
#| eval: false
#| include: true

import pandas as pd
import os

input_dir = "data/mumin"
output_dir = "data/mumin_csv"
os.makedirs(output_dir, exist_ok=True)

file_names = [
    "claim",
    "user",
    "tweet",
    "reply",
    "article",
    "tweet_discusses_claim",
    "article_discusses_claim",
    "user_follows_user",
    "user_retweeted_tweet",
    "reply_quote_of_tweet",
    "reply_reply_to_tweet"
]

for name in file_names:
    input_path = os.path.join(input_dir, name)
    output_path = os.path.join(output_dir, f"{name}.csv")
    try:
        df = pd.read_pickle(input_path, compression="xz")
        df.to_csv(output_path, index=False)
        print(f"Saved: {output_path}")
    except Exception as e:
        print(f"Failed to convert {name}: {e}")

```

This script will generate the corresponding CSV files for further analysis.

Then, preview the Data in R:

```{r}
#| eval: false
#| include: true
# Set the data path 
data_path <- "data/mumin_csv/"

# Define the list of files to read
files <- c(
  "claim.csv", "user.csv", "tweet.csv", "reply.csv", "article.csv",
  "tweet_discusses_claim.csv", "article_discusses_claim.csv",
  "user_follows_user.csv", "user_retweeted_tweet.csv",
  "reply_quote_of_tweet.csv", "reply_reply_to_tweet.csv"
)

# Preview the first few rows of each file 
previews <- lapply(files, function(fname) {
  fpath <- file.path(data_path, fname)
  tryCatch(
    read_csv(fpath, n_max = 5),
    error = function(e) tibble::tibble(error = paste("Error:", e$message))
  )
})

names(previews) <- files

```

```{=html}
<script>
document.addEventListener("DOMContentLoaded", function() {
    const toc = document.getElementById("TOC");
    if (toc) {
        const sourceLink = document.createElement("div");
        sourceLink.innerHTML = `
            <div class="toc-source">
                <a href="https://github.com/troy-yu-cheng/sna-final-paper" 
                   target="_blank" 
                   class="github-button">
                   <svg xmlns="http://www.w3.org/2000/svg" 
                        viewBox="0 0 24 24" 
                        width="16" 
                        height="16" 
                        fill="currentColor"
                        style="vertical-align: middle; margin-right: 5px;">
                     <path d="M12 0C5.373 0 0 5.373 0 12c0 5.303 3.438 9.8 8.207 11.387.6.113.82-.26.82-.577v-2.157c-3.338.726-4.033-1.416-4.033-1.416-.546-1.386-1.332-1.756-1.332-1.756-1.09-.745.083-.73.083-.73 1.205.084 1.84 1.237 1.84 1.237 1.07 1.832 2.807 1.303 3.492.996.108-.774.418-1.303.76-1.602-2.665-.3-5.466-1.332-5.466-5.93 0-1.311.468-2.382 1.237-3.222-.124-.302-.536-1.52.118-3.163 0 0 1.008-.322 3.3 1.23a11.516 11.516 0 0 1 3.002-.403 11.486 11.486 0 0 1 3.002.403c2.292-1.552 3.3-1.23 3.3-1.23.654 1.644.242 2.861.118 3.163.77.84 1.236 1.911 1.236 3.222 0 4.61-2.807 5.627-5.48 5.922.43.372.812 1.103.812 2.222v3.293c0 .321.218.694.825.576C20.565 21.796 24 17.3 24 12 24 5.373 18.627 0 12 0z"/>
                   </svg>
                   View source
                </a>
            </div>
        `;
        toc.appendChild(sourceLink);
    }
});
</script>
```

