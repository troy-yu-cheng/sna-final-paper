---
title: "Social Network Analysis"
subtitle: "Temporal Patterns of Misinformation Diffusion: A Multi-Stage Network Analysis of COVID-19 Origin Narratives on Twitter"
author: 
  - name: "Troy (Yu) Cheng"
    email: yc1317@georgetown.edu
    affiliation: Georgetown University
    corresponding: true
df-print: kable
title-block-banner: "#0a0e1a"
title-block-banner-color: "#4DB8FF"
execute:
  warning: false
date: 2025-04-28
date-modified: last-modified
format:
  html:
    embed-resources: true
    toc: true                 
    toc-title: "Contents"     
    toc-location: right       
    number-sections: true
    number-depth: 3       
    smooth-scroll: true       
    css: trycstyle.css 
    code-overflow: wrap
include-in-header:
  text: |
    <link rel="shortcut icon" href="assets/gu.ico" type="image/x-icon">           
highlight-style: nord       
engine: knitr
---
# Abstract

This study examines the temporal diffusion patterns of the misinformation narrative claiming that [COVID-19 was deliberately created/manufactured by China or the Wuhan laboratory](https://en.wikipedia.org/wiki/COVID-19_lab_leak_theory). The central research question asks: How did this narrative propagate across Twitter retweeter networks over time, and did early spreaders maintain structural advantages? Drawing on the Diffusion of Innovations Theory and Echo Chamber Theory, the study explores whether ideological homophily emerged as the narrative spread.

Using data from the [MuMiN](https://mumin-dataset.github.io/) project, six prominent misinformation claims between March 2020 and August 2021 were analyzed. Retweeters are treated as nodes, with ties defined by co-retweeting, co-replying, co-quoting, and following behaviors. The hypothesis posits that retweeters involved in earlier misinformation narratives occupy more central positions and retain higher connectivity over time.

Social Network Analysis (SNA) is employed to construct adjacency matrices, visualize evolving network structures, and compute centrality and modularity metrics. While temporal network growth is discontinuous across misinformation events, this study explores whether Temporal Exponential Random Graph Models (tERGM) can model these episodic formations by treating thematic similarity as a historical tie.

This research advances understanding of how misinformation narratives persist in online environments and how early participants shape long-term information diffusion.

# Literature Review


# Data Collection & Graph

## Dataset

This study uses secondary data from the **MuMiN Project** (Multi-platform Misinformation Influence Network), publicly available at: <https://data.bristol.ac.uk/data/en_GB/dataset/23yv276we2mll25fjakkfim2ml/resource/e63a98c4-b4d6-4a89-9be9-06875b83ce33?inner_span=True>

The dataset includes information about social media users, tweets, misinformation claims, and their relational behaviors across various platforms.

## Data Preparation

### Loading Required Packages

```{r}
#| label: set up packages
library(tidyverse)
library(readr)
library(statnet)
library(intergraph)
library(reshape2)
```

### Loading and Merging Data

```{r}
# Load data
tweets <- read_csv("data/mumin_csv/tweet.csv")
claims <- read_csv("data/mumin_csv/claim.csv")
tweet_claim <- read_csv("data/mumin_csv/tweet_discusses_claim.csv")
user_retweet <- read_csv("data/mumin_csv/user_retweeted_tweet.csv")

# Join tweet & claim via tweet_claim
tweet_claim_joined <- tweet_claim |> 
  rename(tweet_id = src, claim_id = tgt) |> 
  inner_join(claims, by = c("claim_id" = "id"))

# Join retweeters within users & claim via retweeted tweet
user_claim <- user_retweet |> 
  rename(retweeter_id = src, tweet_id = tgt) |> 
  inner_join(tweet_claim_joined, by = "tweet_id")

# Create a mapping of retweeters and tweets
retweet_map <- user_claim |> 
  select(retweeter_id, tweet_id) |> 
  distinct() 

# Basic data overview
table(user_claim$label)
head(table(user_claim$cluster_keywords))
```

### Filtering for Target Misinformation Narratives

This study focuses specifically on misinformation narratives claiming that **COVID-19 was deliberately created or spread by China or the Wuhan laboratory**. The following filtering steps were applied:

1. Filter keywords containing "china" or "wuhan".

2. Manually select misinformation topics directly related to the COVID-19 origin narrative.

3. Restrict the analysis to English-language posts labeled as "misinformation".

```{r}
user_claim_filtered <- user_claim |> 
  filter(str_detect(keywords, "china|wuhan")) 

head(unique(user_claim_filtered$keywords))

# Final filtered dataset
covid_wuhan_misinfo <- user_claim_filtered |>
  filter(keywords %in% c(
    "coronavirus comes biological laboratory wuhan",
    "including corona virus manufactured wuhan",
    "china created spread coronavirus",
    "announced coronavirus artificially created china",
    "china created coronavirus",
    "coronavirus created laboratory china",
    "honjo said china manufactured coronavirus",
    "said new coronavirus manufactured wuhan",
    "coronavirus tested biological weapon china",
    "china testing coronavirus biological weapon",
    "covid 19 lab china",
    "coronavirus natural worked wuhan laboratory",
    "coronavirus manufactured laboratory wuhan specifically",
    "doctor claimed coronavirus china create",
    "corona virus manufactured china",
    "says current coronavirus manufactured wuhan",
    "wuhan coronavirus created patented",
    "covid 19 disease manufactured china",
    "pandemic caused artificial virus china",
    "collaborator assures coronavirus manufactured wuhan",
    "concluded covid leaked wuhan lab",
    "coronavirus created united states china",
    "air comes china import coronavirus",
    "coronavirus released china"
  )) |>
  filter(language == "en") |>
  filter(label == "misinformation")

# Distribution of final misinformation topics
table(covid_wuhan_misinfo$keywords)
table(covid_wuhan_misinfo$cluster_keywords)
```

## Social Network Construction

This network models the co-dissemination behavior of misinformation retweeters. While the exact paths of information transmission are unknown, this co-spreader network captures the structural relationships that may facilitate misinformation diffusion.

### Co-Retweet Network

The `co-retweet` network captures the relationship between users who have both retweeted the same misinformation tweet. In this network, a tie is created between two users if they co-retweeted the same piece of misinformation tweet. The edge weight indicates how many misinformation tweets the two users co-retweeted together. This structure reflects patterns of coordinated or shared interest in misinformation content, and is often used to analyze the spread dynamics and clustering behavior of misinformation propagation.

A tie is created between two users only if they both retweeted the same specific misinformation tweet (i.e., identical tweet_id).

The co-retweet network constructed in this study represents precise co-dissemination behavior. A tie is established between two users only if they both retweeted the exact same misinformation tweet, identified by a shared `tweet_id`. Each edge is weighted by the number of such co-retweeting events, reflecting how often the same pair of users jointly retweeted the same pieces of misinformation. 

This formulation does not infer shared opinion or indirect coordination, but rather captures direct and synchronous amplification of specific misinformation artifacts. As such, this network is especially useful for identifying tightly connected retweeter clusters that may act as echo chambers or exhibit signs of coordinated behavior.



The co-retweet network captures the relational structure among users who have collectively engaged in disseminating the same pieces of misinformation. In this network, a tie is established between two users if they both retweeted the same misinformation tweet. The weight of the edge represents the frequency of such co-retweet behavior, indicating how many distinct misinformation tweets the two users jointly amplified. This network structure is particularly relevant for identifying patterns of coordinated information spread and examining the formation of tightly connected user clusters that facilitate the persistence and reinforcement of misinformation narratives.

In the context of this study, the co-retweet network offers critical insights into the underlying social mechanisms that support the diffusion of the COVID-19 origin conspiracy narrative. By analyzing the weighted connections, this network reveals which users are central to the dissemination process and whether specific communities emerge around the repeated propagation of misinformation. Such patterns are indicative of potential echo chambers and coordinated amplification efforts, both of which are crucial for understanding how misinformation sustains its visibility and influence over time.

```{r}
# Extract misinformation-related tweets id
misinfo_tweet_id <- unique(covid_wuhan_misinfo$tweet_id)

# Identify pairs of users who co-retweeted the same misinformation tweet
co_retweet_edges <- user_retweet |> 
  filter(tgt %in% misinfo_tweet_id) |> 
  rename(tweet_id = tgt, retweeter_id = src) |> 
  group_by(tweet_id) |> 
  summarise(
    pairs = list(as.data.frame(t(combn(retweeter_id, 2)))), 
    .groups = "drop"
  ) |> 
  unnest(pairs) |> 
  mutate(
    user_1 = pmin(V1, V2), # Ensure lower ID comes first
    user_2 = pmax(V1, V2) # Ensure higher ID comes second
  ) |> 
  select(user_1, user_2) |> 
  group_by(user_1, user_2) |> 
  summarise(weight = n(), .groups = "drop") |> 
  mutate(type = "co-retweet") |>
  filter(user_1 != user_2) |>
  mutate(
    user_1 = as.character(user_1),
    user_2 = as.character(user_2)
  )

# Obtain the full list of unique users involved
all_users <- unique(c(
  covid_wuhan_misinfo$retweeter_id,  
  co_quote_edges$user_1, 
  co_quote_edges$user_2
)) %>% 
  as.character() %>% 
  sort()

# Create initial matrix
adj_matrix_co_retweet <- acast(
  co_retweet_edges, 
  user_1 ~ user_2, 
  value.var = "weight", 
  fill = 0
)

# Ensure matrix completeness by adding missing rows and columns
missing_rows <- setdiff(all_users, rownames(adj_matrix_co_retweet))
missing_cols <- setdiff(all_users, colnames(adj_matrix_co_retweet))

if (length(missing_rows) > 0) {
  adj_matrix_co_retweet <- rbind(
    adj_matrix_co_retweet, 
    matrix(0, nrow = length(missing_rows), ncol = ncol(adj_matrix_co_retweet), 
           dimnames = list(missing_rows, colnames(adj_matrix_co_retweet)))
  )
}

if (length(missing_cols) > 0) {
  adj_matrix_co_retweet <- cbind(
    adj_matrix_co_retweet, 
    matrix(0, nrow = nrow(adj_matrix_co_retweet), ncol = length(missing_cols), 
           dimnames = list(rownames(adj_matrix_co_retweet), missing_cols))
  )
}

# Reorder the matrix to align rows and columns
adj_matrix_co_retweet <- adj_matrix_co_retweet[all_users, all_users]

# Export the adjacency matrix for further analysis
write.csv(adj_matrix_co_retweet, "data/adj_matrix_co_retweet.csv", row.names = TRUE)

# Check dimensions of the final matrix
ncol(adj_matrix_co_retweet)
nrow(adj_matrix_co_retweet)
```
### Co-quote

The `Co-quote` adjacency matrix captures the relationship between users who co-engaged with misinformation through the quoting function on Twitter. Specifically, two users are connected if one quoted a misinformation-related tweet and the other either quoted the same tweet or was the author of that quoted tweet. This interaction reflects a more deliberate and explicit form of engagement with misinformation content, often involving commentary or amplification.

The matrix is weighted based on the number of times each user pair engaged in co-quoting behavior. Diagonal elements (self-loops) are removed, and the matrix is fully completed to ensure that all users appear in both rows and columns, enabling comprehensive analysis of the co-quote network structure.


Êàë‰ª¨ËÉΩÁ°ÆÂÆöÂÖ≥Á≥ªÁöÑÊòØretweeter of quoting tweetÂíåretweeter of quoted tweet‰πãÈó¥ÁöÑÂÖ≥Á≥ª

Co-QuoteÔºö
A retweeted ‰∫ÜÊüê‰∏™ quoting tweetÔºàÂºïÁî®‰∫Ü‰∏ÄÊù° misinformation tweet ÁöÑ tweetÔºâ„ÄÇ

B retweeted ‰∫ÜË¢´ÂºïÁî®ÁöÑÈÇ£Êù° misinformation tweet„ÄÇ

‚Üí Ëøû A Âíå B„ÄÇ

Áé∞ÂÆûÊÑè‰πâÔºö

A ÈÄöËøá retweet ‰∫Ü‰∏Ä‰∏™ÂºïÁî®Ë∞£Ë®ÄÁöÑÂÜÖÂÆπÔºåÂèÇ‰∏é‰∫ÜÂõ¥ÁªïË∞£Ë®ÄÁöÑ‰º†Êí≠ÂíåËÆ®ËÆ∫„ÄÇ

B Áõ¥Êé• retweet ‰∫ÜËøô‰∏™Ë∞£Ë®Ä„ÄÇ

‰ªñ‰ª¨ÈÉΩÂõ¥ÁªïÁùÄÂêå‰∏Ä misinformation ÂÜÖÂÆπÂèÇ‰∏é‰∫Ü‰º†Êí≠Ôºå‰ΩÜË∑ØÂæÑ‰∏çÂêå„ÄÇ


```{r}
# Co-Quote Edges
co_quote_edges <- read_csv("data/mumin_csv/reply_quote_of_tweet.csv") |>
  filter(tgt %in% misinfo_tweet_id | src %in% misinfo_tweet_id) |> 
  rename(
    quoted_tweet_id = tgt,    # Ë¢´ÂºïÁî®ÁöÑ tweet
    quoting_tweet_id = src    # ÂèëËµ∑ÂºïÁî®ÁöÑ tweet
  ) |> 
  # Êâæ quoting tweet ÊòØË∞Å retweeted ÁöÑÔºàÂç≥ quoting userÔºâ
  left_join(retweet_map, by = c("quoting_tweet_id" = "tweet_id")) |> 
  rename(quoting_user = retweeter_id) |> 
  # Êâæ quoted tweet ÊòØË∞Å retweeted ÁöÑÔºàÂç≥ quoted userÔºâ
  left_join(retweet_map, by = c("quoted_tweet_id" = "tweet_id")) |> 
  rename(quoted_user = retweeter_id) |> 
  filter(!is.na(quoting_user) & !is.na(quoted_user)) |> 
  mutate(
    user_1 = pmin(quoting_user, quoted_user),
    user_2 = pmax(quoting_user, quoted_user)
  ) |> 
  select(user_1, user_2) |> 
  group_by(user_1, user_2) |> 
  summarise(weight = n(), .groups = "drop") |> 
  mutate(type = "co-quote") |> 
  mutate(type = "co-quote") |>
  filter(user_1 != user_2) |>
  mutate(
    user_1 = as.character(user_1),
    user_2 = as.character(user_2)
  )

# Step 1: Ëé∑ÂèñÂÆåÊï¥ retweeter ÂàóË°®ÔºàÂåÖÂê´ÊúâÊó† co-quote Ë°å‰∏∫ÁöÑÔºâ
all_retweeters <- unique(c(
  covid_wuhan_misinfo$retweeter_id,  # Ê†∏ÂøÉ‰º†Êí≠ËÄÖ
  co_quote_edges$user_1, 
  co_quote_edges$user_2
)) %>% 
  as.character() %>% 
  sort()

# Step 2: ÂàõÂª∫ÂÆåÊï¥Áü©Èòµ
adj_matrix_co_quote <- acast(
  co_quote_edges, 
  user_1 ~ user_2, 
  value.var = "weight", 
  fill = 0
)

# Step 3: Ê∑ªÂä†Áº∫Â§±Ë°åÂíåÂàó
missing_rows <- setdiff(all_retweeters, rownames(adj_matrix_co_quote))
missing_cols <- setdiff(all_retweeters, colnames(adj_matrix_co_quote))

if (length(missing_rows) > 0) {
  adj_matrix_co_quote <- rbind(
    adj_matrix_co_quote, 
    matrix(0, nrow = length(missing_rows), ncol = ncol(adj_matrix_co_quote), 
           dimnames = list(missing_rows, colnames(adj_matrix_co_quote)))
  )
}

if (length(missing_cols) > 0) {
  adj_matrix_co_quote <- cbind(
    adj_matrix_co_quote, 
    matrix(0, nrow = nrow(adj_matrix_co_quote), ncol = length(missing_cols), 
           dimnames = list(rownames(adj_matrix_co_quote), missing_cols))
  )
}

# Step 4: Á°Æ‰øùÁü©ÈòµÂØπÈΩê
adj_matrix_co_quote <- adj_matrix_co_quote[all_retweeters, all_retweeters]

# ‰øùÂ≠ò‰∏∫ CSV
write.csv(adj_matrix_co_quote, "data/adj_matrix_co_quote.csv", row.names = TRUE)


nrow(adj_matrix_co_quote)
ncol(adj_matrix_co_quote)


```

### Co-reply

Êàë‰ª¨ËÉΩÁ°ÆÂÆöÂÖ≥Á≥ªÁöÑÊòØretweeter of replying tweetÂíåretweeter of replyed tweet‰πãÈó¥ÁöÑÂÖ≥Á≥ª

A retweeted ‰∫Ü‰∏Ä‰∏™ replying tweetÔºàÂØπ‰∏ÄÊù° misinformation tweet ËøõË°å‰∫Ü reply ÁöÑ tweetÔºâ„ÄÇ

B retweeted ‰∫ÜË¢´ reply ÁöÑÈÇ£Êù° misinformation tweet„ÄÇ

‚Üí Ëøû A Âíå B„ÄÇ

Áé∞ÂÆûÊÑè‰πâÔºö

A ÈÄöËøá retweet ‰∫Ü‰∏Ä‰∏™ reply Â∏ñÂ≠êÔºåÂèÇ‰∏é‰∫ÜÂõ¥Áªï misinformation ÁöÑËÆ®ËÆ∫Èìæ„ÄÇ

B ÊòØÁõ¥Êé•ÁöÑ‰º†Êí≠ËÄÖ„ÄÇ

‰ªñ‰ª¨ÊòØÂõ¥ÁªïÁõ∏Âêå misinformation ÂÜÖÂÆπÁöÑ Èó¥Êé•‰º†Êí≠ÂèÇ‰∏éËÄÖ„ÄÇ

#### co_reply_edges Explanation (General Co-Reply Network)
This adjacency matrix captures the co-reply relationship between users who have engaged with each other via the reply function on Twitter in the context of misinformation.
In this network, two users are connected if:

One replied to a tweet, and

The other either replied to the same tweet or authored the replied tweet.

However, due to limitations in the dataset (missing tweet author information), this matrix primarily reflects shared engagement with the same tweet rather than direct author-replier relationships.

Note: In this case, no edges were detected, possibly because the retweeters of misinformation tweets did not participate significantly in reply activities.

```{r}
# Co-reply
co_reply_edges <- read_csv("data/mumin_csv/reply_reply_to_tweet.csv") |>
  filter(tgt %in% misinfo_tweet_id | src %in% misinfo_tweet_id) |> 
  rename(
    replied_tweet_id = tgt, 
    replying_tweet_id = src
  ) |> 
  # ÊâæÂá∫‰∏§Êù° tweet ÂêÑËá™ÁöÑ retweeter
  left_join(retweet_map, by = c("replied_tweet_id" = "tweet_id")) |> 
  rename(user_replied = retweeter_id) |> 
  left_join(retweet_map, by = c("replying_tweet_id" = "tweet_id")) |> 
  rename(user_replying = retweeter_id) |> 
  filter(!is.na(user_replied) & !is.na(user_replying)) |> 
  mutate(
    user_1 = pmin(user_replied, user_replying),
    user_2 = pmax(user_replied, user_replying)
  ) |> 
  select(user_1, user_2) |> 
  group_by(user_1, user_2) |> 
  summarise(weight = n(), .groups = "drop") |> 
  mutate(type = "co-reply")

table(co_reply_edges$weight)

reply_data <- read_csv("data/mumin_csv/reply_reply_to_tweet.csv")
sum(reply_data$src %in% retweet_map$tweet_id)  # ÊúâÂ§öÂ∞ë replying tweets Ë¢´ retweetedÔºü
sum(reply_data$tgt %in% retweet_map$tweet_id)  # ÊúâÂ§öÂ∞ë replied tweets Ë¢´ retweetedÔºü


```

#### co_reply_edges_v2 Explanation (Focused Co-Reply on Misinformation Tweets)

This adjacency matrix focuses exclusively on replies to misinformation tweets.
It captures the relationship between users who retweeted the same misinformation tweet and also replied to it.

In this network, two users are connected if they both retweeted a misinformation tweet and subsequently replied to that tweet or engaged in discussions around it.

This captures shared attention and engagement specifically around misinformation content, providing insight into how users might form conversational clusters around these topics.

```{r}
co_reply_edges_v2 <- read_csv("data/mumin_csv/reply_reply_to_tweet.csv") |>
  filter(tgt %in% misinfo_tweet_id) |>  # Ë¢´ reply ÁöÑ tweet ÊòØ misinformation
  rename(replied_tweet_id = tgt) |> 
  # ÊâæÂá∫Ëøô‰∏™ misinformation tweet Ë¢´Ë∞Å retweeted Ëøá
  left_join(retweet_map, by = c("replied_tweet_id" = "tweet_id")) |>
  rename(user_replied = retweeter_id) |> 
  filter(!is.na(user_replied)) |> 
  group_by(replied_tweet_id) |> 
  summarise(
    pairs = list(as.data.frame(t(combn(user_replied, 2)))), 
    .groups = "drop"
  ) |> 
  unnest(pairs) |> 
  mutate(
    user_1 = pmin(V1, V2),
    user_2 = pmax(V1, V2)
  ) |> 
  select(user_1, user_2) |> 
  group_by(user_1, user_2) |> 
  summarise(weight = n(), .groups = "drop") |> 
  mutate(type = "co-reply-v2")  |>
  filter(user_1 != user_2) |>
  mutate(
    user_1 = as.character(user_1),
    user_2 = as.character(user_2)
  )

# Step 1: ÂÆö‰πâÊâÄÊúâ retweetersÔºàÂåÖÊã¨ÂèÇ‰∏éÂíåÊú™ÂèÇ‰∏é reply ÁöÑÔºâ
all_retweeters_reply <- unique(c(
  covid_wuhan_misinfo$retweeter_id,  # Ê†∏ÂøÉ‰º†Êí≠ËÄÖ
  co_reply_edges_v2$user_1, 
  co_reply_edges_v2$user_2
)) %>% 
  as.character() %>% 
  sort()

# Step 2: ÂàõÂª∫ Adjacency Matrix
adj_matrix_co_reply_v2 <- acast(
  co_reply_edges_v2, 
  user_1 ~ user_2, 
  value.var = "weight", 
  fill = 0
)

# Step 3: Á°Æ‰øùÁü©ÈòµÂåÖÂê´ÊâÄÊúâ retweeters
missing_rows <- setdiff(all_retweeters_reply, rownames(adj_matrix_co_reply_v2))
missing_cols <- setdiff(all_retweeters_reply, colnames(adj_matrix_co_reply_v2))

if (length(missing_rows) > 0) {
  adj_matrix_co_reply_v2 <- rbind(
    adj_matrix_co_reply_v2, 
    matrix(0, nrow = length(missing_rows), ncol = ncol(adj_matrix_co_reply_v2), 
           dimnames = list(missing_rows, colnames(adj_matrix_co_reply_v2)))
  )
}

if (length(missing_cols) > 0) {
  adj_matrix_co_reply_v2 <- cbind(
    adj_matrix_co_reply_v2, 
    matrix(0, nrow = nrow(adj_matrix_co_reply_v2), ncol = length(missing_cols), 
           dimnames = list(rownames(adj_matrix_co_reply_v2), missing_cols))
  )
}

# Step 4: Reorder to ensure rows and columns match
adj_matrix_co_reply_v2 <- adj_matrix_co_reply_v2[all_retweeters_reply, all_retweeters_reply]

# Step 5: ‰øùÂ≠ò CSV
write.csv(adj_matrix_co_reply_v2, "data/adj_matrix_co_reply_v2.csv", row.names = TRUE)

nrow(adj_matrix_co_reply_v2)
ncol(adj_matrix_co_reply_v2)


```

This step ensures that the adjacency matrix fully represents the social structure by including all users who participated in the retweet network, regardless of their direct involvement in reply behaviors.

Users who did not engage in replying are represented as isolated nodes (zero rows and columns), preserving the completeness of the network for structural analysis.


### Follow

#### Undirected follow

This edge represents an undirected tie between any two users who are both retweeters of misinformation tweets and have a recorded follower-followee relationship in either direction. However, the relationship is not necessarily mutual. It simply captures the existence of a connection in the follower network among the misinformation retweeters, regardless of direction.

srcÔºàuser_aÔºâÊòØfollowerÔºåtgtÔºàuser_bÔºâÊòØfollowee„ÄÇ

filter(user_a %in% retweeter_id_misinfo & user_b %in% retweeter_id_misinfo)Ôºö
‚Üí Ë°®Á§∫ËøôÊù°Ëæπ‰ªÖË¶ÅÊ±ÇÂèåÊñπÈÉΩÊòØ retweetersÔºå‰∏çË¶ÅÊ±Ç‰ªñ‰ª¨‰∫íÁõ∏ÂÖ≥Ê≥®„ÄÇ

pmin/pmax ÊòØ‰∏∫‰∫ÜÂéªÊéâÊñπÂêëÊÄßÔºåÊääËæπËΩ¨ÊàêÊó†ÂêëÁöÑ„ÄÇ

Ëøô‰∏çÊòØ mutual followÔºà‰∫íÁõ∏ÂÖ≥Ê≥®ÔºâÔºåËÄåÊòØÂè™Ë¶Å follower Âíå followee ÈÉΩÊòØ retweeterÔºåÂ∞±ÂàõÂª∫‰∏ÄÊù°Êó†ÂêëËæπ„ÄÇ

```{r}
# Follow
# Ëé∑Âèñ retweeter ÂàóË°®
retweeter_id_misinfo <- unique(covid_wuhan_misinfo$retweeter_id)

# ÊûÑÈÄ† Follow Ëæπ
retweeter_follow_edges <- read_csv("data/mumin_csv/user_follows_user.csv") |>
  rename(user_a = src, user_b = tgt) |> 
  # ‰øùÁïô‰∏§ËÄÖÈÉΩÂú® retweeter ÂàóË°®‰∏≠ÁöÑËÆ∞ÂΩï
  filter(user_a %in% retweeter_id_misinfo & user_b %in% retweeter_id_misinfo) |> 
  mutate(
    user_1 = pmin(user_a, user_b),  # ‰øùÊåÅÂ∞èÁöÑ ID Âú®ÂâçÔºåÂéªÊéâÊñπÂêëÊÄß
    user_2 = pmax(user_a, user_b)
  ) |> 
  select(user_1, user_2) |> 
  distinct() |>  # ÂéªÈáçÔºåÈò≤Ê≠¢ÈáçÂ§çËÆ∞ÂΩï A -> B Âíå B -> A
  mutate(weight = 1, type = "follow")

retweeter_follow_edges

```

all 0 matrix:

```{r}
# Ëé∑ÂèñÊâÄÊúâ retweeters
all_retweeters <- sort(unique(c(
  covid_wuhan_misinfo$retweeter_id, 
  retweeter_follow_edges$user_1, 
  retweeter_follow_edges$user_2
))) %>% as.character()

# ÂàõÂª∫ÂÖ® 0 Áü©Èòµ
adj_matrix_follow <- matrix(
  0, 
  nrow = length(all_retweeters), 
  ncol = length(all_retweeters),
  dimnames = list(all_retweeters, all_retweeters)
)

# ËΩ¨ÊàêÊï∞ÊçÆÊ°ÜÂØºÂá∫
write.csv(adj_matrix_follow, "data/adj_matrix_follow.csv", row.names = TRUE)

```

#### Directed follow

This edge preserves the directionality of follower relationships between misinformation retweeters (e.g., User A follows User B). It allows for modeling influence flow and assessing asymmetric structures (e.g., hubs or hierarchies) in the spread of misinformation.

follower ‚Üí followee Ë°®Á§∫ÂçïÂêëÁöÑÂÖ≥Ê≥®„ÄÇ

ÂêåÊ†∑Âú∞ÔºåÂè™Ë¶Å‰∏§ËÄÖÈÉΩÂú® retweeter ÂàóË°®‰∏≠ÔºåÂ∞±‰øùÁïôËøô‰∏™ÊñπÂêëÊÄßÂÖ≥Á≥ª„ÄÇ

ËøôÊòØÁúüÊ≠£ÁöÑ directed edgeÔºåË°®Á§∫‚ÄúË∞ÅÂÖ≥Ê≥®‰∫ÜË∞Å‚ÄùÔºåÊñπÂêëÊÄß‰øùÁïô„ÄÇ

```{r}
retweeter_follow_edges_directed <- read_csv("data/mumin_csv/user_follows_user.csv") |> 
  rename(follower = src, followee = tgt) |> 
  # Âè™‰øùÁïô retweeter ‰πãÈó¥ÁöÑÂÖ≥Ê≥®ÂÖ≥Á≥ªÔºàÊúâÊñπÂêëÔºâ
  filter(follower %in% retweeter_id_misinfo & followee %in% retweeter_id_misinfo) |> 
  mutate(
    weight = 1,          # ÈªòËÆ§ÊùÉÈáç‰∏∫ 1
    type = "follow_directed"      # ÊòéÁ°ÆËØ¥ÊòéÊòØÂÖ≥Ê≥®ÂÖ≥Á≥ª
  ) |> 
  select(follower, followee, weight, type)

```


```{r}
follow_data<-read_csv("data/mumin_csv/user_follows_user.csv") 
sum(follow_data$src %in% covid_wuhan_misinfo$retweeter_id)
sum(follow_data$tgt %in% covid_wuhan_misinfo$retweeter_id)

sum(covid_wuhan_misinfo$retweeter_id%in% follow_data$src)
sum(covid_wuhan_misinfo$retweeter_id%in% follow_data$tgt)

covid_wuhan_misinfo |>
  group_by(date, keywords) |>
  select(date, keywords) |>
  arrange(date)|>
  unique()

```



# Analysis

## Co-retweet Net

```{r}
# ËØªÂèñ co-retweet adjacency matrix
adj_matrix_co_retweet <- read.csv(
  "data/adj_matrix_co_retweet.csv", 
  row.names = 1, 
  check.names = FALSE  # ÂÖ≥ÈîÆÂèÇÊï∞ÔºåÁ¶ÅÊ≠¢Ëá™Âä®Âä† x ÂâçÁºÄ
)

# ÊûÑÂª∫ network ÂØπË±°ÔºàÊó†ÂêëÂõæÔºâ
net_co_retweet <- network(as.matrix(adj_matrix_co_retweet), directed = FALSE, matrix.type = "adjacency")

get.vertex.attribute(net_co_retweet, "vertex.names")

# Ëé∑ÂèñÂàÜÁªÑ‰ø°ÊÅØ
retweeter_group <- covid_wuhan_misinfo %>%
  mutate(retweeter_id = as.character(retweeter_id)) %>%
  select(retweeter_id, date, keywords) %>%
  distinct() %>%
  arrange(date) %>%
  mutate(group = as.numeric(factor(paste(date, keywords), levels = unique(paste(date, keywords)))))

# Â∞Ü Group ‰ø°ÊÅØÊ∑ªÂä†Âà∞ËäÇÁÇπÂ±ûÊÄß‰∏≠
set.vertex.attribute(
  net_co_retweet, 
  "group", 
  retweeter_group$group[match(get.vertex.attribute(net_co_retweet, "vertex.names"), retweeter_group$retweeter_id)]
)

get.vertex.attribute(net_co_retweet, "group")

for (g in 1:6) {
  sub_g <- get.inducedSubgraph(net_co_retweet, 
                               which(get.vertex.attribute(net_co_retweet, "group") == g))
  plot.network(sub_g, 
                displaylabels = FALSE, 
                vertex.cex = 1, 
                vertex.col = "skyblue", 
                main = paste("Subgraph for Group", g))
}


```

```{r}
# 1. Ëé∑ÂèñÈò∂ÊÆµ‰ø°ÊÅØ
group_stages <- sort(unique(get.vertex.attribute(net_co_retweet, "group")))

results <- data.frame()  # Ê∏ÖÁ©∫ÊàñÂàùÂßãÂåñ

for (g in group_stages) {
  sub_nodes <- which(get.vertex.attribute(net_co_retweet, "group") <= g)
  sub_g <- get.inducedSubgraph(net_co_retweet, v = sub_nodes)
  
  adj_mat <- as.matrix.network(sub_g, matrix.type = "adjacency")
  
  results <- rbind(results, data.frame(
    Stage = g,
    Nodes = network.size(sub_g),
    Edges = network.edgecount(sub_g),
    Density = gden(sub_g),
    Degree_Centralization = centralization(adj_mat, FUN = degree, mode = "graph"),
    Closeness_Centralization = centralization(adj_mat, FUN = closeness, mode = "graph"),
    Betweenness_Centralization = centralization(adj_mat, FUN = betweenness, mode = "graph"),
    Transitivity = gtrans(sub_g, mode = "graph")
  ))
}
# 4. Êü•ÁúãÁªìÊûú
print(results)
```


1Ô∏è‚É£ ÂØÜÂ∫¶ (Density) ‰∏ãÈôçÊ∏ÖÊô∞ÂèØËßÅ
Á¨¨‰∏ÄÈò∂ÊÆµÂØÜÂ∫¶ = 1.0ÔºåÂÆåÂÖ®ÂõæÔºàÊØè‰∏™ËäÇÁÇπÈÉΩ‰∫íÁõ∏ÂÖ≥ËÅîÔºâ„ÄÇ

ÈöèÁùÄËäÇÁÇπÂ¢ûÂä†ÔºåÂØÜÂ∫¶ËøÖÈÄü‰∏ãÈôçÂà∞ 0.13 Â∑¶Âè≥„ÄÇ

üìå Ëß£ÈáäÔºö

ÊúÄÂàùÁöÑÊ†∏ÂøÉ‰º†Êí≠ËÄÖÈ´òÂ∫¶‰∫íÂä®ÔºåÂΩ¢Êàê‰∫ÜÂ∞èËßÑÊ®°ÁöÑ‚ÄúÁ≤æËã±‰º†Êí≠Âúà‚ÄùÔºàÂ¶ÇÂØÜÈó≠Â∞èÂõ¢‰ΩìÔºâ„ÄÇ

ÈöèÁùÄ‰º†Êí≠Êâ©Êï£ÔºåËæπÁºòÁî®Êà∑ÔºàÂ§ñÂõ¥ retweetersÔºâË¢´ÈÄêÊ∏êÂê∏ÂºïËøõÊù•Ôºå‰ΩÜ‰ªñ‰ª¨‰πãÈó¥Âπ∂Ê≤°ÊúâÂ§ßÈáèÁöÑÁõ∏‰∫íËÅîÁ≥ªÔºå‰ªÖ‰∏éÊ†∏ÂøÉ‰º†Êí≠ËÄÖÊàñÂ∞ëÊï∞Áî®Êà∑ËøûÊé•ÔºåÂØºËá¥ÁΩëÁªúË∂äÊù•Ë∂äÁ®ÄÁñè„ÄÇ

2Ô∏è‚É£ Degree Centralization Á®çÂæÆ‰∏äÂçáÔºå‰ΩÜÂßãÁªàÂÅè‰Ωé
‰ªé 0.048 Á®≥ÂÆö‰∏äÂçáÂà∞ 0.086„ÄÇ

Ë°®ÊòéÔºö

ËôΩÁÑ∂ÊúâÈÉ®ÂàÜ‚ÄúË∂ÖÁ∫ß‰º†Êí≠ËÄÖ‚ÄùËäÇÁÇπÂá∫Áé∞ÔºàÊã•ÊúâÊõ¥Â§öËøûÊé•ÔºâÔºå

‰ΩÜÊï¥‰∏™ÁΩëÁªúÂπ∂Ê≤°ÊúâÂΩ¢ÊàêÂº∫ÁÉàÁöÑ‚ÄúÂçï‰∏ÄÊ†∏ÂøÉÊéßÂà∂‚ÄùÁé∞Ë±°ÔºåËøòÊòØËæÉ‰∏∫ÂàÜÊï£ÁöÑ„ÄÇ

üìå ÂØπÊØîÂàÜÊûêÔºö

ËøôÁ¨¶ÂêàË∞£Ë®Ä‰º†Êí≠‰∏≠ÁöÑ‚ÄúÂéª‰∏≠ÂøÉÂåñÁâπÂæÅ‚ÄùÔºö

ËôΩÁÑ∂ÊúâÂΩ±ÂìçÂäõÂ§ßÁöÑÁî®Êà∑Ôºå‰ΩÜ‰πüÊúâÂ§ßÈáè‰∏≠Â∞èËäÇÁÇπÂèÇ‰∏é‰º†Êí≠ÔºåÂΩ¢Êàê‰∫Ü‚ÄúÂàÜÂ∏ÉÂºèÊâ©Êï£‚Äù„ÄÇ

3Ô∏è‚É£ Closeness Âíå Betweenness Centralization ‰∏ÄÁõ¥‰∏∫ 0
üìå Ëß£ÈáäÔºö

ËøôÊÑèÂë≥ÁùÄÔºö

Ê≤°ÊúâËäÇÁÇπÁúüÊ≠£ÊâøÊãÖ‚Äú‰∏≠‰ªãÊ°•Ê¢Å‚ÄùÁöÑËßíËâ≤Ôºàbetweenness = 0Ôºâ„ÄÇ

Ê≤°ÊúâËäÇÁÇπÂú®‰ø°ÊÅØ‰º†ÈÄíË∑ØÂæÑ‰∏≠Âç†ÊçÆÊòæËëó‰ΩçÁΩÆÔºàcloseness = 0Ôºâ„ÄÇ

ÂæàÂèØËÉΩÊòØÂõ†‰∏∫Ëøô‰∏™ÁΩëÁªúÊòØ Êó†ÂêëÂõæ‰∏îÂ∞èÂõ¢‰ΩìÂÜÖÈÉ®Âº∫ËøûÊé•ÔºåÂØºËá¥Â§ßÈÉ®ÂàÜËäÇÁÇπË∑ØÂæÑÈïøÂ∫¶Áõ∏‰ººÔºåÊàñÊ†πÊú¨‰∏çÈúÄË¶ÅÈÄöËøá‰∏≠‰ªãËäÇÁÇπÂ∞±ËÉΩÁõ¥Êé•ËøûÊé•„ÄÇ

üìå Ê¥ûÂØüÔºö

ËøôÊòØÂÖ∏ÂûãÁöÑ‚ÄúÁæ§Âõ¢Âºè‰º†Êí≠‚ÄùÔºå‰∏çÂêåÁæ§‰ΩìÂÜÖÈÉ®ËøûÈÄöÁ¥ßÂØÜÔºå‰ΩÜÁæ§‰Ωì‰πãÈó¥ÁöÑÊ°•Ê¢ÅËäÇÁÇπÁ®ÄÁº∫„ÄÇ

Á¨¶Âêà Echo Chamber Theory ÁöÑÊèèËø∞ ‚Äî‚Äî ‰ø°ÊÅØÂú®Áæ§‰ΩìÂÜÖÈÉ®ÂèçÂ§ç‰º†Êí≠ÔºåÂæàÈöæË∑®Áæ§‰Ωì‰º†ÈÄí„ÄÇ

4Ô∏è‚É£ Transitivity (ÂÖ®Â±ÄËÅöÁ±ªÁ≥ªÊï∞) ÊûÅÈ´ò
‰∏ÄÁõ¥Áª¥ÊåÅÂú® Êé•Ëøë 1.0ÔºåÂì™ÊÄïËäÇÁÇπÊï∞ÈáèÂ¢ûÂä†‰πüÂè™ÊúâÊûÅÂæÆÂº±‰∏ãÈôç„ÄÇ

üìå Ëß£ÈáäÔºö

ÁΩëÁªú‰∏≠ÁªùÂ§ßÈÉ®ÂàÜ‰∏âÂÖÉÈó≠ÁéØÈÉΩÂ≠òÂú® ‚Äî‚Äî Êç¢Âè•ËØùËØ¥Ôºå‚ÄúÊúãÂèãÁöÑÊúãÂèã‰πüÊòØÊúãÂèã‚Äù„ÄÇ

ÂÜçÊ¨°Âç∞ËØÅ‰∫ÜÈ´òÂ∫¶Áæ§‰ΩìÂåñ„ÄÅÂ∞èÂúàÂ≠êÂº∫ËøûÊé•ÁöÑ‰º†Êí≠Ê®°Âºè„ÄÇ

üìä ÁªºÂêàÊ¥ûÂØüÊÄªÁªì
ÂàùÊúüÊ†∏ÂøÉÂ∞èÂõ¢‰Ωì‰∏ªÂØºÔºåÈöèÁùÄ‰º†Êí≠ÊºîÂåñÔºåÁΩëÁªúËßÑÊ®°Êâ©Â§ß‰ΩÜËÅîÁ≥ªÁ®ÄÁñè„ÄÇ

ÁΩëÁªú‰øùÊåÅÈ´òÂ∫¶ÁöÑËÅöÁ±ªÂíåÂ±ÄÈÉ®ÊÄßÔºåÁæ§‰Ωì‰πãÈó¥ÁöÑ‰º†Êí≠Â£ÅÂûíÂº∫ÁÉà„ÄÇ

‰ø°ÊÅØÁöÑË∑®Áæ§‰ΩìÊâ©Êï£ËÉΩÂäõËæÉÂº±ÔºåÁ¨¶Âêà ÂõûÈü≥ÂÆ§ÊïàÂ∫îÔºàEcho ChamberÔºâ Âíå Âéª‰∏≠ÂøÉÂåñÁöÑÂàÜÊï£‰º†Êí≠ÁâπÂæÅ„ÄÇ

Ê≤°ÊúâÂΩ¢ÊàêÂÖ∏ÂûãÁöÑ‚ÄúÊòéÊòüÁî®Êà∑‰∏ªÂØºÁöÑ‰∏≠ÂøÉÂåñÊâ©Êï£‚ÄùÔºåËÄåÊòØÂ§öÁæ§‰Ωì„ÄÅÂ∞èÂúàÂ≠êÂú®Áã¨Á´ã‰º†Êí≠„ÄÇ


```{r}
results <- data.frame()  # Ê∏ÖÁ©∫ÊàñÂàùÂßãÂåñ

for (g in group_stages) {
  sub_nodes <- which(get.vertex.attribute(net_co_retweet, "group") == g)
  sub_g <- get.inducedSubgraph(net_co_retweet, v = sub_nodes)
  
  adj_mat <- as.matrix.network(sub_g, matrix.type = "adjacency")
  
  results <- rbind(results, data.frame(
    Stage = g,
    Nodes = network.size(sub_g),
    Edges = network.edgecount(sub_g),
    Density = gden(sub_g),
    Degree_Centralization = centralization(adj_mat, FUN = degree, mode = "graph"),
    Closeness_Centralization = centralization(adj_mat, FUN = closeness, mode = "graph"),
    Betweenness_Centralization = centralization(adj_mat, FUN = betweenness, mode = "graph"),
    Transitivity = gtrans(sub_g, mode = "graph")
  ))
}
# 4. Êü•ÁúãÁªìÊûú
print(results)


```


1Ô∏è‚É£ ÂàùÂßãÈò∂ÊÆµ (Stage 1)
ÂÆåÁæéÁöÑ ÂÆåÂÖ®Âõæ (Density=1)ÔºåËäÇÁÇπ‰πãÈó¥ÂÖ®ËøûÊé•„ÄÇ

ÂêÑÁßç‰∏≠ÂøÉÊÄß‰∏∫ 0 ‚Üí ÊùÉÂäõÊûÅÂ∫¶ÂùáË°°ÔºåÊ≤°ÊúâÊòéÊòæÁöÑÊ†∏ÂøÉËäÇÁÇπ„ÄÇ

Transitivity = 1 ‚Üí ÂÆåÁæéÁöÑ‰∏âËßíÈó≠ÁéØÔºåËøôÈÄöÂ∏∏ÂèëÁîüÂú®Â∞èÂõ¢‰Ωì„ÄÅÂêåË¥®ÊÄßÊûÅÈ´òÁöÑÂúàÂ≠ê„ÄÇ

2Ô∏è‚É£ ‰º†Êí≠ÁàÜÂèë (Stage 2)
Density ÈôçÂà∞ 0.51Ôºå‰ΩÜÁΩëÁªúËßÑÊ®°Êâ©Â§ßÔºåEdges Â¢ûÂ§ö„ÄÇ

Degree Centralization ÂºÄÂßã‰∏äÂçáÔºåË°®ÊòéÂá∫Áé∞‰∫ÜÂÖ≥ÈîÆ‰º†Êí≠ËÄÖÔºàÊ†∏ÂøÉËäÇÁÇπÈÄêÊ∏êÂΩ¢ÊàêÔºâ„ÄÇ

‰æùÁÑ∂ÊòØÈ´òÈó≠ÂåÖÔºàTransitivity=1ÔºâÔºåËØ¥ÊòéÁ§æÁæ§ÂÜÖÈÉ®ËÅîÁ≥ªÁ¥ßÂØÜÔºå‰ΩÜÂºÄÂßãÊòæÁé∞‰º†Êí≠ÂàÜÂ∑•„ÄÇ

3Ô∏è‚É£ Áü≠ÊöÇÊî∂Áº© (Stage 3)
ËäÇÁÇπÊï∞ÂíåËæπÊï∞Â§ßÂπÖÂáèÂ∞ëÔºåÁΩëÁªúÂÜçÊ¨°ÂèòÊàêÂÆåÂÖ®Âõæ„ÄÇ

ÂèØËÉΩÊòØ‰ø°ÊÅØ‰º†Êí≠ÁöÑ Áü≠ÊöÇÂÅúÊªû Êàñ Â∞èÂúàÂ±ÇÁã¨Á´ã‰º†Êí≠„ÄÇ

4Ô∏è‚É£ Êâ©Â±ïÂ∞ùËØï (Stage 4)
ËäÇÁÇπÊï∞ÂÜçÊ¨°‰∏äÂçáÔºå‰ΩÜ Density Âæà‰ΩéÔºà0.24ÔºâÔºåÁΩëÁªúÊùæÊï£„ÄÇ

ËØ¥Êòé‰ø°ÊÅØÊâ©Êï£Âà∞‰∫ÜÊõ¥ÂπøÊ≥õÁöÑÂèó‰ºóÔºå‰ΩÜÂΩºÊ≠§‰πãÈó¥ËÅîÁ≥ª‰∏çÂº∫„ÄÇ

‰∏≠ÂøÉÊÄß‰ªç‰ΩéÔºåÊú™ÂΩ¢ÊàêÁ®≥ÂÆöÁöÑ‰ø°ÊÅØ‰º†Êí≠‰∏ªÂØºËÄÖ„ÄÇ

5Ô∏è‚É£ Ê†∏ÂøÉÊâ©Êï£ (Stage 5)
ËôΩÁÑ∂ËäÇÁÇπÊï∞‰∏çÂ§öÔºå‰ΩÜÂá∫Áé∞‰∫ÜÊòæËëóÁöÑ‰∏≠ÂøÉÊÄßÁâπÂæÅÔºö

Degree Centralization È´òËææ 0.36

Closeness Centralization ËææÂà∞ 0.47

Betweenness Centralization ‰πüÊúâ 0.16

Ëøô‰∏ÄÈò∂ÊÆµÂèØËÉΩÂá∫Áé∞‰∫ÜÂÖ≥ÈîÆÊÑèËßÅÈ¢ÜË¢ñÊàñË∂ÖÁ∫ß‰º†Êí≠ËÄÖÔºåÂØπ‰ø°ÊÅØÊâ©Êï£Ëµ∑Âà∞ÊòæËëó‰ΩúÁî®„ÄÇ

Transitivity Èôç‰ΩéÂà∞ 0.85 ‚Üí ÁΩëÁªúÂÜÖÈó≠ÁéØÂáèÂ∞ëÔºåÊõ¥Â§ö Ê°•Êé•ÂûãËäÇÁÇπ Âá∫Áé∞„ÄÇ

6Ô∏è‚É£ ÊúÄÊú´Èò∂ÊÆµ (Stage 6)
ÁΩëÁªúÂÜçÊ¨°Êî∂Áº©ÊàêÂÆåÂÖ®ÂõæÔºåÁæ§‰ΩìÈùûÂ∏∏Â∞èÔºå‰ΩÜËÅîÁ≥ªÈùûÂ∏∏Á¥ßÂØÜ„ÄÇ

ÂèØËÉΩÊòØÊ†∏ÂøÉÁæ§‰ΩìÁöÑ‰ΩôÊ≥¢‰∫§ÊµÅÔºå‰ΩÜÊú™ÂÜçÁªßÁª≠ÂêëÂ§ñ‰º†Êí≠„ÄÇ

## tERGM sample

```{r}

# # Step 1: ÂáÜÂ§áÁΩëÁªúÂàóË°®ÔºàÊØè‰∏™Êó∂Èó¥ÁÇπ‰∏Ä‰∏™ networkÔºâ
# network_list <- list()
# for (g in group_stages) {
#   sub_nodes <- which(get.vertex.attribute(net_co_retweet, "group") <= g)
#   sub_g <- get.inducedSubgraph(net_co_retweet, v = sub_nodes)
#   network_list[[as.character(g)]] <- sub_g
# }
# 
# # Step 2: ÊûÑÂª∫Ê®°Âûã
# # ‰ΩøÁî®ÁÆÄÂçïÁªìÊûÑÊÄßÁâπÂæÅ‰Ωú‰∏∫‰æãÂ≠ê
# model <- tergm(
#   network_list ~ Form(~edges + gwesp(0.5, fixed = TRUE)) + 
#     Dissolution(~edges), 
#   estimate = "CMLE"
# )
# 
# summary(model)

```


# Reference


# Appendix

Raw dataset download link: <https://data.bristol.ac.uk/data/en_GB/dataset/23yv276we2mll25fjakkfim2ml/resource/e63a98c4-b4d6-4a89-9be9-06875b83ce33?inner_span=True>


After downloading all files, create a `data` folder in your working directory and place the files inside it.

Follow the setup instructions provided [here](https://colab.research.google.com/drive/1JCjgg3moGBOuZk4iVjBpQNqgsAYFyNoS#scrollTo=YS1uxj-59UmA). Use the shell to install required packages via `pip` as directed.

Next, open `VS Code`, and run the following Python script to convert `.pkl` files to `.csv`:

```{python}
#| eval: false
#| include: true

import pandas as pd
import os

input_dir = "data/mumin"
output_dir = "data/mumin_csv"
os.makedirs(output_dir, exist_ok=True)

file_names = [
    "claim",
    "user",
    "tweet",
    "reply",
    "article",
    "tweet_discusses_claim",
    "article_discusses_claim",
    "user_follows_user",
    "user_retweeted_tweet",
    "reply_quote_of_tweet",
    "reply_reply_to_tweet"
]

for name in file_names:
    input_path = os.path.join(input_dir, name)
    output_path = os.path.join(output_dir, f"{name}.csv")
    try:
        df = pd.read_pickle(input_path, compression="xz")
        df.to_csv(output_path, index=False)
        print(f"Saved: {output_path}")
    except Exception as e:
        print(f"Failed to convert {name}: {e}")

```

This script will generate the corresponding CSV files for further analysis.

Then, preview the Data in R:

```{r}
#| eval: false
#| include: true
# Set the data path 
data_path <- "data/mumin_csv/"

# Define the list of files to read
files <- c(
  "claim.csv", "user.csv", "tweet.csv", "reply.csv", "article.csv",
  "tweet_discusses_claim.csv", "article_discusses_claim.csv",
  "user_follows_user.csv", "user_retweeted_tweet.csv",
  "reply_quote_of_tweet.csv", "reply_reply_to_tweet.csv"
)

# Preview the first few rows of each file 
previews <- lapply(files, function(fname) {
  fpath <- file.path(data_path, fname)
  tryCatch(
    read_csv(fpath, n_max = 5),
    error = function(e) tibble::tibble(error = paste("Error:", e$message))
  )
})

names(previews) <- files

```

```{=html}
<script>
document.addEventListener("DOMContentLoaded", function() {
    const toc = document.getElementById("TOC");
    if (toc) {
        const sourceLink = document.createElement("div");
        sourceLink.innerHTML = `
            <div class="toc-source">
                <a href="https://github.com/troy-yu-cheng/sna-final-paper" 
                   target="_blank" 
                   class="github-button">
                   <svg xmlns="http://www.w3.org/2000/svg" 
                        viewBox="0 0 24 24" 
                        width="16" 
                        height="16" 
                        fill="currentColor"
                        style="vertical-align: middle; margin-right: 5px;">
                     <path d="M12 0C5.373 0 0 5.373 0 12c0 5.303 3.438 9.8 8.207 11.387.6.113.82-.26.82-.577v-2.157c-3.338.726-4.033-1.416-4.033-1.416-.546-1.386-1.332-1.756-1.332-1.756-1.09-.745.083-.73.083-.73 1.205.084 1.84 1.237 1.84 1.237 1.07 1.832 2.807 1.303 3.492.996.108-.774.418-1.303.76-1.602-2.665-.3-5.466-1.332-5.466-5.93 0-1.311.468-2.382 1.237-3.222-.124-.302-.536-1.52.118-3.163 0 0 1.008-.322 3.3 1.23a11.516 11.516 0 0 1 3.002-.403 11.486 11.486 0 0 1 3.002.403c2.292-1.552 3.3-1.23 3.3-1.23.654 1.644.242 2.861.118 3.163.77.84 1.236 1.911 1.236 3.222 0 4.61-2.807 5.627-5.48 5.922.43.372.812 1.103.812 2.222v3.293c0 .321.218.694.825.576C20.565 21.796 24 17.3 24 12 24 5.373 18.627 0 12 0z"/>
                   </svg>
                   View source
                </a>
            </div>
        `;
        toc.appendChild(sourceLink);
    }
});
</script>
```

